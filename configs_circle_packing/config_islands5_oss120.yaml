# OpenEvolve Island-Based Evolution Configuration
# This configuration demonstrates the proper use of island-based evolution

# General settings
max_iterations: 1000
checkpoint_interval: 100
log_level: "INFO"

# LLM configuration
llm:
  # Use ALCF OpenAI-compatible endpoint
  api_base: "https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1"
  # Available LIVE models on Sophia (as of check):
  # - openai/gpt-oss-120b (120B - large, may have different context limit)
  # - meta-llama/Meta-Llama-3.1-70B-Instruct (70B - 16K context limit)
  # - google/gemma-3-27b-it (27B)
  # - meta-llama/Llama-4-Scout-17B-16E-Instruct (17B)
  # NOTE: 405B is currently STOPPED on Sophia
  primary_model: "openai/gpt-oss-120b"
  primary_model_weight: 1.0
  secondary_model: "openai/gpt-oss-120b"
  secondary_model_weight: 0.0
  temperature: 0.8
  top_p: 0.95
  # gpt-oss-120b is a reasoning model - needs more tokens for reasoning + output
  # Set higher to give room for both thinking and code generation
  max_tokens: 16192
  
  # Timeout settings for Sophia
  timeout: 300
  retries: 3
  retry_delay: 10

# Database configuration with proper island settings
database:
  population_size: 500
  archive_size: 100
  
  # Island-based evolution settings
  num_islands: 5                    # Number of separate populations
  migration_interval: 50            # Migrate every 50 generations
  migration_rate: 0.1               # Migrate 10% of top programs
  
  # Selection parameters
  elite_selection_ratio: 0.1
  exploration_ratio: 0.3
  exploitation_ratio: 0.7
  # Note: diversity_metric fixed to "edit_distance"
  
  # Feature map dimensions for MAP-Elites
  # Default if not specified: ["complexity", "diversity"]
  # Comment out the line below to use the defaults
  # feature_dimensions: ["complexity", "diversity"]
  feature_bins: 10
  # Can also use per-dimension bins:
  # feature_bins:
  #   performance: 20
  #   correctness: 10

# Prompt configuration
prompt:
  num_top_programs: 3
  num_diverse_programs: 2
  use_template_stochasticity: true

# Evaluator configuration
evaluator:
  timeout: 600
  max_retries: 3
  cascade_evaluation: true
  parallel_evaluations: 4

# Evolution settings
# Diff-based evolution requires LLM to output exact SEARCH/REPLACE format
# Full rewrites are more reliable with Llama models
diff_based_evolution: false
allow_full_rewrites: true
max_code_length: 10000
