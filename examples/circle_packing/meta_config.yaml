# Meta-Evolution Configuration for Circle Packing
# 
# This demonstrates the automatic prompt engineering framework.
# The outer loop learns better seed prompts while the inner loop evolves code.

# ============================================================================
# BASE OPENEVOLVE SETTINGS (for inner loop)
# ============================================================================

max_iterations: 50
checkpoint_interval: 10
log_level: "INFO"

# LLM configuration for inner loop evolution
llm:
  api_base: "https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1"
  models:
    - name: "meta-llama/Meta-Llama-3.1-70B-Instruct"
      weight: 0.8
    - name: "meta-llama/Meta-Llama-3.1-8B-Instruct"
      weight: 0.2
  temperature: 0.7
  top_p: 0.95
  max_tokens: 4096
  timeout: 180
  retries: 3
  retry_delay: 10

# Initial prompt (will be replaced/refined by meta-evolution)
prompt:
  system_message: |
    You are an expert at circle packing optimization.
    Your goal is to maximize the sum of radii of 26 circles in a unit square.
  num_top_programs: 3
  use_template_stochasticity: true

# Database/population settings
database:
  population_size: 60
  archive_size: 25
  num_islands: 4
  elite_selection_ratio: 0.3
  exploration_ratio: 0.3
  exploitation_ratio: 0.7

# Evaluator settings
evaluator:
  timeout: 600
  cascade_evaluation: true
  cascade_thresholds: [0.5, 0.75]
  parallel_evaluations: 4
  use_llm_feedback: false

diff_based_evolution: false
allow_full_rewrites: true
max_code_length: 10000

# ============================================================================
# META-EVOLUTION SETTINGS (for outer loop)
# ============================================================================
# Note: These are passed via command-line arguments to meta-evolve.py
# 
# Example run:
#   python meta-evolve.py \
#       examples/circle_packing/initial_program.py \
#       examples/circle_packing/evaluator.py \
#       --config examples/circle_packing/meta_config.yaml \
#       --outer-iterations 5 \
#       --inner-iterations 50 \
#       --baseline-iterations 1000 \
#       --baseline-score 2.635

