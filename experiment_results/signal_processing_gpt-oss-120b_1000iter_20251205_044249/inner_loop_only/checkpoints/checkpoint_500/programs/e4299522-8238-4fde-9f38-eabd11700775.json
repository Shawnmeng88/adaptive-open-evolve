{"id": "e4299522-8238-4fde-9f38-eabd11700775", "code": "# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _kernel(w, kind):\n    if kind == \"gaussian\":\n        s = w / 6.0\n        t = np.arange(w) - (w - 1) / 2\n        k = np.exp(-0.5 * (t / s) ** 2)\n    elif kind in (\"exp\", \"exponential\"):\n        k = np.exp(np.linspace(-2, 0, w))\n    elif kind == \"hann\":\n        k = np.hanning(w)\n    else:\n        k = np.ones(w)\n    return k / k.sum()\n\ndef _mad(x):\n    m = np.median(x)\n    return np.median(np.abs(x - m))\n\ndef _auto_kind(x):\n    return \"gaussian\" if _mad(x) < 0.05 else \"exponential\"\n\ndef _detrend(x, w):\n    return x - np.convolve(x, np.ones(w) / w, \"same\") if w > 0 and len(x) >= w else x\n\ndef _median_filter(x, w):\n    p = w // 2\n    ext = np.pad(x, (p, p), \"edge\")\n    out = np.empty_like(x)\n    for i in range(len(x)):\n        out[i] = np.median(ext[i : i + w])\n    return out\n\ndef process_signal(sig, window=20, alg=\"enhanced\", full=False):\n    if window <= 0:\n        raise ValueError(\"window must be positive\")\n    x = np.asarray(sig, float)\n\n    if alg == \"enhanced\":\n        x = _detrend(x, window)\n        kind = _auto_kind(x)\n    elif alg == \"simple\":\n        kind = \"uniform\"\n    elif alg == \"median\":\n        y = _median_filter(x, window)\n        return np.pad(y, (window // 2, window // 2), \"edge\") if full else y\n    else:\n        kind = alg\n\n    mode = \"same\" if full else \"valid\"\n    return np.convolve(x, _kernel(window, kind), mode=mode)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n", "language": "python", "parent_id": "cdda241d-b057-4be8-b91e-f80d7ac3dbd1", "generation": 8, "timestamp": 1764932653.445892, "iteration_found": 293, "metrics": {"runs_successfully": 1.0, "composite_score": 0.4128316457180309, "output_length": 91.0, "overall_score": 0.28798980114435524, "slope_changes": 155.0, "lag_error": 0.35539883377261255, "avg_error": 0.9565324748302244, "false_reversals": 124.2, "correlation": -0.006103226166624641, "noise_reduction": 0.0, "smoothness_score": 0.11428571428571428, "responsiveness_score": 0.7377902172282407, "accuracy_score": 0.0, "efficiency_score": 1.0, "execution_time": 0.0006083488464355469, "success_rate": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Evolve block rewrite (preserved external code)", "parent_metrics": {"runs_successfully": 1.0, "composite_score": 0.4128316457180309, "output_length": 91.0, "overall_score": 0.28798980114435524, "slope_changes": 155.0, "lag_error": 0.35539883377261255, "avg_error": 0.9565324748302244, "false_reversals": 124.2, "correlation": -0.006103226166624641, "noise_reduction": 0.0, "smoothness_score": 0.11428571428571428, "responsiveness_score": 0.7377902172282407, "accuracy_score": 0.0, "efficiency_score": 1.0, "execution_time": 0.0006182670593261718, "success_rate": 1.0}, "island": 4}, "prompts": {"full_rewrite_user": {"system": "You are an expert software developer tasked with iteratively improving a codebase.\nYour goal is to maximize the FITNESS SCORE while exploring diverse solutions across feature dimensions.\nThe system maintains a collection of diverse programs - both high fitness AND diversity are valuable.", "user": "# Current Program Information\n- Fitness: 23.5037\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness declined: 23.5037 \u2192 23.5037. Consider revising recent changes.\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4128, output_length: 91.0000, overall_score: 0.2880, slope_changes: 155.0000, lag_error: 0.3554, avg_error: 0.9565, false_reversals: 124.2000, correlation: -0.0061, noise_reduction: 0.0000, smoothness_score: 0.1143, responsiveness_score: 0.7378, accuracy_score: 0.0000, efficiency_score: 1.0000, execution_time: 0.0007, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4128, output_length: 91.0000, overall_score: 0.2880, slope_changes: 155.0000, lag_error: 0.3554, avg_error: 0.9565, false_reversals: 124.2000, correlation: -0.0061, noise_reduction: 0.0000, smoothness_score: 0.1143, responsiveness_score: 0.7378, accuracy_score: 0.0000, efficiency_score: 1.0000, execution_time: 0.0007, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4128, output_length: 91.0000, overall_score: 0.2880, slope_changes: 155.0000, lag_error: 0.3554, avg_error: 0.9565, false_reversals: 124.2000, correlation: -0.0061, noise_reduction: 0.0000, smoothness_score: 0.1143, responsiveness_score: 0.7378, accuracy_score: 0.0000, efficiency_score: 1.0000, execution_time: 0.0007, success_rate: 1.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 23.5037)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\ndef _w(w,k):\n    if k==\"gaussian\":\n        s=w/6.;t=np.arange(w)-(w-1)/2;wt=np.exp(-0.5*(t/s)**2)\n    elif k==\"exponential\":\n        wt=np.exp(np.linspace(-2,0,w))\n    else:\n        wt=np.ones(w)\n    return wt/wt.sum()\ndef _d(x,w):\n    if w<=0 or len(x)<w:return x\n    tr=np.convolve(x,np.ones(w)/w,'same')\n    return x-tr\ndef process_signal(sig,win=20,alg=\"enhanced\",full=False):\n    x=np.asarray(sig,float)\n    if alg==\"enhanced\":\n        x=_d(x,win);k=\"exponential\"\n    elif alg==\"simple\":\n        k=\"uniform\"\n    elif alg==\"gaussian\":\n        k=\"gaussian\"\n    elif alg==\"exp\":\n        k=\"exponential\"\n    else:\n        k=alg\n    y=np.convolve(x,_w(win,k),'valid')\n    if full:\n        pad=win//2\n        y=np.pad(y,(pad,len(x)-len(y)-pad),mode='edge')\n    return y\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4128), Performs well on output_length (91.0000), Performs well on overall_score (0.2880), Performs well on slope_changes (155.0000), Performs well on lag_error (0.3554), Performs well on avg_error (0.9565), Performs well on false_reversals (124.2000), Performs well on correlation (-0.0061), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.1143), Performs well on responsiveness_score (0.7378), Performs well on accuracy_score (0.0000), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0007), Performs well on success_rate (1.0000)\n\n### Program 2 (Score: 23.5037)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _kernel(w, kind):\n    \"\"\"Return a normalized weighting kernel.\"\"\"\n    if kind == \"gaussian\":\n        sigma = w / 6.0\n        t = np.arange(w) - (w - 1) / 2\n        k = np.exp(-0.5 * (t / sigma) ** 2)\n    elif kind in (\"exponential\", \"exp\"):\n        k = np.exp(np.linspace(-2, 0, w))\n    else:  # uniform fallback\n        k = np.ones(w)\n    return k / k.sum()\n\n\ndef _detrend(x, w):\n    \"\"\"Remove a moving\u2011average trend from the signal.\"\"\"\n    if w > 0 and len(x) >= w:\n        return x - np.convolve(x, np.ones(w) / w, mode=\"same\")\n    return x\n\n\ndef _mad(x):\n    \"\"\"Median absolute deviation, a robust measure of spread.\"\"\"\n    med = np.median(x)\n    return np.median(np.abs(x - med))\n\n\ndef _auto_kind(x):\n    \"\"\"Choose kernel based on signal variability (robust MAD test).\"\"\"\n    return \"gaussian\" if _mad(x) < 0.05 else \"exponential\"\n\n\ndef process_signal(sig, window=20, alg=\"enhanced\", full=False):\n    \"\"\"\n    Smooth a 1\u2011D signal.\n\n    Parameters\n    ----------\n    sig : array\u2011like\n        Input signal.\n    window : int, optional\n        Length of the smoothing kernel (default 20).\n    alg : str, optional\n        \"enhanced\" \u2013 detrend + adaptive kernel,\n        \"simple\"   \u2013 uniform moving average,\n        any other value is taken as a kernel kind\n        (e.g. \"gaussian\", \"exponential\", \"exp\").\n    full : bool, optional\n        If True, return a full\u2011length (``same``) output; otherwise ``valid``.\n\n    Returns\n    -------\n    np.ndarray\n        Smoothed signal.\n    \"\"\"\n    if window <= 0:\n        raise ValueError(\"window must be a positive integer\")\n    x = np.asarray(sig, dtype=float)\n\n    if alg == \"enhanced\":\n        x = _detrend(x, window)\n        kind = _auto_kind(x)\n    elif alg == \"simple\":\n        kind = \"uniform\"\n    else:\n        kind = alg\n\n    mode = \"same\" if full else \"valid\"\n    return np.convolve(x, _kernel(window, kind), mode=mode)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4128), Performs well on output_length (91.0000), Performs well on overall_score (0.2880), Performs well on slope_changes (155.0000), Performs well on lag_error (0.3554), Performs well on avg_error (0.9565), Performs well on false_reversals (124.2000), Performs well on correlation (-0.0061), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.1143), Performs well on responsiveness_score (0.7378), Performs well on accuracy_score (0.0000), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0007), Performs well on success_rate (1.0000)\n\n### Program 3 (Score: 23.5037)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef _kernel(w, kind):\n    if kind == \"gaussian\":\n        s = w / 6.0\n        t = np.arange(w) - (w - 1) / 2\n        k = np.exp(-0.5 * (t / s) ** 2)\n    elif kind in (\"exponential\", \"exp\"):\n        k = np.exp(np.linspace(-2, 0, w))\n    else:\n        k = np.ones(w)\n    return k / k.sum()\n\ndef _detrend(x, w):\n    if w > 0 and len(x) >= w:\n        return x - np.convolve(x, np.ones(w) / w, mode=\"same\")\n    return x\n\ndef _mad(x):\n    m = np.median(x)\n    return np.median(np.abs(x - m))\n\ndef _auto_kind(x):\n    return \"gaussian\" if _mad(x) < 0.05 else \"exponential\"\n\ndef process_signal(sig, window=20, alg=\"enhanced\", full=False):\n    x = np.asarray(sig, dtype=float)\n    if alg == \"enhanced\":\n        x = _detrend(x, window)\n        kind = _auto_kind(x)\n    elif alg == \"simple\":\n        kind = \"uniform\"\n    else:\n        kind = alg\n    mode = \"same\" if full else \"valid\"\n    return np.convolve(x, _kernel(window, kind), mode=mode)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4128), Performs well on output_length (91.0000), Performs well on overall_score (0.2880), Performs well on slope_changes (155.0000), Performs well on lag_error (0.3554), Performs well on avg_error (0.9565), Performs well on false_reversals (124.2000), Performs well on correlation (-0.0061), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.1143), Performs well on responsiveness_score (0.7378), Performs well on accuracy_score (0.0000), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0007), Performs well on success_rate (1.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 23.5037)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _kernel(w, k):\n    if k == \"gaussian\":\n        s = w / 6.0\n        t = np.arange(w) - (w - 1) / 2\n        kw = np.exp(-0.5 * (t / s) ** 2)\n    elif k in (\"exponential\", \"exp\"):\n        kw = np.exp(np.linspace(-2, 0, w))\n    else:\n        kw = np.ones(w)\n    return kw / kw.sum()\n\ndef _detrend(x, w):\n    return x - np.convolve(x, np.ones(w) / w, mode=\"same\") if w > 0 and len(x) >= w else x\n\ndef process_signal(sig, win=20, alg=\"enhanced\", full=False):\n    x = np.asarray(sig, float)\n    if alg == \"enhanced\":\n        x = _detrend(x, win)\n        mad = np.median(np.abs(x - np.median(x)))\n        k = \"gaussian\" if mad < 0.05 else \"exponential\"\n    elif alg == \"simple\":\n        k = \"uniform\"\n    else:\n        k = alg\n    mode = \"same\" if full else \"valid\"\n    return np.convolve(x, _kernel(win, k), mode=mode)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to composite_score\n\n### Program D2 (Score: 23.5037)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _kernel(w, kind):\n    \"\"\"Return a normalized weighting kernel.\"\"\"\n    if kind == \"gaussian\":\n        s = w / 6.0\n        t = np.arange(w) - (w - 1) / 2\n        k = np.exp(-0.5 * (t / s) ** 2)\n    elif kind in (\"exp\", \"exponential\"):\n        k = np.exp(np.linspace(-2, 0, w))\n    else:\n        k = np.ones(w)\n    return k / k.sum()\n\ndef _mad(x):\n    \"\"\"Median absolute deviation \u2013 a robust spread estimator.\"\"\"\n    m = np.median(x)\n    return np.median(np.abs(x - m))\n\ndef _detrend(x, w):\n    \"\"\"Remove a moving\u2011average trend from the signal.\"\"\"\n    return (\n        x - np.convolve(x, np.ones(w) / w, mode=\"same\")\n        if w > 0 and len(x) >= w\n        else x\n    )\n\ndef process_signal(sig, win=20, alg=\"enhanced\", full=False, kernel_func=None):\n    \"\"\"\n    Smooth a 1\u2011D signal.\n\n    Parameters\n    ----------\n    sig : array\u2011like\n        Input signal.\n    win : int, optional\n        Window length for the kernel (must be > 0).\n    alg : str, optional\n        \"enhanced\" \u2013 detrend + adaptive kernel,\n        \"simple\"   \u2013 uniform moving average,\n        any other string is interpreted as a kernel kind.\n    full : bool, optional\n        Return full\u2011length output (mode='same') when True.\n    kernel_func : callable, optional\n        Custom kernel generator ``func(win, kind)``. If supplied, its\n        output is normalized before convolution.\n\n    Returns\n    -------\n    np.ndarray\n        Smoothed signal.\n    \"\"\"\n    if win <= 0:\n        raise ValueError(\"win must be a positive integer\")\n    x = np.asarray(sig, dtype=float)\n\n    if alg == \"enhanced\":\n        x = _detrend(x, win)\n        kind = \"gaussian\" if _mad(x) < 0.05 else \"exponential\"\n    elif alg == \"simple\":\n        kind = \"uniform\"\n    else:\n        kind = alg\n\n    mode = \"same\" if full else \"valid\"\n    kernel = kernel_func(win, kind) if kernel_func else _kernel(win, kind)\n    kernel = kernel / np.sum(kernel)  # ensure normalization\n    return np.convolve(x, kernel, mode=mode)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to composite_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 23.5037, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef _kernel(w, kind):\n    if w <= 0:\n        raise ValueError(\"window must be positive\")\n    if w == 1:\n        return np.ones(1)\n    if kind == \"gaussian\":\n        s = w / 6.0\n        t = np.arange(w) - (w - 1) / 2\n        k = np.exp(-0.5 * (t / s) ** 2)\n    elif kind in (\"exp\", \"exponential\"):\n        k = np.exp(np.linspace(-2, 0, w))\n    else:\n        k = np.ones(w)\n    return k / k.sum()\n\ndef _mad(x):\n    m = np.median(x)\n    return np.median(np.abs(x - m))\n\ndef _detrend(x, w):\n    if w > 0 and len(x) >= w:\n        return x - np.convolve(x, np.ones(w) / w, mode=\"same\")\n    return x\n\ndef process_signal(sig, win=20, alg=\"enhanced\", full=False, kernel_func=None):\n    if win <= 0:\n        raise ValueError(\"win must be a positive integer\")\n    x = np.asarray(sig, dtype=float)\n\n    if alg == \"enhanced\":\n        x = _detrend(x, win)\n        kind = \"gaussian\" if _mad(x) < 0.05 else \"exponential\"\n    elif alg == \"simple\":\n        kind = \"uniform\"\n    elif alg == \"median\":\n        k = win if win % 2 else win + 1\n        pad = k // 2\n        padded = np.pad(x, pad, mode=\"edge\")\n        out = np.empty_like(x)\n        for i in range(len(x)):\n            out[i] = np.median(padded[i:i + k])\n        return out if not full else np.pad(out, (pad, pad), mode=\"edge\")\n    else:\n        kind = alg\n\n    mode = \"same\" if full else \"valid\"\n    kernel = kernel_func(win, kind) if kernel_func else _kernel(win, kind)\n    kernel = kernel / np.sum(kernel)\n    return np.convolve(x, kernel, mode=mode)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (91.000)\n\n### Inspiration 2 (Score: 13.7277, Type: Migrant)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nReal-Time Adaptive Signal Processing Algorithm for Non-Stationary Time Series\n\nThis algorithm implements a sliding window approach to filter volatile, non-stationary\ntime series data while minimizing noise and preserving signal dynamics.\n\"\"\"\nimport numpy as np\nfrom scipy import signal\nfrom collections import deque\n\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"\n    Adaptive signal processing algorithm using sliding window approach.\n\n    Args:\n        x: Input signal (1D array of real-valued samples)\n        window_size: Size of the sliding window (W samples)\n\n    Returns:\n        y: Filtered output signal with length = len(x) - window_size + 1\n    \"\"\"\n    if len(x) < window_size:\n        raise ValueError(f\"Input signal length ({len(x)}) must be >= window_size ({window_size})\")\n\n    # Initialize output array\n    output_length = len(x) - window_size + 1\n    y = np.zeros(output_length)\n\n    # Simple moving average as baseline\n    for i in range(output_length):\n        window = x[i : i + window_size]\n\n        # Basic moving average filter\n        y[i] = np.mean(window)\n\n    return y\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"\n    Enhanced version with trend preservation using weighted moving average.\n\n    Args:\n        x: Input signal (1D array of real-valued samples)\n        window_size: Size of the sliding window\n\n    Returns:\n        y: Filtered output signal\n    \"\"\"\n    if len(x) < window_size:\n        raise ValueError(f\"Input signal length ({len(x)}) must be >= window_size ({window_size})\")\n\n    output_length = len(x) - window_size + 1\n    y = np.zeros(output_length)\n\n    # Create weights that emphasize recent samples\n    weights = np.exp(np.linspace(-2, 0, window_size))\n    weights = weights / np.sum(weights)\n\n    for i in range(output_length):\n        window = x[i : i + window_size]\n\n        # Weighted moving average with exponential weights\n        y[i] = np.sum(window * weights)\n\n    return y\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Main signal processing function that applies the selected algorithm.\n\n    Args:\n        input_signal: Input time series data\n        window_size: Window size for processing\n        algorithm_type: Type of algorithm to use (\"basic\" or \"enhanced\")\n\n    Returns:\n        Filtered signal\n    \"\"\"\n    if algorithm_type == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    else:\n        return adaptive_filter(input_signal, window_size)\n\n\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Excellent runs_successfully (1.000), Excellent output_length (91.000), Excellent slope_changes (66.000)\n\n### Inspiration 3 (Score: 23.5037, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef _kernel(w, kind):\n    if kind == \"gaussian\":\n        sigma = w / 6.0\n        t = np.arange(w) - (w - 1) / 2\n        k = np.exp(-0.5 * (t / sigma) ** 2)\n    elif kind in (\"exp\", \"exponential\"):\n        k = np.exp(np.linspace(-2, 0, w))\n    elif kind == \"hann\":\n        k = np.hanning(w)\n    else:  # uniform fallback\n        k = np.ones(w)\n    return k / k.sum()\n\ndef _mad(x):\n    m = np.median(x)\n    return np.median(np.abs(x - m))\n\ndef _detrend(x, w):\n    if w > 0 and len(x) >= w:\n        return x - np.convolve(x, np.ones(w) / w, mode=\"same\")\n    return x\n\ndef _choose_kernel(x):\n    mad = _mad(x)\n    if mad < 0.02:\n        return \"gaussian\"\n    if mad < 0.1:\n        return \"hann\"\n    return \"exponential\"\n\ndef process_signal(sig, win=20, alg=\"enhanced\", full=False, kernel_func=None):\n    \"\"\"\n    Smooth a 1\u2011D signal.\n\n    Parameters\n    ----------\n    sig : array\u2011like\n        Input signal.\n    win : int, optional\n        Window length (>0).\n    alg : str, optional\n        \"enhanced\" \u2013 detrend + adaptive kernel,\n        \"simple\"   \u2013 uniform moving average,\n        otherwise interpreted as a kernel name.\n    full : bool, optional\n        Return full\u2011length output (mode='same') when True.\n    kernel_func : callable, optional\n        Custom kernel generator ``func(win, kind)``.\n    \"\"\"\n    if win <= 0:\n        raise ValueError(\"win must be a positive integer\")\n    x = np.asarray(sig, dtype=float)\n\n    if alg == \"enhanced\":\n        x = _detrend(x, win)\n        kind = _choose_kernel(x)\n    elif alg == \"simple\":\n        kind = \"uniform\"\n    else:\n        kind = alg\n\n    mode = \"same\" if full else \"valid\"\n    kernel = kernel_func(win, kind) if kernel_func else _kernel(win, kind)\n    return np.convolve(x, kernel, mode=mode)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (91.000)\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef _kernel(w, kind):\n    if kind == \"gaussian\":\n        s = w / 6.0\n        t = np.arange(w) - (w - 1) / 2\n        k = np.exp(-0.5 * (t / s) ** 2)\n    elif kind in (\"exp\", \"exponential\"):\n        k = np.exp(np.linspace(-2, 0, w))\n    else:\n        k = np.ones(w)\n    return k / k.sum()\n\ndef _mad(x):\n    m = np.median(x)\n    return np.median(np.abs(x - m))\n\ndef _auto_kind(x):\n    return \"gaussian\" if _mad(x) < 0.05 else \"exponential\"\n\ndef _detrend(x, w):\n    return x - np.convolve(x, np.ones(w) / w, mode=\"same\") if w > 0 and len(x) >= w else x\n\ndef process_signal(sig, window=20, alg=\"enhanced\", full=False):\n    if window <= 0:\n        raise ValueError(\"window must be a positive integer\")\n    x = np.asarray(sig, dtype=float)\n    if alg == \"enhanced\":\n        x = _detrend(x, window)\n        kind = _auto_kind(x)\n    elif alg == \"simple\":\n        kind = \"uniform\"\n    else:\n        kind = alg\n    mode = \"same\" if full else \"valid\"\n    return np.convolve(x, _kernel(window, kind), mode=mode)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\n\n# Task\nImprove the code to maximize FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\n\n## CRITICAL INSTRUCTIONS\nIf the code contains `# EVOLVE-BLOCK-START` and `# EVOLVE-BLOCK-END` markers:\n- Output ONLY the code that goes BETWEEN these markers\n- Do NOT include the markers themselves\n- Do NOT include code outside the markers (like `run_packing()`)\n- The system will automatically merge your output with the preserved sections\n\nIf there are NO EVOLVE-BLOCK markers:\n- Output the complete rewritten program\n\n```python\n# Your improved code here (ONLY the evolve block content if markers exist)\n```", "responses": ["import numpy as np\n\ndef _kernel(w, kind):\n    if kind == \"gaussian\":\n        s = w / 6.0\n        t = np.arange(w) - (w - 1) / 2\n        k = np.exp(-0.5 * (t / s) ** 2)\n    elif kind in (\"exp\", \"exponential\"):\n        k = np.exp(np.linspace(-2, 0, w))\n    elif kind == \"hann\":\n        k = np.hanning(w)\n    else:\n        k = np.ones(w)\n    return k / k.sum()\n\ndef _mad(x):\n    m = np.median(x)\n    return np.median(np.abs(x - m))\n\ndef _auto_kind(x):\n    return \"gaussian\" if _mad(x) < 0.05 else \"exponential\"\n\ndef _detrend(x, w):\n    return x - np.convolve(x, np.ones(w) / w, \"same\") if w > 0 and len(x) >= w else x\n\ndef _median_filter(x, w):\n    p = w // 2\n    ext = np.pad(x, (p, p), \"edge\")\n    out = np.empty_like(x)\n    for i in range(len(x)):\n        out[i] = np.median(ext[i : i + w])\n    return out\n\ndef process_signal(sig, window=20, alg=\"enhanced\", full=False):\n    if window <= 0:\n        raise ValueError(\"window must be positive\")\n    x = np.asarray(sig, float)\n\n    if alg == \"enhanced\":\n        x = _detrend(x, window)\n        kind = _auto_kind(x)\n    elif alg == \"simple\":\n        kind = \"uniform\"\n    elif alg == \"median\":\n        y = _median_filter(x, window)\n        return np.pad(y, (window // 2, window // 2), \"edge\") if full else y\n    else:\n        kind = alg\n\n    mode = \"same\" if full else \"valid\"\n    return np.convolve(x, _kernel(window, kind), mode=mode)"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}