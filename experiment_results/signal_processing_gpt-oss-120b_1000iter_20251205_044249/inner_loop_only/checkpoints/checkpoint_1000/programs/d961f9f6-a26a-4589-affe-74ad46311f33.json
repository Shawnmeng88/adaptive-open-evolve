{"id": "d961f9f6-a26a-4589-affe-74ad46311f33", "code": "# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\n@lru_cache(None)\ndef _kernel(w, kind):\n    t = np.arange(w) - (w - 1) / 2\n    if kind == \"gaussian\":\n        s = w / 6.0\n        k = np.exp(-0.5 * (t / s) ** 2)\n    elif kind == \"hann\":\n        k = np.hanning(w)\n    elif kind in (\"exp\", \"exponential\"):\n        k = np.exp(np.linspace(-2, 0, w))\n    else:\n        k = np.ones(w)\n    return k / k.sum()\n\ndef _interp_nan(x):\n    if np.isnan(x).any():\n        i = np.arange(x.size)\n        m = np.isfinite(x)\n        x = np.interp(i, i[m], x[m])\n    return x\n\ndef _detrend(x, w):\n    if w > 0 and x.size >= w:\n        return x - np.convolve(x, np.ones(w) / w, mode=\"same\")\n    return x\n\ndef _mad(x):\n    m = np.median(x)\n    return np.median(np.abs(x - m))\n\ndef _auto_kind(x):\n    mad = _mad(x)\n    var = x.var()\n    if mad < 0.015 and var < 0.02:\n        return \"gaussian\"\n    if mad < 0.07:\n        return \"hann\"\n    return \"exponential\"\n\ndef _median_filter(x, w):\n    p = w // 2\n    a = np.pad(x, (p, p), mode=\"edge\")\n    shape = (x.size, w)\n    strides = (a.strides[0], a.strides[0])\n    win = np.lib.stride_tricks.as_strided(a, shape, strides)\n    return np.median(win, axis=1)\n\ndef _valid_slice(y, w):\n    off = w - 1\n    s = off // 2\n    e = -(off - s) if (off - s) != 0 else None\n    return y[s:e]\n\ndef process_signal(sig, win=20, alg=\"enhanced\", full=False):\n    if win <= 0:\n        raise ValueError(\"win must be positive\")\n    x = _interp_nan(np.asarray(sig, float))\n    if alg == \"enhanced\":\n        x = _detrend(x, win)\n        kind = _auto_kind(x)\n        y = np.convolve(x, _kernel(win, kind), mode=\"same\")\n    elif alg == \"simple\":\n        y = np.convolve(x, _kernel(win, \"uniform\"), mode=\"same\")\n    elif alg == \"median\":\n        y = _median_filter(x, win)\n        return y if full else y\n    elif alg == \"smooth\":\n        y = np.convolve(x, _kernel(win, \"hann\"), mode=\"same\")\n    else:\n        y = np.convolve(x, _kernel(win, alg), mode=\"same\")\n    if not full:\n        y = _valid_slice(y, win)\n    return y\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n", "language": "python", "parent_id": "f1d13e23-6ff6-4b5c-8095-ab55bf7caa52", "generation": 10, "timestamp": 1764936136.122779, "iteration_found": 0, "metrics": {"runs_successfully": 1.0, "composite_score": 0.41313607247534356, "output_length": 91.0, "overall_score": 0.28813772418464545, "slope_changes": 154.8, "lag_error": 0.35881931759431995, "avg_error": 0.9556927600460691, "false_reversals": 125.6, "correlation": -0.007282066797801695, "noise_reduction": 0.0, "smoothness_score": 0.11441647597254004, "responsiveness_score": 0.7359330170330661, "accuracy_score": 0.0, "efficiency_score": 1.0, "execution_time": 0.0006815433502197265, "success_rate": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Evolve block rewrite (preserved external code)", "parent_metrics": {"runs_successfully": 1.0, "composite_score": 0.41313607247534356, "output_length": 91.0, "overall_score": 0.28813772418464545, "slope_changes": 154.8, "lag_error": 0.35881931759431995, "avg_error": 0.9556927600460691, "false_reversals": 125.6, "correlation": -0.007282066797801695, "noise_reduction": 0.0, "smoothness_score": 0.11441647597254004, "responsiveness_score": 0.7359330170330661, "accuracy_score": 0.0, "efficiency_score": 1.0, "execution_time": 0.0006133556365966797, "success_rate": 1.0}, "island": 3, "migrant": true}, "prompts": null, "artifacts_json": null, "artifact_dir": null, "embedding": null}