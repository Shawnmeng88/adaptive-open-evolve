{"id": "9d758cad-8297-479b-81c1-de28695d5c8b", "code": "# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _weights(w, kind):\n    t = np.arange(w) - (w - 1) / 2\n    if kind == \"gaussian\":\n        s = w / 6.0\n        wts = np.exp(-0.5 * (t / s) ** 2)\n    elif kind == \"exponential\":\n        wts = np.exp(np.linspace(-2, 0, w))\n    elif kind == \"triangular\":\n        wts = 1 - np.abs(t) / ((w + 1) / 2)\n    else:  # uniform / fallback\n        wts = np.ones(w)\n    return wts / wts.sum()\n\ndef _smooth(x, w, kind):\n    if len(x) < w:\n        raise ValueError(\"signal shorter than window\")\n    return np.convolve(x, _weights(w, kind), mode=\"valid\")\n\ndef _median(x, w):\n    if len(x) < w:\n        raise ValueError(\"signal shorter than window\")\n    shape = (len(x) - w + 1, w)\n    strides = (x.strides[0], x.strides[0])\n    win = np.lib.stride_tricks.as_strided(x, shape=shape, strides=strides)\n    return np.median(win, axis=1)\n\ndef _detrend_linear(x):\n    n = len(x)\n    if n < 2:\n        return x\n    t = np.arange(n)\n    m, c = np.linalg.lstsq(np.vstack([t, np.ones(n)]).T, x, rcond=None)[0]\n    return x - (m * t + c)\n\ndef _detrend_ma(x, w):\n    if w <= 0 or len(x) < w:\n        return x\n    trend = np.convolve(x, np.ones(w) / w, mode=\"same\")\n    return x - trend\n\ndef process_signal(sig, window=20, algo=\"enhanced\", detrend=\"linear\"):\n    x = np.asarray(sig, dtype=float)\n\n    if detrend == \"linear\":\n        x = _detrend_linear(x)\n    elif detrend == \"ma\":\n        x = _detrend_ma(x, window)\n\n    if algo == \"enhanced\":\n        return _smooth(x, window, \"exponential\")\n    if algo == \"simple\":\n        return _smooth(x, window, \"uniform\")\n    if algo == \"median\":\n        return _median(x, window)\n    if algo in (\"gaussian\", \"triangular\", \"exponential\"):\n        kind = \"exponential\" if algo == \"exponential\" else algo\n        return _smooth(x, window, kind)\n\n    # custom weighting name\n    return _smooth(x, window, algo)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n", "language": "python", "parent_id": "65e59e4e-111e-4f62-94dc-23b3d3d18a16", "generation": 6, "timestamp": 1764932037.664899, "iteration_found": 158, "metrics": {"runs_successfully": 1.0, "composite_score": 0.3958493784730336, "output_length": 91.0, "overall_score": 0.36006395314799333, "slope_changes": 64.6, "lag_error": 1.6017393170552072, "avg_error": 1.3861988156801675, "false_reversals": 52.6, "correlation": 0.27221438940855636, "noise_reduction": 0.0, "smoothness_score": 0.23640661938534283, "responsiveness_score": 0.38435826120037864, "accuracy_score": 0.27221438940855636, "efficiency_score": 1.0, "execution_time": 0.0005889892578125, "success_rate": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Evolve block rewrite (preserved external code)", "parent_metrics": {"runs_successfully": 1.0, "composite_score": 0.4287441921505808, "output_length": 82.0, "overall_score": 0.39284752068826045, "slope_changes": 65.8, "lag_error": 0.978874256773139, "avg_error": 1.1588927406878609, "false_reversals": 54.0, "correlation": 0.37364898603990737, "noise_reduction": 0.0, "smoothness_score": 0.2331002331002331, "responsiveness_score": 0.5053378184982076, "accuracy_score": 0.37364898603990737, "efficiency_score": 1.0, "execution_time": 0.0007300376892089844, "success_rate": 1.0}, "island": 2}, "prompts": {"full_rewrite_user": {"system": "You are an expert software developer tasked with iteratively improving a codebase.\nYour goal is to maximize the FITNESS SCORE while exploring diverse solutions across feature dimensions.\nThe system maintains a collection of diverse programs - both high fitness AND diversity are valuable.", "user": "# Current Program Information\n- Fitness: 13.0779\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness declined: 23.5037 \u2192 13.0779. Consider revising recent changes.\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4128, output_length: 91.0000, overall_score: 0.2880, slope_changes: 155.0000, lag_error: 0.3554, avg_error: 0.9565, false_reversals: 124.2000, correlation: -0.0061, noise_reduction: 0.0000, smoothness_score: 0.1143, responsiveness_score: 0.7378, accuracy_score: 0.0000, efficiency_score: 1.0000, execution_time: 0.0005, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4128, output_length: 91.0000, overall_score: 0.2880, slope_changes: 155.0000, lag_error: 0.3554, avg_error: 0.9565, false_reversals: 124.2000, correlation: -0.0061, noise_reduction: 0.0000, smoothness_score: 0.1143, responsiveness_score: 0.7378, accuracy_score: 0.0000, efficiency_score: 1.0000, execution_time: 0.0005, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4128, output_length: 91.0000, overall_score: 0.2880, slope_changes: 155.0000, lag_error: 0.3554, avg_error: 0.9565, false_reversals: 124.2000, correlation: -0.0061, noise_reduction: 0.0000, smoothness_score: 0.1143, responsiveness_score: 0.7378, accuracy_score: 0.0000, efficiency_score: 1.0000, execution_time: 0.0005, success_rate: 1.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 23.5037)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\ndef _w(w,k):\n    if k==\"gaussian\":\n        t=np.arange(w)-(w-1)/2; s=w/6.; wts=np.exp(-0.5*(t/s)**2)\n    elif k==\"exponential\":\n        wts=np.exp(np.linspace(-2,0,w))\n    elif k==\"triangular\":\n        t=np.arange(w)-(w-1)/2; wts=1-abs(t)/((w+1)/2)\n    else:\n        wts=np.ones(w)\n    return wts/wts.sum()\ndef _s(x,w,k):\n    if len(x)<w: raise ValueError\n    return np.convolve(x,_w(w,k),mode=\"valid\")\ndef _d(x,w,m):\n    if m==\"linear\" and len(x)>1:\n        t=np.arange(len(x)); a,b=np.linalg.lstsq(np.vstack([t,np.ones_like(t)]).T,x,rcond=None)[0]\n        return x-(a*t+b)\n    if m==\"ma\" and w>0:\n        return x-np.convolve(x,np.ones(w)/w,mode=\"same\")\n    return x\ndef process_signal(sig,window=20,algorithm=\"enhanced\",detrend=\"ma\"):\n    x=np.asarray(sig,float)\n    if algorithm==\"enhanced\":\n        x=_d(x,window,detrend); k=\"exponential\"\n    elif algorithm==\"simple\": k=\"uniform\"\n    elif algorithm==\"gaussian\": k=\"gaussian\"\n    elif algorithm==\"triangular\": k=\"triangular\"\n    else: k=algorithm\n    return _s(x,window,k)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4128), Performs well on output_length (91.0000), Performs well on overall_score (0.2880), Performs well on slope_changes (155.0000), Performs well on lag_error (0.3554), Performs well on avg_error (0.9565), Performs well on false_reversals (124.2000), Performs well on correlation (-0.0061), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.1143), Performs well on responsiveness_score (0.7378), Performs well on accuracy_score (0.0000), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0005), Performs well on success_rate (1.0000)\n\n### Program 2 (Score: 23.5037)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _weights(w, kind):\n    if kind == \"gaussian\":\n        sigma = w / 6.0\n        t = np.arange(w) - (w - 1) / 2\n        wts = np.exp(-0.5 * (t / sigma) ** 2)\n    elif kind == \"exponential\":\n        wts = np.exp(np.linspace(-2, 0, w))\n    else:  # uniform / fallback\n        wts = np.ones(w)\n    return wts / wts.sum()\n\ndef _smooth(x, w, kind):\n    if len(x) < w:\n        raise ValueError(f\"Signal length ({len(x)}) < window ({w})\")\n    return np.convolve(x, _weights(w, kind), mode=\"valid\")\n\ndef _detrend(x, w, mode):\n    if mode == \"linear\" and len(x) > 1:\n        t = np.arange(len(x))\n        m, c = np.linalg.lstsq(np.vstack([t, np.ones_like(t)]).T, x, rcond=None)[0]\n        return x - (m * t + c)\n    if mode == \"ma\" and w > 0:\n        return x - np.convolve(x, np.ones(w) / w, mode=\"same\")\n    return x\n\ndef process_signal(sig, window=20, algorithm=\"enhanced\", detrend=\"ma\"):\n    \"\"\"\n    Filter a 1\u2011D signal.\n\n    Parameters\n    ----------\n    sig : array\u2011like\n        Input signal.\n    window : int, optional\n        Length of the smoothing window (default 20).\n    algorithm : str, optional\n        Weighting scheme:\n        - \"enhanced\": detrend + exponential weighting\n        - \"simple\": uniform moving average\n        - \"gaussian\": Gaussian weighting\n        - \"exp\": exponential weighting\n        Any other value is treated as a custom weighting name.\n    detrend : str, optional\n        Detrending method: \"linear\", \"ma\", or None.\n\n    Returns\n    -------\n    np.ndarray\n        Filtered signal (valid part only).\n    \"\"\"\n    x = np.asarray(sig, dtype=float)\n\n    if algorithm == \"enhanced\":\n        x = _detrend(x, window, detrend)\n        kind = \"exponential\"\n    elif algorithm == \"simple\":\n        kind = \"uniform\"\n    elif algorithm == \"gaussian\":\n        kind = \"gaussian\"\n    elif algorithm == \"exp\":\n        kind = \"exponential\"\n    else:\n        kind = algorithm  # assume a valid weighting name\n\n    return _smooth(x, window, kind)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4128), Performs well on output_length (91.0000), Performs well on overall_score (0.2880), Performs well on slope_changes (155.0000), Performs well on lag_error (0.3554), Performs well on avg_error (0.9565), Performs well on false_reversals (124.2000), Performs well on correlation (-0.0061), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.1143), Performs well on responsiveness_score (0.7378), Performs well on accuracy_score (0.0000), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0005), Performs well on success_rate (1.0000)\n\n### Program 3 (Score: 23.5037)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _check_len(x, w):\n    if len(x) < w:\n        raise ValueError(f\"Signal length ({len(x)}) < window ({w})\")\n\ndef _weights(w, kind):\n    if kind == \"gaussian\":\n        sigma = w / 6.0\n        t = np.arange(w) - (w - 1) / 2\n        wts = np.exp(-0.5 * (t / sigma) ** 2)\n    elif kind == \"exponential\":\n        wts = np.exp(np.linspace(-2, 0, w))\n    else:  # uniform\n        wts = np.ones(w)\n    return wts / wts.sum()\n\ndef _smooth(x, w, kind):\n    _check_len(x, w)\n    return np.convolve(x, _weights(w, kind), mode=\"valid\")\n\ndef _detrend_ma(x, tw):\n    if tw <= 0 or len(x) < tw:\n        return x\n    trend = np.convolve(x, np.ones(tw) / tw, mode=\"same\")\n    return x - trend\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Parameters\n    ----------\n    input_signal : array\u2011like\n        Raw 1\u2011D signal.\n    window_size : int, optional\n        Length of the smoothing window (default 20).\n    algorithm_type : str, optional\n        \"enhanced\" \u2013 detrend + exponential,\n        \"simple\"   \u2013 uniform moving average,\n        \"gaussian\" \u2013 Gaussian weighted average,\n        \"exp\"      \u2013 exponential weighted average,\n        any other value is treated as a weighting kind.\n\n    Returns\n    -------\n    np.ndarray\n        Filtered signal (valid part only).\n    \"\"\"\n    x = np.asarray(input_signal, dtype=float)\n\n    if algorithm_type == \"enhanced\":\n        x = _detrend_ma(x, window_size)\n        kind = \"exponential\"\n    elif algorithm_type == \"simple\":\n        kind = \"uniform\"\n    elif algorithm_type == \"gaussian\":\n        kind = \"gaussian\"\n    elif algorithm_type == \"exp\":\n        kind = \"exponential\"\n    else:\n        kind = algorithm_type  # assume a valid weighting name\n\n    return _smooth(x, window_size, kind)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4128), Performs well on output_length (91.0000), Performs well on overall_score (0.2880), Performs well on slope_changes (155.0000), Performs well on lag_error (0.3554), Performs well on avg_error (0.9565), Performs well on false_reversals (124.2000), Performs well on correlation (-0.0061), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.1143), Performs well on responsiveness_score (0.7378), Performs well on accuracy_score (0.0000), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0005), Performs well on success_rate (1.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 13.5069)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _weights(window: int, kind: str) -> np.ndarray:\n    \"\"\"Return normalized weighting vector.\"\"\"\n    if kind == \"gaussian\":\n        sigma = window / 6.0\n        t = np.arange(window) - (window - 1) / 2\n        w = np.exp(-0.5 * (t / sigma) ** 2)\n    elif kind == \"exponential\":\n        w = np.exp(np.linspace(-2, 0, window))\n    else:  # uniform\n        w = np.ones(window)\n    return w / w.sum()\n\n\ndef _smooth(signal: np.ndarray, window: int, kind: str) -> np.ndarray:\n    \"\"\"Convolve signal with chosen weighting; return the \u201cvalid\u201d part.\"\"\"\n    if len(signal) < window:\n        raise ValueError(f\"Signal length ({len(signal)}) < window ({window})\")\n    return np.convolve(signal, _weights(window, kind), mode=\"valid\")\n\n\ndef _detrend_linear(signal: np.ndarray) -> np.ndarray:\n    \"\"\"Remove a linear trend using least\u2011squares fit.\"\"\"\n    if len(signal) < 2:\n        return signal\n    t = np.arange(len(signal))\n    coeff = np.polyfit(t, signal, 1)\n    trend = np.polyval(coeff, t)\n    return signal - trend\n\n\ndef process_signal(\n    input_signal,\n    window_size: int = 20,\n    algorithm_type: str = \"enhanced\",\n) -> np.ndarray:\n    \"\"\"\n    Filter a 1\u2011D signal.\n\n    Parameters\n    ----------\n    input_signal : array\u2011like\n        Raw signal.\n    window_size : int, optional\n        Length of the smoothing window (default 20).\n    algorithm_type : str, optional\n        \"enhanced\" \u2013 linear detrend + exponential weighting,\n        \"simple\"   \u2013 uniform moving average,\n        \"gaussian\" \u2013 Gaussian weighting,\n        \"exp\"      \u2013 exponential weighting,\n        any other value is interpreted as a weighting kind.\n\n    Returns\n    -------\n    np.ndarray\n        Filtered signal (valid part only).\n    \"\"\"\n    x = np.asarray(input_signal, dtype=float)\n\n    kind_map = {\n        \"enhanced\": \"exponential\",\n        \"simple\": \"uniform\",\n        \"gaussian\": \"gaussian\",\n        \"exp\": \"exponential\",\n    }\n\n    if algorithm_type == \"enhanced\":\n        x = _detrend_linear(x)\n        kind = kind_map[\"enhanced\"]\n    else:\n        kind = kind_map.get(algorithm_type, algorithm_type)\n\n    return _smooth(x, window_size, kind)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to composite_score\n\n### Program D2 (Score: 13.5069)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _check_len(x, w):\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if len(x) < w:\n        raise ValueError(f\"Signal length ({len(x)}) < window ({w})\")\n\ndef _weights(w, kind):\n    if kind == \"gaussian\":\n        sigma = w / 6.0\n        t = np.arange(w) - (w - 1) / 2\n        wts = np.exp(-0.5 * (t / sigma) ** 2)\n    elif kind == \"exponential\":\n        wts = np.exp(np.linspace(-2, 0, w))\n    elif kind == \"triangular\":\n        wts = 1 - np.abs((np.arange(w) - (w - 1) / 2) / ((w + 1) / 2))\n    else:  # uniform\n        wts = np.ones(w)\n    return wts / wts.sum()\n\ndef _smooth(x, w, kind):\n    _check_len(x, w)\n    return np.convolve(x, _weights(w, kind), mode=\"valid\")\n\ndef _detrend_linear(x):\n    n = len(x)\n    if n < 2:\n        return x\n    t = np.arange(n)\n    A = np.vstack([t, np.ones(n)]).T\n    m, c = np.linalg.lstsq(A, x, rcond=None)[0]\n    return x - (m * t + c)\n\ndef _detrend_ma(x, tw):\n    if tw <= 0 or len(x) < tw:\n        return x\n    trend = np.convolve(x, np.ones(tw) / tw, mode=\"same\")\n    return x - trend\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\", detrend=\"linear\"):\n    \"\"\"\n    Filter a 1\u2011D signal.\n\n    Parameters\n    ----------\n    input_signal : array\u2011like\n        Raw signal.\n    window_size : int, default 20\n        Length of the smoothing window.\n    algorithm_type : str, default \"enhanced\"\n        Weighting scheme: \"enhanced\", \"simple\", \"gaussian\",\n        \"exp\", \"triangular\" or any custom name handled by _weights.\n    detrend : str, default \"linear\"\n        Detrending method: \"linear\", \"ma\" or None.\n\n    Returns\n    -------\n    np.ndarray\n        Smoothed signal (valid part only).\n    \"\"\"\n    x = np.asarray(input_signal, dtype=float)\n\n    # Detrending\n    if detrend == \"linear\":\n        x = _detrend_linear(x)\n    elif detrend == \"ma\":\n        x = _detrend_ma(x, window_size)\n\n    # Choose weighting\n    if algorithm_type == \"enhanced\":\n        kind = \"exponential\"\n    elif algorithm_type == \"simple\":\n        kind = \"uniform\"\n    elif algorithm_type == \"gaussian\":\n        kind = \"gaussian\"\n    elif algorithm_type in (\"exp\", \"exponential\"):\n        kind = \"exponential\"\n    elif algorithm_type == \"triangular\":\n        kind = \"triangular\"\n    else:\n        kind = algorithm_type  # assume valid weighting name\n\n    return _smooth(x, window_size, kind)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to composite_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 23.5037, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\ndef _w(w,k):\n    if k==\"gaussian\":\n        t=np.arange(w)-(w-1)/2; s=w/6.; wts=np.exp(-0.5*(t/s)**2)\n    elif k==\"exponential\":\n        wts=np.exp(np.linspace(-2,0,w))\n    elif k==\"triangular\":\n        t=np.arange(w)-(w-1)/2; wts=1-abs(t)/((w+1)/2)\n    else:\n        wts=np.ones(w)\n    return wts/wts.sum()\ndef _s(x,w,k):\n    if len(x)<w: raise ValueError\n    return np.convolve(x,_w(w,k),mode=\"valid\")\ndef _d(x,w,m):\n    if m==\"linear\" and len(x)>1:\n        t=np.arange(len(x)); a,b=np.linalg.lstsq(np.vstack([t,np.ones_like(t)]).T,x,rcond=None)[0]\n        return x-(a*t+b)\n    if m==\"ma\" and w>0:\n        return x-np.convolve(x,np.ones(w)/w,mode=\"same\")\n    return x\ndef process_signal(sig,window=20,algorithm=\"enhanced\",detrend=\"ma\"):\n    x=np.asarray(sig,float)\n    if algorithm==\"enhanced\":\n        x=_d(x,window,detrend); k=\"exponential\"\n    elif algorithm==\"simple\": k=\"uniform\"\n    elif algorithm==\"gaussian\": k=\"gaussian\"\n    elif algorithm==\"triangular\": k=\"triangular\"\n    else: k=algorithm\n    return _s(x,window,k)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (91.000)\n\n### Inspiration 2 (Score: 13.5069, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _check_len(x, w):\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if len(x) < w:\n        raise ValueError(f\"Signal length ({len(x)}) < window ({w})\")\n\ndef _weights(w, kind):\n    if kind == \"gaussian\":\n        sigma = w / 6.0\n        t = np.arange(w) - (w - 1) / 2\n        wts = np.exp(-0.5 * (t / sigma) ** 2)\n    elif kind == \"exponential\":\n        wts = np.exp(np.linspace(-2, 0, w))\n    elif kind == \"triangular\":\n        wts = 1 - np.abs((np.arange(w) - (w - 1) / 2) / ((w + 1) / 2))\n    else:  # uniform\n        wts = np.ones(w)\n    return wts / wts.sum()\n\ndef _smooth(x, w, kind):\n    _check_len(x, w)\n    return np.convolve(x, _weights(w, kind), mode=\"valid\")\n\ndef _detrend_linear(x):\n    n = len(x)\n    if n < 2:\n        return x\n    t = np.arange(n)\n    A = np.vstack([t, np.ones(n)]).T\n    m, c = np.linalg.lstsq(A, x, rcond=None)[0]\n    return x - (m * t + c)\n\ndef _detrend_ma(x, tw):\n    if tw <= 0 or len(x) < tw:\n        return x\n    trend = np.convolve(x, np.ones(tw) / tw, mode=\"same\")\n    return x - trend\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\", detrend=\"linear\"):\n    \"\"\"\n    Filter a 1\u2011D signal.\n\n    Parameters\n    ----------\n    input_signal : array\u2011like\n        Raw signal.\n    window_size : int, default 20\n        Length of the smoothing window.\n    algorithm_type : str, default \"enhanced\"\n        Weighting scheme: \"enhanced\", \"simple\", \"gaussian\",\n        \"exp\", \"triangular\" or any custom name handled by _weights.\n    detrend : str, default \"linear\"\n        Detrending method: \"linear\", \"ma\" or None.\n\n    Returns\n    -------\n    np.ndarray\n        Smoothed signal (valid part only).\n    \"\"\"\n    x = np.asarray(input_signal, dtype=float)\n\n    # Detrending\n    if detrend == \"linear\":\n        x = _detrend_linear(x)\n    elif detrend == \"ma\":\n        x = _detrend_ma(x, window_size)\n\n    # Choose weighting\n    if algorithm_type == \"enhanced\":\n        kind = \"exponential\"\n    elif algorithm_type == \"simple\":\n        kind = \"uniform\"\n    elif algorithm_type == \"gaussian\":\n        kind = \"gaussian\"\n    elif algorithm_type in (\"exp\", \"exponential\"):\n        kind = \"exponential\"\n    elif algorithm_type == \"triangular\":\n        kind = \"triangular\"\n    else:\n        kind = algorithm_type  # assume valid weighting name\n\n    return _smooth(x, window_size, kind)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (91.000)\n\n### Inspiration 3 (Score: 0.0000, Type: Exploratory)\n```python\n# EVOLVE-BLOCK-START\ndef _weights(w, kind):\n    t = np.arange(w) - (w - 1) / 2\n    if kind == \"gaussian\":\n        s = w / 6.0\n        wts = np.exp(-0.5 * (t / s) ** 2)\n    elif kind == \"exponential\":\n        wts = np.exp(np.linspace(-2, 0, w))\n    elif kind == \"triangular\":\n        wts = 1 - np.abs(t) / ((w + 1) / 2)\n    else:\n        wts = np.ones(w)\n    return wts / wts.sum()\n\n\ndef _detrend(x, mode):\n    if mode == \"linear\" and len(x) > 1:\n        t = np.arange(len(x))\n        m, c = np.linalg.lstsq(np.vstack([t, np.ones_like(t)]).T, x, rcond=None)[0]\n        return x - (m * t + c)\n    if mode == \"ma\" and len(x) > 0:\n        w = max(1, len(x) // 10)\n        return x - np.convolve(x, np.ones(w) / w, mode=\"same\")\n    return x\n\n\ndef process_signal(sig, window=20, algorithm_type=\"enhanced\", detrend=\"linear\", passes=1):\n    x = np.asarray(sig, dtype=float)\n    x = _detrend(x, detrend)\n\n    kind = {\n        \"enhanced\": \"exponential\",\n        \"simple\": \"uniform\",\n        \"gaussian\": \"gaussian\",\n        \"exp\": \"exponential\",\n        \"triangular\": \"triangular\",\n    }.get(algorithm_type, algorithm_type)\n\n    if algorithm_type == \"adaptive\":\n        w = max(1, int(window * (1 + np.tanh(np.var(x)))))\n    else:\n        w = window\n\n    for _ in range(max(1, passes)):\n        x = np.convolve(x, _weights(w, kind), mode=\"valid\")\n    return x\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Alternative runs_successfully approach, NumPy-based implementation\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _check_len(x, w):\n    if w <= 0:\n        raise ValueError(\"window must be >0\")\n    if len(x) < w:\n        raise ValueError(f\"len(x)={len(x)} < w={w}\")\n\ndef _weights(w, kind):\n    t = np.arange(w) - (w - 1) / 2\n    if kind == \"gaussian\":\n        sigma = w / 6.0\n        wts = np.exp(-0.5 * (t / sigma) ** 2)\n    elif kind == \"exponential\":\n        wts = np.exp(np.linspace(-2, 0, w))\n    elif kind == \"triangular\":\n        wts = 1 - np.abs(t) / ((w + 1) / 2)\n    else:  # uniform\n        wts = np.ones(w)\n    return wts / wts.sum()\n\ndef _smooth(x, w, kind):\n    _check_len(x, w)\n    return np.convolve(x, _weights(w, kind), mode=\"valid\")\n\ndef _median_filter(x, w):\n    _check_len(x, w)\n    shape = (len(x) - w + 1, w)\n    strides = (x.strides[0], x.strides[0])\n    windows = np.lib.stride_tricks.as_strided(x, shape=shape, strides=strides)\n    return np.median(windows, axis=1)\n\ndef _detrend_linear(x):\n    n = len(x)\n    if n < 2:\n        return x\n    t = np.arange(n)\n    A = np.vstack([t, np.ones(n)]).T\n    m, c = np.linalg.lstsq(A, x, rcond=None)[0]\n    return x - (m * t + c)\n\ndef _detrend_ma(x, w):\n    if w <= 0 or len(x) < w:\n        return x\n    trend = np.convolve(x, np.ones(w) / w, mode=\"same\")\n    return x - trend\n\ndef _auto_window(x, base):\n    # increase window if variance is high\n    var = np.var(x)\n    return int(base * (1 + np.tanh(var)))\n\ndef process_signal(sig, window=20, algo=\"enhanced\", detrend=\"linear\"):\n    \"\"\"\n    Parameters\n    ----------\n    sig : array\u2011like\n        Raw 1\u2011D signal.\n    window : int, default 20\n        Base smoothing window.\n    algo : str, default \"enhanced\"\n        \"enhanced\", \"simple\", \"gaussian\", \"exp\", \"triangular\",\n        \"median\" or any custom weighting name.\n    detrend : str, default \"linear\"\n        \"linear\", \"ma\" or None.\n    \"\"\"\n    x = np.asarray(sig, dtype=float)\n\n    # adaptive window based on signal variance\n    w = max(1, _auto_window(x, window))\n\n    # detrending\n    if detrend == \"linear\":\n        x = _detrend_linear(x)\n    elif detrend == \"ma\":\n        x = _detrend_ma(x, w)\n\n    # filtering\n    if algo == \"enhanced\":\n        kind = \"exponential\"\n        return _smooth(x, w, kind)\n    if algo == \"simple\":\n        return _smooth(x, w, \"uniform\")\n    if algo == \"median\":\n        return _median_filter(x, w)\n    if algo in (\"gaussian\", \"exp\", \"exponential\", \"triangular\"):\n        kind = {\"gaussian\": \"gaussian\",\n                \"exp\": \"exponential\",\n                \"exponential\": \"exponential\",\n                \"triangular\": \"triangular\"}[algo]\n        return _smooth(x, w, kind)\n    # fallback to custom weighting\n    return _smooth(x, w, algo)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\n\n# Task\nImprove the code to maximize FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\n\n## CRITICAL INSTRUCTIONS\nIf the code contains `# EVOLVE-BLOCK-START` and `# EVOLVE-BLOCK-END` markers:\n- Output ONLY the code that goes BETWEEN these markers\n- Do NOT include the markers themselves\n- Do NOT include code outside the markers (like `run_packing()`)\n- The system will automatically merge your output with the preserved sections\n\nIf there are NO EVOLVE-BLOCK markers:\n- Output the complete rewritten program\n\n```python\n# Your improved code here (ONLY the evolve block content if markers exist)\n```", "responses": ["import numpy as np\n\ndef _weights(w, kind):\n    t = np.arange(w) - (w - 1) / 2\n    if kind == \"gaussian\":\n        s = w / 6.0\n        wts = np.exp(-0.5 * (t / s) ** 2)\n    elif kind == \"exponential\":\n        wts = np.exp(np.linspace(-2, 0, w))\n    elif kind == \"triangular\":\n        wts = 1 - np.abs(t) / ((w + 1) / 2)\n    else:  # uniform / fallback\n        wts = np.ones(w)\n    return wts / wts.sum()\n\ndef _smooth(x, w, kind):\n    if len(x) < w:\n        raise ValueError(\"signal shorter than window\")\n    return np.convolve(x, _weights(w, kind), mode=\"valid\")\n\ndef _median(x, w):\n    if len(x) < w:\n        raise ValueError(\"signal shorter than window\")\n    shape = (len(x) - w + 1, w)\n    strides = (x.strides[0], x.strides[0])\n    win = np.lib.stride_tricks.as_strided(x, shape=shape, strides=strides)\n    return np.median(win, axis=1)\n\ndef _detrend_linear(x):\n    n = len(x)\n    if n < 2:\n        return x\n    t = np.arange(n)\n    m, c = np.linalg.lstsq(np.vstack([t, np.ones(n)]).T, x, rcond=None)[0]\n    return x - (m * t + c)\n\ndef _detrend_ma(x, w):\n    if w <= 0 or len(x) < w:\n        return x\n    trend = np.convolve(x, np.ones(w) / w, mode=\"same\")\n    return x - trend\n\ndef process_signal(sig, window=20, algo=\"enhanced\", detrend=\"linear\"):\n    x = np.asarray(sig, dtype=float)\n\n    if detrend == \"linear\":\n        x = _detrend_linear(x)\n    elif detrend == \"ma\":\n        x = _detrend_ma(x, window)\n\n    if algo == \"enhanced\":\n        return _smooth(x, window, \"exponential\")\n    if algo == \"simple\":\n        return _smooth(x, window, \"uniform\")\n    if algo == \"median\":\n        return _median(x, window)\n    if algo in (\"gaussian\", \"triangular\", \"exponential\"):\n        kind = \"exponential\" if algo == \"exponential\" else algo\n        return _smooth(x, window, kind)\n\n    # custom weighting name\n    return _smooth(x, window, algo)"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}