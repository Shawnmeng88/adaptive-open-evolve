{"id": "9f23a63b-e8eb-4afd-ba57-e373cc580da8", "code": "# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _kernel(w, kind):\n    t = np.arange(w) - (w - 1) / 2\n    if kind == \"gaussian\":\n        s = w / 6.0\n        k = np.exp(-0.5 * (t / s) ** 2)\n    elif kind == \"exponential\":\n        k = np.exp(np.linspace(-2, 0, w))\n    elif kind == \"triangular\":\n        k = 1 - np.abs(t) / ((w + 1) / 2)\n    else:\n        k = np.ones(w)\n    return k / k.sum()\n\ndef _median(x, w):\n    view = np.lib.stride_tricks.sliding_window_view(x, w)\n    return np.median(view, axis=1)\n\ndef _detrend(x, w, method):\n    if method == \"median\":\n        m = _median(x, w)\n        pad = (len(x) - len(m)) // 2\n        trend = np.pad(m, (pad, len(x) - len(m) - pad), mode=\"edge\")\n    else:\n        trend = np.convolve(x, np.ones(w) / w, mode=\"same\")\n    return x - trend\n\ndef process_signal(sig, window=20, algorithm=\"enhanced\", passes=1, detrend_factor=5):\n    x = np.asarray(sig, float)\n    dw = window * detrend_factor if algorithm in (\"enhanced\", \"robust\") else window\n\n    if algorithm == \"enhanced\":\n        x = _detrend(x, dw, \"mean\")\n        kind = \"exponential\"\n    elif algorithm == \"robust\":\n        x = _detrend(x, dw, \"median\")\n        kind = \"exponential\"\n    elif algorithm == \"simple\":\n        kind = \"uniform\"\n    elif algorithm == \"gaussian\":\n        kind = \"gaussian\"\n    elif algorithm == \"triangular\":\n        kind = \"triangular\"\n    elif algorithm in (\"exp\", \"exponential\"):\n        kind = \"exponential\"\n    elif algorithm == \"median\":\n        return _median(x, window)\n    else:\n        kind = algorithm\n\n    for _ in range(passes):\n        x = _median(x, window) if kind == \"median\" else np.convolve(x, _kernel(window, kind), mode=\"same\")\n    return x\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n", "language": "python", "parent_id": "1f2bbcf1-b683-43b8-8df3-a13da657938b", "generation": 8, "timestamp": 1764932912.372824, "iteration_found": 350, "metrics": {"runs_successfully": 1.0, "composite_score": 0.42022818718489957, "output_length": 91.0, "overall_score": 0.33712338245184104, "slope_changes": 69.2, "lag_error": 0.758217527873353, "avg_error": 1.2330281826459721, "false_reversals": 56.0, "correlation": 0.1209452912526349, "noise_reduction": 0.0, "smoothness_score": 0.2242152466367713, "responsiveness_score": 0.5687578380642964, "accuracy_score": 0.1209452912526349, "efficiency_score": 1.0, "execution_time": 0.0005466461181640625, "success_rate": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Evolve block rewrite (preserved external code)", "parent_metrics": {"runs_successfully": 1.0, "composite_score": 0.4095431414698137, "output_length": 91.0, "overall_score": 0.31113303303002066, "slope_changes": 153.4, "lag_error": 0.47341340542714, "avg_error": 0.928013591646535, "false_reversals": 125.6, "correlation": 0.12123862846191749, "noise_reduction": 0.0, "smoothness_score": 0.11534025374855825, "responsiveness_score": 0.6786961461845135, "accuracy_score": 0.12123862846191749, "efficiency_score": 1.0, "execution_time": 0.0005266666412353516, "success_rate": 1.0}, "island": 1}, "prompts": {"full_rewrite_user": {"system": "You are an expert software developer tasked with iteratively improving a codebase.\nYour goal is to maximize the FITNESS SCORE while exploring diverse solutions across feature dimensions.\nThe system maintains a collection of diverse programs - both high fitness AND diversity are valuable.", "user": "# Current Program Information\n- Fitness: 23.5099\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness declined: 23.5099 \u2192 23.5099. Consider revising recent changes.\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4095, output_length: 91.0000, overall_score: 0.3111, slope_changes: 153.4000, lag_error: 0.4734, avg_error: 0.9280, false_reversals: 125.6000, correlation: 0.1212, noise_reduction: 0.0000, smoothness_score: 0.1153, responsiveness_score: 0.6787, accuracy_score: 0.1212, efficiency_score: 1.0000, execution_time: 0.0005, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4095, output_length: 91.0000, overall_score: 0.3111, slope_changes: 153.4000, lag_error: 0.4734, avg_error: 0.9280, false_reversals: 125.6000, correlation: 0.1212, noise_reduction: 0.0000, smoothness_score: 0.1153, responsiveness_score: 0.6787, accuracy_score: 0.1212, efficiency_score: 1.0000, execution_time: 0.0006, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4095, output_length: 91.0000, overall_score: 0.3111, slope_changes: 153.4000, lag_error: 0.4734, avg_error: 0.9280, false_reversals: 125.6000, correlation: 0.1212, noise_reduction: 0.0000, smoothness_score: 0.1153, responsiveness_score: 0.6787, accuracy_score: 0.1212, efficiency_score: 1.0000, execution_time: 0.0006, success_rate: 1.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 23.5100)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _kernel(w,k):\n    t=np.arange(w)-(w-1)/2\n    if k==\"gaussian\":\n        s=w/6.;k=np.exp(-.5*(t/s)**2)\n    elif k==\"exponential\":\n        k=np.exp(np.linspace(-2,0,w))\n    elif k==\"triangular\":\n        k=1-np.abs(t)/((w+1)/2)\n    else:\n        k=np.ones(w)\n    return k/k.sum()\n\ndef _median(x,w):\n    if len(x)<w:return x\n    v=np.lib.stride_tricks.sliding_window_view(x,w)\n    return np.median(v,axis=1)\n\ndef _smooth(x,w,k,passes):\n    for _ in range(passes):\n        if k==\"median\":\n            x=_median(x,w)\n        else:\n            x=np.convolve(x,_kernel(w,k),mode=\"same\")\n    return x\n\ndef _detrend(x,w,method):\n    if method==\"median\":\n        m=_median(x,w)\n        p=(len(x)-len(m))//2\n        trend=np.pad(m,(p,len(x)-len(m)-p),mode=\"edge\")\n    else:\n        trend=np.convolve(x,np.ones(w)/w,mode=\"same\")\n    return x-trend\n\ndef process_signal(sig,window=20,algo=\"enhanced\",passes=1):\n    x=np.asarray(sig,float)\n    if algo==\"enhanced\":\n        x=_detrend(x,window,\"mean\");k=\"exponential\"\n    elif algo==\"robust\":\n        x=_detrend(x,window,\"median\");k=\"exponential\"\n    elif algo==\"simple\":\n        k=\"uniform\"\n    elif algo==\"median\":\n        k=\"median\"\n    elif algo in (\"gaussian\",\"triangular\",\"exponential\",\"exp\"):\n        k=algo\n    else:\n        k=algo\n    return _smooth(x,window,k,passes)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4095), Performs well on output_length (91.0000), Performs well on overall_score (0.3111), Performs well on slope_changes (153.4000), Performs well on lag_error (0.4734), Performs well on avg_error (0.9280), Performs well on false_reversals (125.6000), Performs well on correlation (0.1212), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.1153), Performs well on responsiveness_score (0.6787), Performs well on accuracy_score (0.1212), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0006), Performs well on success_rate (1.0000)\n\n### Program 2 (Score: 23.5099)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _weights(w, kind):\n    if kind == \"gaussian\":\n        sigma = w / 6.0\n        t = np.arange(w) - (w - 1) / 2\n        wts = np.exp(-0.5 * (t / sigma) ** 2)\n    elif kind == \"exponential\":\n        wts = np.exp(np.linspace(-2, 0, w))\n    else:\n        wts = np.ones(w)\n    return wts / wts.sum()\n\n\ndef _smooth(x, w, kind, passes=1):\n    \"\"\"Apply smoothing (same\u2011length output).\"\"\"\n    def _median(y):\n        pad = w // 2\n        y_pad = np.pad(y, (pad, pad), mode=\"edge\")\n        view = np.lib.stride_tricks.sliding_window_view(y_pad, w)\n        return np.median(view, axis=1)\n\n    if kind == \"median\":\n        y = _median(x)\n    else:\n        wts = _weights(w, kind)\n        y = np.convolve(x, wts, mode=\"same\")\n    for _ in range(passes - 1):\n        if kind == \"median\":\n            y = _median(y)\n        else:\n            y = np.convolve(y, _weights(w, kind), mode=\"same\")\n    return y\n\n\ndef _detrend(x, w, method):\n    \"\"\"Remove trend using mean or median.\"\"\"\n    if method == \"median\":\n        pad = w // 2\n        x_pad = np.pad(x, (pad, pad), mode=\"edge\")\n        view = np.lib.stride_tricks.sliding_window_view(x_pad, w)\n        trend = np.median(view, axis=1)\n    else:  # mean\n        trend = np.convolve(x, np.ones(w) / w, mode=\"same\")\n    return x - trend\n\n\ndef process_signal(sig, window_size=20, algorithm_type=\"enhanced\", passes=1):\n    \"\"\"\n    Parameters\n    ----------\n    sig : array\u2011like\n        Raw 1\u2011D signal.\n    window_size : int, optional\n        Length of the smoothing window (default 20).\n    algorithm_type : str, optional\n        \"enhanced\" \u2013 mean detrend + exponential,\n        \"robust\"   \u2013 median detrend + exponential,\n        \"simple\"   \u2013 uniform moving average,\n        \"gaussian\" \u2013 Gaussian weighted average,\n        \"median\"   \u2013 median filter,\n        \"exp\"/\"exponential\" \u2013 exponential weighted average,\n        any other value is taken as a weighting kind.\n    passes : int, optional\n        Number of smoothing passes (default 1).\n    \"\"\"\n    x = np.asarray(sig, dtype=float)\n\n    if algorithm_type == \"enhanced\":\n        x = _detrend(x, window_size, \"mean\")\n        kind = \"exponential\"\n    elif algorithm_type == \"robust\":\n        x = _detrend(x, window_size, \"median\")\n        kind = \"exponential\"\n    elif algorithm_type == \"simple\":\n        kind = \"uniform\"\n    elif algorithm_type == \"gaussian\":\n        kind = \"gaussian\"\n    elif algorithm_type in (\"exp\", \"exponential\"):\n        kind = \"exponential\"\n    elif algorithm_type == \"median\":\n        kind = \"median\"\n    else:\n        kind = algorithm_type\n\n    return _smooth(x, window_size, kind, passes)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4095), Performs well on output_length (91.0000), Performs well on overall_score (0.3111), Performs well on slope_changes (153.4000), Performs well on lag_error (0.4734), Performs well on avg_error (0.9280), Performs well on false_reversals (125.6000), Performs well on correlation (0.1212), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.1153), Performs well on responsiveness_score (0.6787), Performs well on accuracy_score (0.1212), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0006), Performs well on success_rate (1.0000)\n\n### Program 3 (Score: 23.5099)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _weights(w, kind):\n    \"\"\"Generate normalized weighting kernel.\"\"\"\n    if kind == \"gaussian\":\n        sigma = w / 6.0\n        t = np.arange(w) - (w - 1) / 2\n        wts = np.exp(-0.5 * (t / sigma) ** 2)\n    elif kind == \"exponential\":\n        wts = np.exp(np.linspace(-2, 0, w))\n    else:\n        wts = np.ones(w)\n    return wts / wts.sum()\n\n\ndef _median_filter(x, w):\n    \"\"\"Median filter with edge padding.\"\"\"\n    pad = w // 2\n    xpad = np.pad(x, (pad, pad), mode=\"edge\")\n    view = np.lib.stride_tricks.sliding_window_view(xpad, w)\n    return np.median(view, axis=1)\n\n\ndef _detrend(x, w, method):\n    \"\"\"Remove trend using mean or median.\"\"\"\n    if w <= 0 or len(x) < w:\n        return x\n    if method == \"median\":\n        trend = _median_filter(x, w)\n    else:\n        trend = np.convolve(x, np.ones(w) / w, mode=\"same\")\n    return x - trend\n\n\ndef _smooth(x, w, kind, passes):\n    \"\"\"Apply smoothing kernel or median filter repeatedly.\"\"\"\n    for _ in range(passes):\n        if kind == \"median\":\n            x = _median_filter(x, w)\n        else:\n            x = np.convolve(x, _weights(w, kind), mode=\"same\")\n    return x\n\n\ndef process_signal(\n    sig,\n    window_size=20,\n    algorithm_type=\"enhanced\",\n    passes=1,\n    detrend=False,\n    detrend_method=\"mean\",\n):\n    \"\"\"High\u2011level signal processing entry point.\"\"\"\n    x = np.asarray(sig, dtype=float)\n\n    # Choose processing mode\n    if algorithm_type == \"enhanced\":\n        detrend, detrend_method, kind = True, \"mean\", \"exponential\"\n    elif algorithm_type == \"robust\":\n        detrend, detrend_method, kind = True, \"median\", \"exponential\"\n    elif algorithm_type == \"simple\":\n        kind = \"uniform\"\n    elif algorithm_type == \"gaussian\":\n        kind = \"gaussian\"\n    elif algorithm_type in (\"exp\", \"exponential\"):\n        kind = \"exponential\"\n    elif algorithm_type == \"median\":\n        kind = \"median\"\n    else:\n        kind = algorithm_type\n\n    if detrend:\n        x = _detrend(x, window_size, detrend_method)\n\n    return _smooth(x, window_size, kind, passes)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4095), Performs well on output_length (91.0000), Performs well on overall_score (0.3111), Performs well on slope_changes (153.4000), Performs well on lag_error (0.4734), Performs well on avg_error (0.9280), Performs well on false_reversals (125.6000), Performs well on correlation (0.1212), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.1153), Performs well on responsiveness_score (0.6787), Performs well on accuracy_score (0.1212), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0005), Performs well on success_rate (1.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 23.5099)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _weights(w, kind):\n    if kind == \"gaussian\":\n        sigma = w / 6.0\n        t = np.arange(w) - (w - 1) / 2\n        wts = np.exp(-0.5 * (t / sigma) ** 2)\n    elif kind == \"exponential\":\n        wts = np.exp(np.linspace(-2, 0, w))\n    else:\n        wts = np.ones(w)\n    return wts / wts.sum()\n\n\ndef _median(x, w):\n    pad = w // 2\n    xv = np.pad(x, (pad, pad), mode=\"edge\")\n    view = np.lib.stride_tricks.sliding_window_view(xv, w)\n    return np.median(view, axis=1)\n\n\ndef _smooth(x, w, kind, passes):\n    for _ in range(passes):\n        if kind == \"median\":\n            x = _median(x, w)\n        else:\n            x = np.convolve(x, _weights(w, kind), mode=\"same\")\n    return x\n\n\ndef _detrend(x, w, method):\n    if method == \"median\":\n        return x - _median(x, w)\n    return x - np.convolve(x, np.ones(w) / w, mode=\"same\")\n\n\ndef process_signal(\n    sig,\n    window=20,\n    algorithm=\"enhanced\",\n    passes=1,\n    detrend_w=None,\n    det_method=\"mean\",\n):\n    x = np.asarray(sig, float)\n\n    if algorithm == \"enhanced\":\n        det, kind, det_method = True, \"exponential\", \"mean\"\n    elif algorithm == \"robust\":\n        det, kind, det_method = True, \"exponential\", \"median\"\n    elif algorithm == \"simple\":\n        det, kind = False, \"uniform\"\n    elif algorithm == \"gaussian\":\n        det, kind = False, \"gaussian\"\n    elif algorithm == \"median\":\n        det, kind = False, \"median\"\n    else:\n        det, kind = False, algorithm\n\n    if det:\n        w = detrend_w or window\n        x = _detrend(x, w, det_method)\n\n    return _smooth(x, window, kind, passes)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to composite_score\n\n### Program D2 (Score: 23.5099)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\ndef _kernel(w,k):\n    t=np.arange(w)-(w-1)/2\n    if k==\"gaussian\":\n        s=w/6.;k=np.exp(-.5*(t/s)**2)\n    elif k==\"exponential\":\n        k=np.exp(np.linspace(-2,0,w))\n    else:k=np.ones(w)\n    return k/k.sum()\ndef _median(x,w):\n    p=w//2;x=np.pad(x,(p,p),mode='edge')\n    return np.median(np.lib.stride_tricks.sliding_window_view(x,w),axis=1)\ndef _smooth(x,w,k,p):\n    for _ in range(p):\n        x=_median(x,w) if k==\"median\" else np.convolve(x,_kernel(w,k),mode='same')\n    return x\ndef _detrend(x,w,m):\n    return x-_median(x,w) if m==\"median\" else x-np.convolve(x,np.ones(w)/w,mode='same')\ndef process_signal(sig,window=20,algorithm='enhanced',passes=1,detrend_w=None,det_method='mean'):\n    x=np.asarray(sig,float)\n    det=False;kind='uniform'\n    if algorithm=='enhanced':\n        det,kind,det_method=True,'exponential','mean'\n    elif algorithm=='robust':\n        det,kind,det_method=True,'exponential','median'\n    elif algorithm=='simple':\n        det,kind=False,'uniform'\n    elif algorithm=='gaussian':\n        det,kind=False,'gaussian'\n    elif algorithm=='median':\n        det,kind=False,'median'\n    else:\n        det,kind=False,algorithm\n    if det:\n        w=detrend_w or window\n        x=_detrend(x,w,det_method)\n    return _smooth(x,window,kind,passes)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to composite_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 14.0992, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _weights(w, kind):\n    if kind == \"gaussian\":\n        s = w / 6.0\n        t = np.arange(w) - (w - 1) / 2\n        wts = np.exp(-0.5 * (t / s) ** 2)\n    elif kind == \"exponential\":\n        wts = np.exp(np.linspace(-2, 0, w))\n    else:\n        wts = np.ones(w)\n    return wts / wts.sum()\n\ndef _median_filter(x, w):\n    p = w // 2\n    xp = np.pad(x, (p, p), mode=\"edge\")\n    return np.array([np.median(xp[i:i + w]) for i in range(len(x) - w + 1)])\n\ndef _detrend(x, tw, method):\n    if tw <= 0 or len(x) < tw:\n        return x\n    if method == \"median\":\n        p = tw // 2\n        xp = np.pad(x, (p, p), mode=\"edge\")\n        trend = np.array([np.median(xp[i:i + tw]) for i in range(len(x))])\n    else:\n        trend = np.convolve(x, np.ones(tw) / tw, mode=\"same\")\n    return x - trend\n\ndef process_signal(sig, w=20, alg=\"enhanced\"):\n    x = np.asarray(sig, float)\n    if alg in (\"enhanced\", \"robust\"):\n        tw = max(5 * w, 1)\n        method = \"mean\" if alg == \"enhanced\" else \"median\"\n        x = _detrend(x, tw, method)\n        kind = \"exponential\"\n    elif alg == \"simple\":\n        kind = \"uniform\"\n    elif alg == \"gaussian\":\n        kind = \"gaussian\"\n    elif alg in (\"exp\", \"exponential\"):\n        kind = \"exponential\"\n    elif alg == \"median\":\n        kind = \"median\"\n    else:\n        kind = alg\n    if kind == \"median\":\n        return _median_filter(x, w)\n    return np.convolve(x, _weights(w, kind), mode=\"valid\")\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (91.000)\n\n### Inspiration 2 (Score: 23.5099, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _kernel(w, kind):\n    t = np.arange(w) - (w - 1) / 2\n    if kind == \"gaussian\":\n        s = w / 6.0\n        k = np.exp(-0.5 * (t / s) ** 2)\n    elif kind == \"exponential\":\n        k = np.exp(np.linspace(-2, 0, w))\n    else:  # uniform\n        k = np.ones(w)\n    return k / k.sum()\n\ndef _median(x, w):\n    pad = w // 2\n    xv = np.pad(x, (pad, pad), mode=\"edge\")\n    view = np.lib.stride_tricks.sliding_window_view(xv, w)\n    return np.median(view, axis=1)\n\ndef _detrend(x, w, method):\n    if method == \"median\":\n        m = _median(x, w)\n    else:  # mean\n        m = np.convolve(x, np.ones(w) / w, mode=\"same\")\n    return x - m\n\ndef _smooth(x, w, kind, passes):\n    for _ in range(passes):\n        if kind == \"median\":\n            x = _median(x, w)\n        else:\n            x = np.convolve(x, _kernel(w, kind), mode=\"same\")\n    return x\n\ndef process_signal(sig, window=20, algorithm=\"enhanced\", passes=1, detrend_window=None, detrend_method=\"mean\"):\n    x = np.asarray(sig, float)\n    dw = detrend_window if detrend_window is not None else window\n\n    if algorithm == \"enhanced\":\n        x = _detrend(x, dw, \"mean\")\n        kind = \"exponential\"\n    elif algorithm == \"robust\":\n        x = _detrend(x, dw, \"median\")\n        kind = \"exponential\"\n    elif algorithm == \"simple\":\n        kind = \"uniform\"\n    elif algorithm == \"gaussian\":\n        kind = \"gaussian\"\n    elif algorithm in (\"exp\", \"exponential\"):\n        kind = \"exponential\"\n    elif algorithm == \"median\":\n        return _median(x, window)\n    else:\n        kind = algorithm\n\n    return _smooth(x, window, kind, passes)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (91.000)\n\n### Inspiration 3 (Score: 14.0152, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _chk(x, w):\n    if len(x) < w:\n        raise ValueError(\"Signal shorter than window\")\n\ndef _weights(w, kind):\n    if kind == \"exponential\":\n        wts = np.exp(np.linspace(-2, 0, w))\n    elif kind == \"gaussian\":\n        sigma = w / 6.0\n        t = np.arange(w) - (w - 1) / 2\n        wts = np.exp(-0.5 * (t / sigma) ** 2)\n    else:  # uniform\n        wts = np.ones(w)\n    return wts / wts.sum()\n\ndef wma(x, w, kind=\"uniform\", mode=\"valid\"):\n    _chk(x, w)\n    return np.convolve(x, _weights(w, kind), mode=mode)\n\ndef process_signal(\n    sig,\n    window=20,\n    kind=\"exponential\",\n    detrend=False,\n    trend_w=200,\n    mode=\"valid\",\n):\n    sig = np.asarray(sig, float)\n    if detrend:\n        trend = np.convolve(sig, np.ones(trend_w) / trend_w, mode=\"same\")\n        sig -= trend\n    return wma(sig, window, kind, mode)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (91.000)\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _kernel(w, kind):\n    if kind == \"gaussian\":\n        s = w / 6.0\n        t = np.arange(w) - (w - 1) / 2\n        k = np.exp(-0.5 * (t / s) ** 2)\n    elif kind == \"exponential\":\n        k = np.exp(np.linspace(-2, 0, w))\n    elif kind == \"triangular\":\n        t = np.arange(w) - (w - 1) / 2\n        k = 1 - np.abs(t) / ((w + 1) / 2)\n    else:\n        k = np.ones(w)\n    return k / k.sum()\n\n\ndef _median(x, w):\n    view = np.lib.stride_tricks.sliding_window_view(x, w)\n    return np.median(view, axis=1)\n\n\ndef _detrend(x, w, method):\n    if w <= 0 or len(x) < w:\n        return x\n    if method == \"median\":\n        m = _median(x, w)\n        pad = (len(x) - len(m)) // 2\n        trend = np.pad(m, (pad, len(x) - len(m) - pad), mode=\"edge\")\n    else:\n        trend = np.convolve(x, np.ones(w) / w, mode=\"same\")\n    return x - trend\n\n\ndef process_signal(\n    sig,\n    window=20,\n    algorithm=\"enhanced\",\n    passes=1,\n    trend_w=None,\n    trend_m=\"mean\",\n):\n    x = np.asarray(sig, float)\n    if trend_w is None:\n        trend_w = window\n\n    # decide detrending and smoothing kind\n    if algorithm == \"enhanced\":\n        x = _detrend(x, trend_w, \"mean\")\n        kind = \"exponential\"\n    elif algorithm == \"robust\":\n        x = _detrend(x, trend_w, \"median\")\n        kind = \"exponential\"\n    elif algorithm == \"simple\":\n        kind = \"uniform\"\n    elif algorithm == \"gaussian\":\n        kind = \"gaussian\"\n    elif algorithm == \"triangular\":\n        kind = \"triangular\"\n    elif algorithm in (\"exp\", \"exponential\"):\n        kind = \"exponential\"\n    elif algorithm == \"median\":\n        return _median(x, window)\n    else:\n        kind = algorithm\n\n    # smoothing passes\n    for _ in range(passes):\n        if kind == \"median\":\n            x = _median(x, window)\n        else:\n            x = np.convolve(x, _kernel(window, kind), mode=\"same\")\n    return x\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\n\n# Task\nImprove the code to maximize FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\n\n## CRITICAL INSTRUCTIONS\nIf the code contains `# EVOLVE-BLOCK-START` and `# EVOLVE-BLOCK-END` markers:\n- Output ONLY the code that goes BETWEEN these markers\n- Do NOT include the markers themselves\n- Do NOT include code outside the markers (like `run_packing()`)\n- The system will automatically merge your output with the preserved sections\n\nIf there are NO EVOLVE-BLOCK markers:\n- Output the complete rewritten program\n\n```python\n# Your improved code here (ONLY the evolve block content if markers exist)\n```", "responses": ["import numpy as np\n\ndef _kernel(w, kind):\n    t = np.arange(w) - (w - 1) / 2\n    if kind == \"gaussian\":\n        s = w / 6.0\n        k = np.exp(-0.5 * (t / s) ** 2)\n    elif kind == \"exponential\":\n        k = np.exp(np.linspace(-2, 0, w))\n    elif kind == \"triangular\":\n        k = 1 - np.abs(t) / ((w + 1) / 2)\n    else:\n        k = np.ones(w)\n    return k / k.sum()\n\ndef _median(x, w):\n    view = np.lib.stride_tricks.sliding_window_view(x, w)\n    return np.median(view, axis=1)\n\ndef _detrend(x, w, method):\n    if method == \"median\":\n        m = _median(x, w)\n        pad = (len(x) - len(m)) // 2\n        trend = np.pad(m, (pad, len(x) - len(m) - pad), mode=\"edge\")\n    else:\n        trend = np.convolve(x, np.ones(w) / w, mode=\"same\")\n    return x - trend\n\ndef process_signal(sig, window=20, algorithm=\"enhanced\", passes=1, detrend_factor=5):\n    x = np.asarray(sig, float)\n    dw = window * detrend_factor if algorithm in (\"enhanced\", \"robust\") else window\n\n    if algorithm == \"enhanced\":\n        x = _detrend(x, dw, \"mean\")\n        kind = \"exponential\"\n    elif algorithm == \"robust\":\n        x = _detrend(x, dw, \"median\")\n        kind = \"exponential\"\n    elif algorithm == \"simple\":\n        kind = \"uniform\"\n    elif algorithm == \"gaussian\":\n        kind = \"gaussian\"\n    elif algorithm == \"triangular\":\n        kind = \"triangular\"\n    elif algorithm in (\"exp\", \"exponential\"):\n        kind = \"exponential\"\n    elif algorithm == \"median\":\n        return _median(x, window)\n    else:\n        kind = algorithm\n\n    for _ in range(passes):\n        x = _median(x, window) if kind == \"median\" else np.convolve(x, _kernel(window, kind), mode=\"same\")\n    return x"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}