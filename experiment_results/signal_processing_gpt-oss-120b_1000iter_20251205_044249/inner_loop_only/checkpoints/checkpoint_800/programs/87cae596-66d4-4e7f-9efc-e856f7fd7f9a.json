{"id": "87cae596-66d4-4e7f-9efc-e856f7fd7f9a", "code": "# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef _kernel(w, kind):\n    \"\"\"Return a normalized convolution kernel.\"\"\"\n    if kind == \"gaussian\":\n        sigma = w / 6.0\n        t = np.arange(w) - (w - 1) / 2.0\n        k = np.exp(-0.5 * (t / sigma) ** 2)\n    elif kind in (\"exponential\", \"exp\"):\n        k = np.exp(np.linspace(-2, 0, w))\n    elif kind == \"hann\":\n        k = np.hanning(w)\n    else:  # uniform fallback\n        k = np.ones(w)\n    return k / k.sum()\n\n\ndef _validate_input(sig, w):\n    if not isinstance(w, int) or w <= 0:\n        raise ValueError(\"window size must be a positive integer\")\n    if len(sig) < w:\n        raise ValueError(f\"Signal length ({len(sig)}) < window size ({w})\")\n\n\ndef _detrend(x, w, method):\n    \"\"\"Remove a trend from ``x`` using the specified method.\"\"\"\n    if method == \"median\":\n        # sliding_window_view is fast and memory\u2011efficient\n        v = np.lib.stride_tricks.sliding_window_view(x, w)\n        m = np.median(v, axis=1)\n        pad = (len(x) - len(m)) // 2\n        m = np.pad(m, (pad, len(x) - len(m) - pad), mode=\"edge\")\n    else:  # mean\n        m = np.convolve(x, np.ones(w) / w, mode=\"same\")\n    return x - m\n\n\ndef process_signal(sig, w=20, alg=\"enhanced\", full=False, nan_policy=\"interpolate\"):\n    \"\"\"\n    Filter a 1\u2011D signal.\n\n    Parameters\n    ----------\n    sig : array\u2011like\n        Input signal.\n    w : int, optional\n        Window size (default 20).\n    alg : str, optional\n        Processing mode:\n        * ``enhanced`` \u2013 mean detrend + adaptive kernel,\n        * ``robust``   \u2013 median detrend + adaptive kernel,\n        * ``simple``   \u2013 uniform moving\u2011average kernel,\n        * ``gaussian`` \u2013 Gaussian kernel (no detrend),\n        * ``median``   \u2013 median filter (valid output),\n        * ``ema``      \u2013 exponential moving average,\n        * any other string is interpreted as a custom kernel name.\n    full : bool, optional\n        If True, return the full\u2011length convolution output (mode='same');\n        otherwise return the valid central part.\n    nan_policy : str, optional\n        How to handle NaNs: ``'interpolate'`` (default) linearly interpolates,\n        ``'zero'`` replaces NaNs with zero, ``'ignore'`` leaves them unchanged.\n\n    Returns\n    -------\n    np.ndarray\n        Filtered signal.\n    \"\"\"\n    _validate_input(sig, w)\n    x = np.asarray(sig, dtype=float)\n\n    # NaN handling\n    if np.isnan(x).any():\n        if nan_policy == \"interpolate\":\n            n = np.arange(len(x))\n            mask = np.isfinite(x)\n            x = np.interp(n, n[mask], x[mask])\n        elif nan_policy == \"zero\":\n            x = np.nan_to_num(x, nan=0.0)\n        # 'ignore' leaves NaNs as\u2011is (convolution will propagate them)\n\n    if alg == \"enhanced\":\n        x = _detrend(x, w, \"mean\")\n        kind = \"exponential\"\n        y = np.convolve(x, _kernel(w, kind), mode=\"same\")\n    elif alg == \"robust\":\n        x = _detrend(x, w, \"median\")\n        kind = \"exponential\"\n        y = np.convolve(x, _kernel(w, kind), mode=\"same\")\n    elif alg == \"simple\":\n        y = np.convolve(x, _kernel(w, \"uniform\"), mode=\"same\")\n    elif alg == \"gaussian\":\n        y = np.convolve(x, _kernel(w, \"gaussian\"), mode=\"same\")\n    elif alg == \"median\":\n        v = np.lib.stride_tricks.sliding_window_view(x, w)\n        y = np.median(v, axis=1)\n    elif alg == \"ema\":\n        alpha = 2.0 / (w + 1)\n        y = np.empty_like(x)\n        y[0] = x[0]\n        for i in range(1, len(x)):\n            y[i] = alpha * x[i] + (1 - alpha) * y[i - 1]\n        # EMA naturally aligns with the tail of a moving window\n        y = y[w - 1 :]\n    else:\n        # treat alg as a custom kernel name\n        y = np.convolve(x, _kernel(w, alg), mode=\"same\")\n\n    if full:\n        return y\n    # return central valid portion (equivalent to mode='valid')\n    offset = w - 1\n    start = offset // 2\n    end = -(offset - start) if (offset - start) else None\n    return y[start:end]\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n", "language": "python", "parent_id": "c0f84199-9241-4bd6-a34e-93ad3eb36fc2", "generation": 7, "timestamp": 1764933555.7029839, "iteration_found": 468, "metrics": {"runs_successfully": 1.0, "composite_score": 0.41313607247534356, "output_length": 91.0, "overall_score": 0.28813772418464545, "slope_changes": 154.8, "lag_error": 0.35881931759431995, "avg_error": 0.9556927600460691, "false_reversals": 125.6, "correlation": -0.007282066797801695, "noise_reduction": 0.0, "smoothness_score": 0.11441647597254004, "responsiveness_score": 0.7359330170330661, "accuracy_score": 0.0, "efficiency_score": 1.0, "execution_time": 0.0005128860473632812, "success_rate": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Evolve block rewrite (preserved external code)", "parent_metrics": {"runs_successfully": 0.0, "error": "Stage 1 error: name 'np' is not defined"}, "island": 0}, "prompts": {"full_rewrite_user": {"system": "You are an expert software developer tasked with iteratively improving a codebase.\nYour goal is to maximize the FITNESS SCORE while exploring diverse solutions across feature dimensions.\nThe system maintains a collection of diverse programs - both high fitness AND diversity are valuable.", "user": "# Current Program Information\n- Fitness: 0.0000\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness declined: 23.5787 \u2192 0.0000. Consider revising recent changes.\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4131, output_length: 91.0000, overall_score: 0.2881, slope_changes: 154.8000, lag_error: 0.3588, avg_error: 0.9557, false_reversals: 125.6000, correlation: -0.0073, noise_reduction: 0.0000, smoothness_score: 0.1144, responsiveness_score: 0.7359, accuracy_score: 0.0000, efficiency_score: 1.0000, execution_time: 0.0006, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4131, output_length: 91.0000, overall_score: 0.2881, slope_changes: 154.8000, lag_error: 0.3588, avg_error: 0.9557, false_reversals: 125.6000, correlation: -0.0073, noise_reduction: 0.0000, smoothness_score: 0.1144, responsiveness_score: 0.7359, accuracy_score: 0.0000, efficiency_score: 1.0000, execution_time: 0.0007, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4131, output_length: 91.0000, overall_score: 0.2881, slope_changes: 154.8000, lag_error: 0.3588, avg_error: 0.9557, false_reversals: 125.6000, correlation: -0.0073, noise_reduction: 0.0000, smoothness_score: 0.1144, responsiveness_score: 0.7359, accuracy_score: 0.0000, efficiency_score: 1.0000, execution_time: 0.0007, success_rate: 1.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 23.5787)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef _kernel(w, kind):\n    if kind == \"gaussian\":\n        sigma = w / 6.0\n        t = np.arange(w) - (w - 1) / 2.0\n        k = np.exp(-0.5 * (t / sigma) ** 2)\n    elif kind == \"hann\":\n        k = np.hanning(w)\n    elif kind in (\"exp\", \"exponential\"):\n        k = np.exp(np.linspace(-2, 0, w))\n    else:  # uniform fallback\n        k = np.ones(w)\n    return k / k.sum()\n\ndef _mad(x):\n    m = np.median(x)\n    return np.median(np.abs(x - m))\n\ndef _auto_kind(x):\n    mad = _mad(x)\n    if mad < 0.02:\n        return \"gaussian\"\n    if mad < 0.07:\n        return \"hann\"\n    return \"exponential\"\n\ndef _median_filter(x, w):\n    p = w // 2\n    a = np.pad(x, (p, p), mode=\"edge\")\n    s = a.strides[0]\n    windows = np.lib.stride_tricks.as_strided(a, (len(x), w), (s, s))\n    return np.median(windows, axis=1)\n\ndef _detrend(x, w, method=\"mean\"):\n    if method == \"median\":\n        return x - _median_filter(x, w)\n    # mean (moving\u2011average) detrend\n    return x - np.convolve(x, np.ones(w) / w, mode=\"same\")\n\ndef _valid_slice(y, w):\n    off = w - 1\n    start = off // 2\n    end = -(off - start) if (off - start) else None\n    return y[start:end]\n\ndef process_signal(sig, w=20, alg=\"enhanced\", full=False):\n    if w <= 0 or len(sig) < w:\n        raise ValueError(\"Invalid window size\")\n    x = np.asarray(sig, dtype=float)\n\n    if alg == \"enhanced\":\n        x = _detrend(x, w, \"mean\")\n        kind = _auto_kind(x)\n        y = np.convolve(x, _kernel(w, kind), mode=\"same\")\n    elif alg == \"robust\":\n        x = _detrend(x, w, \"median\")\n        kind = _auto_kind(x)\n        y = np.convolve(x, _kernel(w, kind), mode=\"same\")\n    elif alg == \"simple\":\n        y = np.convolve(x, _kernel(w, \"uniform\"), mode=\"same\")\n    elif alg == \"median\":\n        y = _median_filter(x, w)\n    else:  # explicit kernel name\n        y = np.convolve(x, _kernel(w, alg), mode=\"same\")\n\n    return y if full else _valid_slice(y, w)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4131), Performs well on output_length (91.0000), Performs well on overall_score (0.2881), Performs well on slope_changes (154.8000), Performs well on lag_error (0.3588), Performs well on avg_error (0.9557), Performs well on false_reversals (125.6000), Performs well on correlation (-0.0073), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.1144), Performs well on responsiveness_score (0.7359), Performs well on accuracy_score (0.0000), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0007), Performs well on success_rate (1.0000)\n\n### Program 2 (Score: 23.5787)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\ndef _validate_input(sig, w):\n    if w <= 0:\n        raise ValueError(\"window must be positive\")\n    if len(sig) < w:\n        raise ValueError(f\"Signal length ({len(sig)}) < window ({w})\")\n\n@lru_cache(maxsize=None)\ndef _kernel(w, kind):\n    if kind == \"gaussian\":\n        sigma = w / 6.0\n        t = np.arange(w) - (w - 1) / 2.0\n        k = np.exp(-0.5 * (t / sigma) ** 2)\n    elif kind in (\"exponential\", \"exp\"):\n        k = np.exp(np.linspace(-2, 0, w))\n    elif kind == \"hann\":\n        k = np.hanning(w)\n    else:  # uniform fallback\n        k = np.ones(w)\n    return k / k.sum()\n\ndef _detrend(x, w):\n    return x - np.convolve(x, np.ones(w) / w, mode=\"same\") if w and len(x) >= w else x\n\ndef _mad(x):\n    m = np.median(x)\n    return np.median(np.abs(x - m))\n\ndef _auto_kind(x):\n    mad = _mad(x)\n    if mad < 0.02:\n        return \"gaussian\"\n    if mad < 0.08:\n        return \"hann\"\n    return \"exponential\"\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\", full=False):\n    \"\"\"\n    Smooth a 1\u2011D signal.\n\n    algorithm_type:\n        \"enhanced\" \u2013 detrend + adaptive kernel,\n        \"simple\"   \u2013 uniform moving average,\n        \"median\"   \u2013 median filter,\n        any other string is taken as a kernel kind.\n    \"\"\"\n    _validate_input(input_signal, 1)\n    _validate_input(input_signal, window_size)\n    x = np.asarray(input_signal, dtype=float)\n\n    if algorithm_type == \"enhanced\":\n        x = _detrend(x, window_size)\n        kind = _auto_kind(x)\n        y = np.convolve(x, _kernel(window_size, kind), mode=\"same\")\n    elif algorithm_type == \"simple\":\n        y = np.convolve(x, _kernel(window_size, \"uniform\"), mode=\"same\")\n    elif algorithm_type == \"median\":\n        # median filter using sliding window\n        pad = window_size // 2\n        padded = np.pad(x, (pad, pad), mode=\"edge\")\n        shape = (len(x), window_size)\n        strides = (padded.strides[0], padded.strides[0])\n        windows = np.lib.stride_tricks.as_strided(padded, shape=shape, strides=strides)\n        y = np.median(windows, axis=1)\n    else:\n        y = np.convolve(x, _kernel(window_size, algorithm_type), mode=\"same\")\n\n    if not full:\n        # return valid portion (remove padding)\n        offset = window_size - 1\n        y = y[offset // 2 : -(offset - offset // 2) or None]\n    return y\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4131), Performs well on output_length (91.0000), Performs well on overall_score (0.2881), Performs well on slope_changes (154.8000), Performs well on lag_error (0.3588), Performs well on avg_error (0.9557), Performs well on false_reversals (125.6000), Performs well on correlation (-0.0073), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.1144), Performs well on responsiveness_score (0.7359), Performs well on accuracy_score (0.0000), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0007), Performs well on success_rate (1.0000)\n\n### Program 3 (Score: 23.5787)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef _kernel(w, kind):\n    \"\"\"Return a normalized kernel.\"\"\"\n    if kind == \"gaussian\":\n        sigma = w / 6.0\n        t = np.arange(w) - (w - 1) / 2.0\n        k = np.exp(-0.5 * (t / sigma) ** 2)\n    elif kind in (\"exponential\", \"exp\"):\n        k = np.exp(np.linspace(-2, 0, w))\n    elif kind == \"hann\":\n        k = np.hanning(w)\n    else:  # uniform fallback\n        k = np.ones(w)\n    return k / k.sum()\n\n\ndef _detrend(x, w):\n    \"\"\"Remove a moving\u2011average trend.\"\"\"\n    if w > 0 and len(x) >= w:\n        return x - np.convolve(x, np.ones(w) / w, mode=\"same\")\n    return x\n\n\ndef _mad(x):\n    \"\"\"Median absolute deviation.\"\"\"\n    m = np.median(x)\n    return np.median(np.abs(x - m))\n\n\ndef _auto_kind(x):\n    \"\"\"Choose kernel based on signal variability.\"\"\"\n    return \"gaussian\" if _mad(x) < 0.05 else \"exponential\"\n\n\ndef _median_filter(x, w):\n    \"\"\"Median filter using stride tricks (valid output).\"\"\"\n    pad = w // 2\n    padded = np.pad(x, (pad, pad), mode=\"edge\")\n    shape = (len(x), w)\n    strides = (padded.strides[0], padded.strides[0])\n    windows = np.lib.stride_tricks.as_strided(padded, shape=shape, strides=strides)\n    return np.median(windows, axis=1)\n\n\ndef process_signal(sig, win=20, alg=\"enhanced\", full=False):\n    \"\"\"\n    Smooth a 1\u2011D signal.\n\n    Parameters\n    ----------\n    sig : array\u2011like\n        Input signal.\n    win : int, optional\n        Window length (default 20).\n    alg : str, optional\n        \"enhanced\" \u2013 detrend + adaptive kernel,\n        \"simple\"   \u2013 uniform moving average,\n        \"median\"   \u2013 median filter,\n        \"smooth\"   \u2013 Hann kernel,\n        otherwise interpreted as a kernel kind.\n    full : bool, optional\n        If True, return full\u2011length output (mode='same'); else valid output.\n    \"\"\"\n    if win <= 0:\n        raise ValueError(\"win must be a positive integer\")\n    x = np.asarray(sig, dtype=float)\n\n    if alg == \"enhanced\":\n        x = _detrend(x, win)\n        kind = _auto_kind(x)\n        y = np.convolve(x, _kernel(win, kind), mode=\"same\")\n    elif alg == \"simple\":\n        y = np.convolve(x, _kernel(win, \"uniform\"), mode=\"same\")\n    elif alg == \"median\":\n        return _median_filter(x, win)\n    elif alg == \"smooth\":\n        y = np.convolve(x, _kernel(win, \"hann\"), mode=\"same\")\n    else:\n        y = np.convolve(x, _kernel(win, alg), mode=\"same\")\n\n    if not full:\n        offset = win - 1\n        start = offset // 2\n        end = -(offset - start) if (offset - start) != 0 else None\n        y = y[start:end]\n    return y\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4131), Performs well on output_length (91.0000), Performs well on overall_score (0.2881), Performs well on slope_changes (154.8000), Performs well on lag_error (0.3588), Performs well on avg_error (0.9557), Performs well on false_reversals (125.6000), Performs well on correlation (-0.0073), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.1144), Performs well on responsiveness_score (0.7359), Performs well on accuracy_score (0.0000), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0006), Performs well on success_rate (1.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 23.5787)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\ndef _validate(sig, win):\n    if not isinstance(win, int) or win <= 0:\n        raise ValueError(\"window size must be a positive integer\")\n    if len(sig) < win:\n        raise ValueError(f\"signal length ({len(sig)}) < window ({win})\")\n\n@lru_cache(maxsize=128)\ndef _kernel(win, kind):\n    if kind == \"gaussian\":\n        sigma = win / 6.0\n        t = np.arange(win) - (win - 1) / 2.0\n        k = np.exp(-0.5 * (t / sigma) ** 2)\n    elif kind in (\"exponential\", \"exp\"):\n        k = np.exp(np.linspace(-2, 0, win))\n    elif kind == \"hann\":\n        k = np.hanning(win)\n    else:\n        k = np.ones(win)\n    return k / k.sum()\n\ndef _mad(x):\n    m = np.median(x)\n    return np.median(np.abs(x - m))\n\ndef _auto_kind(x, low=0.02, high=0.07):\n    mad = _mad(x)\n    if mad < low:\n        return \"gaussian\"\n    if mad < high:\n        return \"hann\"\n    return \"exponential\"\n\ndef _detrend_mean(x, win):\n    return x - np.convolve(x, np.ones(win) / win, mode=\"same\") if len(x) >= win else x\n\ndef _detrend_median(x, win):\n    pad = win // 2\n    a = np.pad(x, (pad, pad), mode=\"edge\")\n    s = a.strides[0]\n    win_arr = np.lib.stride_tricks.as_strided(a, (len(x), win), (s, s))\n    trend = np.median(win_arr, axis=1)\n    return x - trend\n\ndef _median_filter(x, win):\n    pad = win // 2\n    a = np.pad(x, (pad, pad), mode=\"edge\")\n    s = a.strides[0]\n    win_arr = np.lib.stride_tricks.as_strided(a, (len(x), win), (s, s))\n    return np.median(win_arr, axis=1)\n\ndef process_signal(sig, win=20, alg=\"enhanced\", full=False, nan_policy=\"interpolate\"):\n    _validate(sig, win)\n    x = np.asarray(sig, dtype=float)\n\n    if np.isnan(x).any():\n        n = np.arange(len(x))\n        mask = np.isfinite(x)\n        x = np.interp(n, n[mask], x[mask])\n\n    if alg == \"enhanced\":\n        x = _detrend_mean(x, win)\n        kind = _auto_kind(x)\n        y = np.convolve(x, _kernel(win, kind), mode=\"same\")\n    elif alg == \"robust\":\n        x = _detrend_median(x, win)\n        kind = _auto_kind(x)\n        y = np.convolve(x, _kernel(win, kind), mode=\"same\")\n    elif alg == \"simple\":\n        y = np.convolve(x, _kernel(win, \"uniform\"), mode=\"same\")\n    elif alg == \"median\":\n        y = _median_filter(x, win)\n    else:\n        y = np.convolve(x, _kernel(win, alg), mode=\"same\")\n\n    if full:\n        return y\n    offset = win - 1\n    start = offset // 2\n    end = -(offset - start) if (offset - start) else None\n    return y[start:end]\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to composite_score\n\n### Program D2 (Score: 23.5787)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef _kernel(w, kind):\n    \"\"\"Return a normalized convolution kernel.\"\"\"\n    if kind == \"gaussian\":\n        sigma = w / 6.0\n        t = np.arange(w) - (w - 1) / 2.0\n        k = np.exp(-0.5 * (t / sigma) ** 2)\n    elif kind == \"hann\":\n        k = np.hanning(w)\n    elif kind in (\"exp\", \"exponential\"):\n        k = np.exp(np.linspace(-2, 0, w))\n    else:  # uniform fallback\n        k = np.ones(w)\n    return k / k.sum()\n\ndef _mad(x):\n    \"\"\"Median absolute deviation.\"\"\"\n    m = np.median(x)\n    return np.median(np.abs(x - m))\n\ndef _choose_kernel(x, w):\n    \"\"\"Pick kernel type based on signal variability.\"\"\"\n    mad = _mad(x)\n    if mad < 0.02:\n        return \"gaussian\"\n    if mad < 0.07:\n        return \"hann\"\n    return \"exponential\"\n\ndef _detrend(x, w):\n    \"\"\"Remove moving\u2011average trend.\"\"\"\n    if w and len(x) >= w:\n        return x - np.convolve(x, np.ones(w) / w, mode=\"same\")\n    return x\n\ndef _median_filter(x, w):\n    \"\"\"Median filter using stride tricks (full\u2011length output).\"\"\"\n    p = w // 2\n    a = np.pad(x, (p, p), mode=\"edge\")\n    s = a.strides[0]\n    windows = np.lib.stride_tricks.as_strided(a, (len(x), w), (s, s))\n    return np.median(windows, axis=1)\n\ndef process_signal(sig, win=20, method=\"auto\", full=False):\n    \"\"\"\n    Smooth a 1\u2011D signal.\n\n    Parameters\n    ----------\n    sig : array\u2011like\n        Input signal.\n    win : int, optional\n        Window length (default 20).\n    method : str, optional\n        \"auto\"      \u2013 adaptive kernel (detrend + choose kernel),\n        \"enhanced\"  \u2013 same as \"auto\",\n        \"median\"    \u2013 median filter,\n        \"gaussian\", \"hann\", \"exponential\", \"uniform\" \u2013 explicit kernel,\n        any other value falls back to uniform.\n    full : bool, optional\n        If True, return the full ``mode='same'`` convolution output;\n        otherwise return the central valid part.\n    \"\"\"\n    if win <= 0 or len(sig) < win:\n        raise ValueError(\"Invalid window size or signal length\")\n    x = np.asarray(sig, dtype=float)\n\n    if method == \"median\":\n        y = _median_filter(x, win)\n    else:\n        if method in (\"auto\", \"enhanced\"):\n            x = _detrend(x, win)\n            kind = _choose_kernel(x, win)\n        elif method in (\"gaussian\", \"hann\", \"exponential\", \"uniform\"):\n            kind = method\n        else:\n            kind = \"uniform\"\n        y = np.convolve(x, _kernel(win, kind), mode=\"same\")\n\n    if not full:\n        offset = win - 1\n        start = offset // 2\n        end = -(offset - start) if (offset - start) != 0 else None\n        y = y[start:end]\n    return y\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to composite_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 10.7862, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _validate(x, w):\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if len(x) < w:\n        raise ValueError(f\"Signal length ({len(x)}) < window size ({w})\")\n\ndef _exp_weights(w):\n    wts = np.exp(np.linspace(-2, 0, w))\n    return wts / wts.sum()\n\ndef _gauss_weights(w):\n    sigma = w / 6.0\n    x = np.arange(w) - (w - 1) / 2.0\n    wts = np.exp(-0.5 * (x / sigma) ** 2)\n    return wts / wts.sum()\n\ndef _convolve(x, kernel):\n    return np.convolve(x, kernel, mode=\"valid\")\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Filter ``input_signal`` with a sliding\u2011window average.\n\n    algorithm_type:\n        \"basic\"    \u2013 simple moving average.\n        \"enhanced\" \u2013 Gaussian weighted average (default, smoother).\n        \"exp\"      \u2013 exponential weighted average.\n    \"\"\"\n    _validate(input_signal, window_size)\n    if algorithm_type == \"basic\":\n        kernel = np.ones(window_size) / window_size\n    elif algorithm_type == \"exp\":\n        kernel = _exp_weights(window_size)\n    else:  # enhanced or any other value\n        kernel = _gauss_weights(window_size)\n    return _convolve(np.asarray(input_signal, dtype=float), kernel)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (91.000)\n\n### Inspiration 2 (Score: 23.5037, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _kernel(w, kind):\n    if kind == \"gaussian\":\n        s = w / 6.0\n        t = np.arange(w) - (w - 1) / 2\n        k = np.exp(-0.5 * (t / s) ** 2)\n    elif kind == \"exponential\":\n        k = np.exp(np.linspace(-2, 0, w))\n    else:  # uniform\n        k = np.ones(w)\n    return k / k.sum()\n\ndef _detrend(x, w, method):\n    if method == \"median\":\n        v = np.lib.stride_tricks.sliding_window_view(x, w)\n        m = np.median(v, axis=1)\n        p = (len(x) - len(m)) // 2\n        return x - np.pad(m, (p, len(x) - len(m) - p), mode=\"edge\")\n    # default: mean\n    return x - np.convolve(x, np.ones(w) / w, mode=\"same\")\n\ndef _ema(x, alpha):\n    out = np.empty_like(x, dtype=float)\n    out[0] = x[0]\n    for i in range(1, len(x)):\n        out[i] = alpha * x[i] + (1 - alpha) * out[i - 1]\n    return out\n\ndef process_signal(sig, window=20, method=\"enhanced\", trend_method=\"mean\"):\n    \"\"\"\n    Parameters\n    ----------\n    sig : array\u2011like\n        Input signal.\n    window : int\n        Smoothing window size.\n    method : str\n        \"enhanced\", \"robust\", \"simple\", \"gaussian\",\n        \"median\", \"ema\" or any kernel name.\n    trend_method : str\n        \"mean\" or \"median\" detrending used for\n        \"enhanced\"/\"robust\".\n    \"\"\"\n    x = np.asarray(sig, dtype=float)\n\n    if method == \"enhanced\":\n        x = _detrend(x, window, \"mean\")\n        kind = \"exponential\"\n    elif method == \"robust\":\n        x = _detrend(x, window, \"median\")\n        kind = \"exponential\"\n    elif method == \"simple\":\n        kind = \"uniform\"\n    elif method == \"gaussian\":\n        kind = \"gaussian\"\n    elif method == \"median\":\n        v = np.lib.stride_tricks.sliding_window_view(x, window)\n        return np.median(v, axis=1)\n    elif method == \"ema\":\n        alpha = 2.0 / (window + 1)\n        return _ema(x, alpha)[window - 1 :]\n    else:\n        kind = method  # treat as kernel name\n\n    return np.convolve(x, _kernel(window, kind), mode=\"valid\")\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (91.000)\n\n### Inspiration 3 (Score: 23.5787, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\ndef _validate(sig, win):\n    if not isinstance(win, int) or win <= 0:\n        raise ValueError(\"window size must be a positive integer\")\n    if len(sig) < win:\n        raise ValueError(f\"signal length ({len(sig)}) < window ({win})\")\n\n@lru_cache(maxsize=128)\ndef _kernel(win, kind):\n    if kind == \"gaussian\":\n        sigma = win / 6.0\n        t = np.arange(win) - (win - 1) / 2.0\n        k = np.exp(-0.5 * (t / sigma) ** 2)\n    elif kind in (\"exponential\", \"exp\"):\n        k = np.exp(np.linspace(-2, 0, win))\n    elif kind == \"hann\":\n        k = np.hanning(win)\n    else:\n        k = np.ones(win)\n    return k / k.sum()\n\ndef _mad(x):\n    m = np.median(x)\n    return np.median(np.abs(x - m))\n\ndef _auto_kind(x, low=0.02, high=0.07):\n    mad = _mad(x)\n    if mad < low:\n        return \"gaussian\"\n    if mad < high:\n        return \"hann\"\n    return \"exponential\"\n\ndef _detrend_mean(x, win):\n    return x - np.convolve(x, np.ones(win) / win, mode=\"same\") if len(x) >= win else x\n\ndef _detrend_median(x, win):\n    pad = win // 2\n    a = np.pad(x, (pad, pad), mode=\"edge\")\n    s = a.strides[0]\n    win_arr = np.lib.stride_tricks.as_strided(a, (len(x), win), (s, s))\n    trend = np.median(win_arr, axis=1)\n    return x - trend\n\ndef _median_filter(x, win):\n    pad = win // 2\n    a = np.pad(x, (pad, pad), mode=\"edge\")\n    s = a.strides[0]\n    win_arr = np.lib.stride_tricks.as_strided(a, (len(x), win), (s, s))\n    return np.median(win_arr, axis=1)\n\ndef process_signal(sig, win=20, alg=\"enhanced\", full=False, nan_policy=\"interpolate\"):\n    _validate(sig, win)\n    x = np.asarray(sig, dtype=float)\n\n    if np.isnan(x).any():\n        n = np.arange(len(x))\n        mask = np.isfinite(x)\n        x = np.interp(n, n[mask], x[mask])\n\n    if alg == \"enhanced\":\n        x = _detrend_mean(x, win)\n        kind = _auto_kind(x)\n        y = np.convolve(x, _kernel(win, kind), mode=\"same\")\n    elif alg == \"robust\":\n        x = _detrend_median(x, win)\n        kind = _auto_kind(x)\n        y = np.convolve(x, _kernel(win, kind), mode=\"same\")\n    elif alg == \"simple\":\n        y = np.convolve(x, _kernel(win, \"uniform\"), mode=\"same\")\n    elif alg == \"median\":\n        y = _median_filter(x, win)\n    else:\n        y = np.convolve(x, _kernel(win, alg), mode=\"same\")\n\n    if full:\n        return y\n    offset = win - 1\n    start = offset // 2\n    end = -(offset - start) if (offset - start) else None\n    return y[start:end]\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (91.000)\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\ndef _kernel(w, kind):\n    \"\"\"Return a normalized kernel for convolution.\"\"\"\n    if kind == \"gaussian\":\n        sigma = w / 6.0\n        t = np.arange(w) - (w - 1) / 2\n        k = np.exp(-0.5 * (t / sigma) ** 2)\n    elif kind == \"exponential\":\n        k = np.exp(np.linspace(-2, 0, w))\n    else:  # uniform fallback\n        k = np.ones(w)\n    return k / k.sum()\n\n\ndef _detrend(x, w, method):\n    \"\"\"Remove a trend from ``x`` using the specified method.\"\"\"\n    if method == \"median\":\n        v = np.lib.stride_tricks.sliding_window_view(x, w)\n        m = np.median(v, axis=1)\n        pad = (len(x) - len(m)) // 2\n        m = np.pad(m, (pad, len(x) - len(m) - pad), mode=\"edge\")\n    else:  # mean\n        m = np.convolve(x, np.ones(w) / w, mode=\"same\")\n    return x - m\n\n\ndef process_signal(sig, w=20, alg=\"enhanced\"):\n    \"\"\"\n    Filter a 1\u2011D signal.\n\n    Parameters\n    ----------\n    sig : array\u2011like\n        Input signal.\n    w : int, optional\n        Window size (default 20).\n    alg : str, optional\n        Processing mode:\n        * ``enhanced`` \u2013 mean detrend + exponential kernel\n        * ``robust``   \u2013 median detrend + exponential kernel\n        * ``simple``   \u2013 uniform (moving\u2011average) kernel\n        * ``gaussian`` \u2013 Gaussian kernel (no detrend)\n        * ``median``   \u2013 median filter (valid output)\n        * ``ema``      \u2013 exponential moving average\n        * any other string is interpreted as a custom kernel name.\n\n    Returns\n    -------\n    np.ndarray\n        Filtered signal (valid part only, except EMA which returns\n        the tail of the recursive filter).\n    \"\"\"\n    x = np.asarray(sig, float)\n\n    if alg == \"enhanced\":\n        x = _detrend(x, w, \"mean\")\n        kind = \"exponential\"\n    elif alg == \"robust\":\n        x = _detrend(x, w, \"median\")\n        kind = \"exponential\"\n    elif alg == \"simple\":\n        kind = \"uniform\"\n    elif alg == \"gaussian\":\n        kind = \"gaussian\"\n    elif alg == \"median\":\n        v = np.lib.stride_tricks.sliding_window_view(x, w)\n        return np.median(v, axis=1)\n    elif alg == \"ema\":\n        alpha = 2.0 / (w + 1)\n        y = np.empty_like(x)\n        y[0] = x[0]\n        for i in range(1, len(x)):\n            y[i] = alpha * x[i] + (1 - alpha) * y[i - 1]\n        return y[w - 1 :]  # align with convolution output length\n    else:\n        kind = alg  # custom kernel name\n\n    return np.convolve(x, _kernel(w, kind), mode=\"valid\")\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\n\n# Task\nImprove the code to maximize FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\n\n## CRITICAL INSTRUCTIONS\nIf the code contains `# EVOLVE-BLOCK-START` and `# EVOLVE-BLOCK-END` markers:\n- Output ONLY the code that goes BETWEEN these markers\n- Do NOT include the markers themselves\n- Do NOT include code outside the markers (like `run_packing()`)\n- The system will automatically merge your output with the preserved sections\n\nIf there are NO EVOLVE-BLOCK markers:\n- Output the complete rewritten program\n\n```python\n# Your improved code here (ONLY the evolve block content if markers exist)\n```", "responses": ["import numpy as np\nfrom functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef _kernel(w, kind):\n    \"\"\"Return a normalized convolution kernel.\"\"\"\n    if kind == \"gaussian\":\n        sigma = w / 6.0\n        t = np.arange(w) - (w - 1) / 2.0\n        k = np.exp(-0.5 * (t / sigma) ** 2)\n    elif kind in (\"exponential\", \"exp\"):\n        k = np.exp(np.linspace(-2, 0, w))\n    elif kind == \"hann\":\n        k = np.hanning(w)\n    else:  # uniform fallback\n        k = np.ones(w)\n    return k / k.sum()\n\n\ndef _validate_input(sig, w):\n    if not isinstance(w, int) or w <= 0:\n        raise ValueError(\"window size must be a positive integer\")\n    if len(sig) < w:\n        raise ValueError(f\"Signal length ({len(sig)}) < window size ({w})\")\n\n\ndef _detrend(x, w, method):\n    \"\"\"Remove a trend from ``x`` using the specified method.\"\"\"\n    if method == \"median\":\n        # sliding_window_view is fast and memory\u2011efficient\n        v = np.lib.stride_tricks.sliding_window_view(x, w)\n        m = np.median(v, axis=1)\n        pad = (len(x) - len(m)) // 2\n        m = np.pad(m, (pad, len(x) - len(m) - pad), mode=\"edge\")\n    else:  # mean\n        m = np.convolve(x, np.ones(w) / w, mode=\"same\")\n    return x - m\n\n\ndef process_signal(sig, w=20, alg=\"enhanced\", full=False, nan_policy=\"interpolate\"):\n    \"\"\"\n    Filter a 1\u2011D signal.\n\n    Parameters\n    ----------\n    sig : array\u2011like\n        Input signal.\n    w : int, optional\n        Window size (default 20).\n    alg : str, optional\n        Processing mode:\n        * ``enhanced`` \u2013 mean detrend + adaptive kernel,\n        * ``robust``   \u2013 median detrend + adaptive kernel,\n        * ``simple``   \u2013 uniform moving\u2011average kernel,\n        * ``gaussian`` \u2013 Gaussian kernel (no detrend),\n        * ``median``   \u2013 median filter (valid output),\n        * ``ema``      \u2013 exponential moving average,\n        * any other string is interpreted as a custom kernel name.\n    full : bool, optional\n        If True, return the full\u2011length convolution output (mode='same');\n        otherwise return the valid central part.\n    nan_policy : str, optional\n        How to handle NaNs: ``'interpolate'`` (default) linearly interpolates,\n        ``'zero'`` replaces NaNs with zero, ``'ignore'`` leaves them unchanged.\n\n    Returns\n    -------\n    np.ndarray\n        Filtered signal.\n    \"\"\"\n    _validate_input(sig, w)\n    x = np.asarray(sig, dtype=float)\n\n    # NaN handling\n    if np.isnan(x).any():\n        if nan_policy == \"interpolate\":\n            n = np.arange(len(x))\n            mask = np.isfinite(x)\n            x = np.interp(n, n[mask], x[mask])\n        elif nan_policy == \"zero\":\n            x = np.nan_to_num(x, nan=0.0)\n        # 'ignore' leaves NaNs as\u2011is (convolution will propagate them)\n\n    if alg == \"enhanced\":\n        x = _detrend(x, w, \"mean\")\n        kind = \"exponential\"\n        y = np.convolve(x, _kernel(w, kind), mode=\"same\")\n    elif alg == \"robust\":\n        x = _detrend(x, w, \"median\")\n        kind = \"exponential\"\n        y = np.convolve(x, _kernel(w, kind), mode=\"same\")\n    elif alg == \"simple\":\n        y = np.convolve(x, _kernel(w, \"uniform\"), mode=\"same\")\n    elif alg == \"gaussian\":\n        y = np.convolve(x, _kernel(w, \"gaussian\"), mode=\"same\")\n    elif alg == \"median\":\n        v = np.lib.stride_tricks.sliding_window_view(x, w)\n        y = np.median(v, axis=1)\n    elif alg == \"ema\":\n        alpha = 2.0 / (w + 1)\n        y = np.empty_like(x)\n        y[0] = x[0]\n        for i in range(1, len(x)):\n            y[i] = alpha * x[i] + (1 - alpha) * y[i - 1]\n        # EMA naturally aligns with the tail of a moving window\n        y = y[w - 1 :]\n    else:\n        # treat alg as a custom kernel name\n        y = np.convolve(x, _kernel(w, alg), mode=\"same\")\n\n    if full:\n        return y\n    # return central valid portion (equivalent to mode='valid')\n    offset = w - 1\n    start = offset // 2\n    end = -(offset - start) if (offset - start) else None\n    return y[start:end]"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}