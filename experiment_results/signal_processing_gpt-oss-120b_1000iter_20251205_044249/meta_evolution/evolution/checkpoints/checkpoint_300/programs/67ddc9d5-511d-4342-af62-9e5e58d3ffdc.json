{"id": "67ddc9d5-511d-4342-af62-9e5e58d3ffdc", "code": "# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\ndef _as_array(x, window_size):\n    \"\"\"Validate input and convert to 1\u2011D float array.\n\n    Returns an empty array when the signal is shorter than the window so\n    callers can handle it gracefully.\n    \"\"\"\n    arr = np.asarray(x, dtype=float)\n    if arr.ndim != 1:\n        raise ValueError(\"Input signal must be one\u2011dimensional\")\n    ws = int(window_size)\n    if ws <= 0:\n        raise ValueError(\"window_size must be a positive integer\")\n    if arr.size < ws:\n        # Graceful handling of too\u2011short signals\n        return np.empty(0, dtype=float), ws\n    return arr, ws\n\n@lru_cache(maxsize=32)\ndef _exp_weights(ws):\n    \"\"\"Pre\u2011compute exponential weights for a given window size.\"\"\"\n    w = np.exp(np.linspace(-2, 0, ws))\n    return w / w.sum()\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Fast simple moving\u2011average using cumulative sum.\"\"\"\n    arr, ws = _as_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    csum = np.cumsum(np.insert(arr, 0, 0.0))\n    return (csum[ws:] - csum[:-ws]) / ws\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"Exponentially weighted moving\u2011average (valid convolution).\"\"\"\n    arr, ws = _as_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    kernel = _exp_weights(ws)\n    return np.convolve(arr, kernel, mode=\"valid\")\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; output length matches other filters.\"\"\"\n    arr, ws = _as_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    alpha = 2.0 / (ws + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[ws - 1 :]\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"Dispatch to the selected filtering algorithm (case\u2011insensitive).\"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    if alg in (\"exp\", \"exponential\"):\n        return exponential_smoothing(input_signal, window_size)\n    # Fallback to enhanced for unknown types\n    return enhanced_filter_with_trend_preservation(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n", "language": "python", "parent_id": "0b180ea0-2029-40ab-8926-ab37c322768d", "generation": 5, "timestamp": 1764937493.698386, "iteration_found": 128, "metrics": {"runs_successfully": 1.0, "composite_score": 0.4147238108898642, "output_length": 91.0, "overall_score": 0.3667365016552355, "slope_changes": 64.2, "lag_error": 1.0255240244901955, "avg_error": 1.3708262692399187, "false_reversals": 52.4, "correlation": 0.2667051952850475, "noise_reduction": 0.0, "smoothness_score": 0.23752969121140144, "responsiveness_score": 0.4936994021839312, "accuracy_score": 0.2667051952850475, "efficiency_score": 1.0, "execution_time": 0.0003360271453857422, "success_rate": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Evolve block rewrite (preserved external code)", "parent_metrics": {"runs_successfully": 0.0, "error": "Stage 1 error: name 'np' is not defined"}, "island": 1}, "prompts": {"full_rewrite_user": {"system": "## CRITICAL FORMAT REQUIREMENTS (DO NOT VIOLATE)\n## OUTPUT FORMAT (CRITICAL)\n- Output ONLY the code that goes BETWEEN the `# EVOLVE-BLOCK-START` and `# EVOLVE-BLOCK-END` markers\n- Do NOT include the markers themselves in your output\n- Do NOT include any code outside the markers (imports, run_packing, etc.)\n- The system will automatically merge your output with the preserved code sections\n\n## FOCUS\n- Improve ONLY the `construct_packing()` function and helper functions within the evolve block\n- Functions like `run_packing()` are preserved automatically - do not include them\n\nViolating these requirements will cause the program to fail evaluation.\n\n---\n\nYou are a code\u2011evolution assistant tasked with improving the **`construct_packing()`** function and any helper functions that appear between the markers `# EVOLVE\u2011BLOCK\u2011START` and `# EVOLVE\u2011BLOCK\u2011END`.  \n\n**OUTPUT REQUIREMENTS**  \n- **Only** output the revised source code that belongs **between** those two markers.  \n- **Do not** include the `# EVOLVE\u2011BLOCK\u2011START` or `# EVOLVE\u2011BLOCK\u2011END` lines themselves.  \n- **Do not** output any other code (imports, `run_packing()`, etc.). The surrounding file will be merged automatically.  \n\n**WHAT TO AVOID (based on previous failures)**  \n- Do **not** make sweeping, aggressive rewrites that change the overall structure or remove existing logic wholesale.  \n- Do **not** introduce syntax errors, undefined names, or mismatched indentation.  \n- Do **not** produce the same invalid program repeatedly; each edit must be a *small, testable* improvement.  \n\n**STRATEGIES FOR SUCCESS**  \n\n1. **Incremental Refactoring**  \n   - Identify a single concrete weakness (e.g., missing sorting of items, inefficient loop, unclear variable naming).  \n   - Modify only the lines directly related to that weakness; leave the rest untouched.  \n\n2. **Preserve Existing Interface**  \n   - Keep the function signature, return type, and any expected side\u2011effects exactly as they are used elsewhere in the repository.  \n\n3. **Safety Checks**  \n   - Add defensive code only if it does not alter the external behavior (e.g., guard against empty input, ensure indices stay in range).  \n   - Use `try/except` sparingly and only around code that may raise a known exception.  \n\n4. **Algorithmic Enhancements Specific to Packing**  \n   - **Sorting**: If items are not already ordered, sort them by size or weight (e.g., `sorted(items, key=lambda x: x.size, reverse=True)`).  \n   - **Greedy Placement**: Implement a simple first\u2011fit or best\u2011fit loop that attempts to place each item into the first bin that can accommodate it.  \n   - **Bin Management**: When a new bin is created, initialize its capacity clearly and update it after each placement.  \n\n5. **Clear Naming & Comments**  \n   - Use descriptive variable names (`remaining_capacity`, `current_bin`, `item_index`).  \n   - Add brief inline comments that explain *why* a change is made, not *what* the code already does.  \n\n6. **Validate Syntax Before Submitting**  \n   - Run a mental check (or a quick local lint) for matching parentheses, proper indentation, and that all referenced identifiers are defined within the block or imported earlier.  \n\n**DELIVERABLE**  \nProvide only the revised code that belongs between `# EVOLVE\u2011BLOCK\u2011START` and `# EVOLVE\u2011BLOCK\u2011END`. No extra text, markers, or surrounding code.", "user": "# Current Program Information\n- Fitness: 0.0000\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness declined: 13.4402 \u2192 0.0000. Consider revising recent changes.\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4147, output_length: 91.0000, overall_score: 0.3667, slope_changes: 64.2000, lag_error: 1.0255, avg_error: 1.3708, false_reversals: 52.4000, correlation: 0.2667, noise_reduction: 0.0000, smoothness_score: 0.2375, responsiveness_score: 0.4937, accuracy_score: 0.2667, efficiency_score: 1.0000, execution_time: 0.0005, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4147, output_length: 91.0000, overall_score: 0.3667, slope_changes: 64.2000, lag_error: 1.0255, avg_error: 1.3708, false_reversals: 52.4000, correlation: 0.2667, noise_reduction: 0.0000, smoothness_score: 0.2375, responsiveness_score: 0.4937, accuracy_score: 0.2667, efficiency_score: 1.0000, execution_time: 0.0009, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Unknown changes\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4200, output_length: 91.0000, overall_score: 0.3899, slope_changes: 66.0000, lag_error: 0.8697, avg_error: 1.2418, false_reversals: 55.2000, correlation: 0.3768, noise_reduction: 0.0000, smoothness_score: 0.2326, responsiveness_score: 0.5349, accuracy_score: 0.3768, efficiency_score: 1.0000, execution_time: 0.0018, success_rate: 1.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 13.7278)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nReal-Time Adaptive Signal Processing Algorithm for Non-Stationary Time Series\n\nThis algorithm implements a sliding window approach to filter volatile, non-stationary\ntime series data while minimizing noise and preserving signal dynamics.\n\"\"\"\nimport numpy as np\nfrom scipy import signal\nfrom collections import deque\n\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"\n    Adaptive signal processing algorithm using sliding window approach.\n\n    Args:\n        x: Input signal (1D array of real-valued samples)\n        window_size: Size of the sliding window (W samples)\n\n    Returns:\n        y: Filtered output signal with length = len(x) - window_size + 1\n    \"\"\"\n    if len(x) < window_size:\n        raise ValueError(f\"Input signal length ({len(x)}) must be >= window_size ({window_size})\")\n\n    # Initialize output array\n    output_length = len(x) - window_size + 1\n    y = np.zeros(output_length)\n\n    # Simple moving average as baseline\n    for i in range(output_length):\n        window = x[i : i + window_size]\n\n        # Basic moving average filter\n        y[i] = np.mean(window)\n\n    return y\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"\n    Enhanced version with trend preservation using weighted moving average.\n\n    Args:\n        x: Input signal (1D array of real-valued samples)\n        window_size: Size of the sliding window\n\n    Returns:\n        y: Filtered output signal\n    \"\"\"\n    if len(x) < window_size:\n        raise ValueError(f\"Input signal length ({len(x)}) must be >= window_size ({window_size})\")\n\n    output_length = len(x) - window_size + 1\n    y = np.zeros(output_length)\n\n    # Create weights that emphasize recent samples\n    weights = np.exp(np.linspace(-2, 0, window_size))\n    weights = weights / np.sum(weights)\n\n    for i in range(output_length):\n        window = x[i : i + window_size]\n\n        # Weighted moving average with exponential weights\n        y[i] = np.sum(window * weights)\n\n    return y\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Main signal processing function that applies the selected algorithm.\n\n    Args:\n        input_signal: Input time series data\n        window_size: Window size for processing\n        algorithm_type: Type of algorithm to use (\"basic\" or \"enhanced\")\n\n    Returns:\n        Filtered signal\n    \"\"\"\n    if algorithm_type == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    else:\n        return adaptive_filter(input_signal, window_size)\n\n\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4200), Performs well on output_length (91.0000), Performs well on overall_score (0.3899), Performs well on slope_changes (66.0000), Performs well on lag_error (0.8697), Performs well on avg_error (1.2418), Performs well on false_reversals (55.2000), Performs well on correlation (0.3768), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.2326), Performs well on responsiveness_score (0.5349), Performs well on accuracy_score (0.3768), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0018), Performs well on success_rate (1.0000)\n\n### Program 2 (Score: 13.4402)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nReal-Time Adaptive Signal Processing Algorithm for Non\u2011Stationary Time Series\n\nProvides several filtering strategies (basic moving\u2011average, weighted EWMA,\nexponential smoothing and optional Savitzky\u2011Golay) with safe fall\u2011backs.\n\"\"\"\nimport numpy as np\nfrom scipy import signal\n\ndef _to_array(x, window):\n    \"\"\"Convert input to 1\u2011D float array and validate length.\"\"\"\n    arr = np.asarray(x, dtype=float)\n    if arr.ndim != 1:\n        raise ValueError(\"Input signal must be 1\u2011D\")\n    if window <= 0:\n        raise ValueError(\"window_size must be positive\")\n    if arr.size < window:\n        # Return empty array \u2013 caller can handle gracefully\n        return np.array([], dtype=float)\n    return arr\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Fast simple moving average using cumulative sum.\"\"\"\n    arr = _to_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    csum = np.cumsum(np.insert(arr, 0, 0.0))\n    return (csum[window_size:] - csum[:-window_size]) / window_size\n\ndef weighted_filter(x, window_size=20):\n    \"\"\"Exponentially weighted moving average (EWMA).\"\"\"\n    arr = _to_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    w = np.exp(np.linspace(-2, 0, window_size))\n    w /= w.sum()\n    return np.convolve(arr, w, mode='valid')\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; output length matches other filters.\"\"\"\n    arr = _to_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    alpha = 2.0 / (window_size + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[window_size - 1 :]\n\ndef _savgol_filter(x, window_size=20, polyorder=3):\n    \"\"\"Savitzky\u2011Golay filter with safe parameter handling.\"\"\"\n    arr = _to_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    # SciPy's savgol_filter may be unavailable; fall back to basic MA\n    if not hasattr(signal, \"savgol_filter\"):\n        return adaptive_filter(arr, window_size)\n    w = int(window_size)\n    if w % 2 == 0:\n        w += 1\n    w = max(w, polyorder + 2)\n    if w % 2 == 0:\n        w += 1\n    return signal.savgol_filter(arr, window_length=w, polyorder=polyorder, mode='interp')\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Dispatch to the selected filtering algorithm.\n\n    algorithm_type options:\n        \"basic\"   \u2013 simple moving average\n        \"enhanced\"\u2013 EWMA (default)\n        \"exp\"     \u2013 exponential smoothing\n        \"savgol\"  \u2013 Savitzky\u2011Golay (fallback to basic)\n        \"hybrid\"  \u2013 EWMA followed by exponential smoothing\n    \"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"enhanced\":\n        return weighted_filter(input_signal, window_size)\n    if alg == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n    if alg == \"savgol\":\n        return _savgol_filter(input_signal, window_size)\n    if alg == \"hybrid\":\n        tmp = weighted_filter(input_signal, window_size)\n        return exponential_smoothing(tmp, window_size)\n    # Default to enhanced for unknown types\n    return weighted_filter(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4147), Performs well on output_length (91.0000), Performs well on overall_score (0.3667), Performs well on slope_changes (64.2000), Performs well on lag_error (1.0255), Performs well on avg_error (1.3708), Performs well on false_reversals (52.4000), Performs well on correlation (0.2667), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.2375), Performs well on responsiveness_score (0.4937), Performs well on accuracy_score (0.2667), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0009), Performs well on success_rate (1.0000)\n\n### Program 3 (Score: 13.4402)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\ndef _prepare_input(x, window):\n    \"\"\"Validate *window* and convert *x* to a 1\u2011D float array.\n\n    Returns an empty array when the signal is shorter than *window* so callers can\n    handle the situation gracefully.\n    \"\"\"\n    ws = int(window)\n    if ws <= 0:\n        raise ValueError(\"window size must be positive\")\n    arr = np.asarray(x, dtype=float).ravel()\n    if arr.size < ws:\n        return np.empty(0, dtype=float), ws\n    return arr, ws\n\n@lru_cache(maxsize=32)\ndef _exp_weights(ws):\n    \"\"\"Pre\u2011compute exponential weights for EWMA.\"\"\"\n    w = np.exp(np.linspace(-2, 0, ws))\n    return w / w.sum()\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Fast simple moving\u2011average using cumulative sum.\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    csum = np.cumsum(np.insert(arr, 0, 0.0))\n    return (csum[ws:] - csum[:-ws]) / ws\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"Exponentially weighted moving\u2011average (valid convolution).\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    kernel = _exp_weights(ws)\n    return np.convolve(arr, kernel, mode='valid')\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; output aligns with other filters.\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    alpha = 2.0 / (ws + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[ws - 1 :]\n\ndef _savgol_filter(x, window_size=20, polyorder=3):\n    \"\"\"Savitzky\u2011Golay filter with safe fallback to basic MA.\"\"\"\n    try:\n        from scipy.signal import savgol_filter\n    except Exception:\n        return adaptive_filter(x, window_size)\n\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n\n    w = int(ws)\n    if w % 2 == 0:\n        w += 1\n    w = max(w, polyorder + 2)\n    if w % 2 == 0:\n        w += 1\n    return savgol_filter(arr, window_length=w, polyorder=polyorder, mode='interp')\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Dispatch to the selected filtering algorithm.\n\n    Supported ``algorithm_type`` values (case\u2011insensitive):\n        \"basic\"   \u2013 simple moving average\n        \"enhanced\"\u2013 EWMA (default)\n        \"exp\"     \u2013 exponential smoothing\n        \"savgol\"  \u2013 Savitzky\u2011Golay (fallback to basic)\n        \"hybrid\"  \u2013 EWMA followed by exponential smoothing\n    \"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    if alg == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n    if alg == \"savgol\":\n        return _savgol_filter(input_signal, window_size)\n    if alg == \"hybrid\":\n        tmp = enhanced_filter_with_trend_preservation(input_signal, window_size)\n        return exponential_smoothing(tmp, window_size)\n\n    # Fallback to enhanced for unknown types\n    return enhanced_filter_with_trend_preservation(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4147), Performs well on output_length (91.0000), Performs well on overall_score (0.3667), Performs well on slope_changes (64.2000), Performs well on lag_error (1.0255), Performs well on avg_error (1.3708), Performs well on false_reversals (52.4000), Performs well on correlation (0.2667), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.2375), Performs well on responsiveness_score (0.4937), Performs well on accuracy_score (0.2667), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0005), Performs well on success_rate (1.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 13.4402)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nReal-Time Adaptive Signal Processing Algorithm for Non-Stationary Time Series\n\"\"\"\nimport numpy as np\n\ndef adaptive_filter(x, window_size=20):\n    if len(x) < window_size:\n        raise ValueError(f\"Input length ({len(x)}) < window_size ({window_size})\")\n    return np.convolve(x, np.ones(window_size) / window_size, mode='valid')\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    if len(x) < window_size:\n        raise ValueError(f\"Input length ({len(x)}) < window_size ({window_size})\")\n    w = np.exp(np.linspace(-2, 0, window_size))\n    w /= w.sum()\n    return np.convolve(x, w, mode='valid')\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    func = enhanced_filter_with_trend_preservation if algorithm_type == \"enhanced\" else adaptive_filter\n    return func(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to composite_score\n\n### Program D2 (Score: 13.4402)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\ndef _validate_window(window_size: int) -> int:\n    \"\"\"Validate and normalize the window size.\"\"\"\n    if not isinstance(window_size, (int, np.integer)):\n        raise TypeError(f\"window_size must be an integer, got {type(window_size).__name__}\")\n    ws = int(window_size)\n    if ws <= 0:\n        raise ValueError(f\"window_size must be positive, got {ws}\")\n    return ws\n\ndef _to_array(x, window_size):\n    \"\"\"Convert input to a 1\u2011D float array and ensure it meets the window requirement.\"\"\"\n    ws = _validate_window(window_size)\n    arr = np.asarray(x, dtype=float)\n    if arr.ndim != 1:\n        raise ValueError(\"Input signal must be one\u2011dimensional\")\n    if arr.size < ws:\n        raise ValueError(f\"Input length ({arr.size}) must be >= window_size ({ws})\")\n    return arr, ws\n\n@lru_cache(maxsize=32)\ndef _exp_weights(ws: int):\n    \"\"\"Pre\u2011compute exponential weights for a given window size.\"\"\"\n    w = np.exp(np.linspace(-2, 0, ws))\n    return w / w.sum()\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Simple moving\u2011average filter (valid convolution).\"\"\"\n    arr, ws = _to_array(x, window_size)\n    kernel = np.ones(ws, dtype=float) / ws\n    return np.convolve(arr, kernel, mode='valid')\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"Exponentially weighted moving\u2011average filter (valid convolution).\"\"\"\n    arr, ws = _to_array(x, window_size)\n    kernel = _exp_weights(ws)\n    return np.convolve(arr, kernel, mode='valid')\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; output aligned with other filters.\"\"\"\n    arr, ws = _to_array(x, window_size)\n    alpha = 2.0 / (ws + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[ws - 1 :]\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Dispatch to the selected filtering algorithm.\n\n    Parameters\n    ----------\n    input_signal : array\u2011like\n        Raw time\u2011series data.\n    window_size : int, optional\n        Size of the sliding window (default 20).\n    algorithm_type : str, optional\n        One of ``\"basic\"``, ``\"enhanced\"``, ``\"exp\"`` (case\u2011insensitive).\n\n    Returns\n    -------\n    numpy.ndarray\n        Filtered signal with length ``len(input_signal) - window_size + 1``.\n    \"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    if alg == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n\n    raise ValueError(\n        f\"Unsupported algorithm_type '{algorithm_type}'. \"\n        \"Supported types are: 'basic', 'enhanced', 'exp'.\"\n    )\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to composite_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 10.5559, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\ntry:\n    from scipy.signal import savgol_filter\n    _HAS_SAVGOL = True\nexcept Exception:\n    _HAS_SAVGOL = False\n\n\ndef _validate_input(x, window_size):\n    \"\"\"Convert to ndarray and ensure minimum length.\"\"\"\n    x = np.asarray(x, dtype=float)\n    if x.size == 0:\n        return x\n    if x.size < window_size:\n        raise ValueError(f\"Input length ({x.size}) < window_size ({window_size})\")\n    return x\n\n\ndef _apply_savgol(x, win, polyorder=3):\n    \"\"\"Savitzky\u2011Golay with safe handling of window size.\"\"\"\n    if not _HAS_SAVGOL:\n        return np.convolve(x, np.ones(win) / win, mode='valid')\n    w = int(win)\n    if w % 2 == 0:\n        w += 1\n    w = max(w, polyorder + 2)\n    if w % 2 == 0:\n        w += 1\n    if w > x.size:\n        w = x.size if x.size % 2 else x.size - 1\n    return savgol_filter(x, window_length=w, polyorder=polyorder, mode='interp')\n\n\ndef _adaptive_window(base, sig):\n    \"\"\"Map signal variability to an odd window size between 5 and base.\"\"\"\n    cv = np.std(sig) / (np.mean(np.abs(sig)) + 1e-9)\n    cv = max(0.0, min(cv, 1.0))\n    win = int(5 + (base - 5) * (1 - cv))\n    if win % 2 == 0:\n        win += 1\n    return max(5, win)\n\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Simple moving\u2011average filter.\"\"\"\n    x = _validate_input(x, window_size)\n    if x.size == 0:\n        return np.array([], dtype=float)\n    return np.convolve(x, np.ones(window_size) / window_size, mode='valid')\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"EWMA \u2192 adaptive Savitzky\u2011Golay \u2192 short MA.\"\"\"\n    x = _validate_input(x, window_size)\n    if x.size == 0:\n        return np.array([], dtype=float)\n\n    # 1\ufe0f\u20e3 exponential weighting\n    w = np.exp(np.linspace(-2, 0, window_size))\n    w /= w.sum()\n    ewma = np.convolve(x, w, mode='valid')\n\n    # 2\ufe0f\u20e3 adaptive Savitzky\u2011Golay\n    aw = _adaptive_window(window_size, ewma)\n    sg = _apply_savgol(ewma, aw, polyorder=2)\n\n    # 3\ufe0f\u20e3 final 3\u2011point moving average\n    if sg.size < 3:\n        return sg\n    return np.convolve(sg, np.ones(3) / 3, mode='valid')\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Dispatch to the selected filtering algorithm.\n    \"\"\"\n    if algorithm_type == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if algorithm_type == \"savgol\":\n        return _apply_savgol(_validate_input(input_signal, window_size), window_size, polyorder=3)\n    return enhanced_filter_with_trend_preservation(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (89.000)\n\n### Inspiration 2 (Score: 0.0000, Type: Exploratory)\n```python\n# EVOLVE-BLOCK-START\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Simple moving\u2011average filter.\"\"\"\n    x = np.asarray(x, dtype=float)\n    if x.size < window_size:\n        raise ValueError(f\"Input length ({x.size}) < window_size ({window_size})\")\n    kernel = np.ones(window_size) / window_size\n    return np.convolve(x, kernel, mode='valid')\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"Weighted (exponential) moving\u2011average filter.\"\"\"\n    x = np.asarray(x, dtype=float)\n    if x.size < window_size:\n        raise ValueError(f\"Input length ({x.size}) < window_size ({window_size})\")\n    w = np.exp(np.linspace(-2, 0, window_size))\n    w /= w.sum()\n    return np.convolve(x, w, mode='valid')\n\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; returns output aligned with other filters.\"\"\"\n    x = np.asarray(x, dtype=float)\n    if x.size < window_size:\n        raise ValueError(f\"Input length ({x.size}) < window_size ({window_size})\")\n    alpha = 2.0 / (window_size + 1.0)\n    y = np.empty_like(x)\n    y[0] = x[0]\n    for i in range(1, x.size):\n        y[i] = alpha * x[i] + (1.0 - alpha) * y[i - 1]\n    # discard the first (window_size\u20111) samples to match 'valid' length\n    return y[window_size - 1:]\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"Dispatch to the selected filtering algorithm.\"\"\"\n    if algorithm_type == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if algorithm_type == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    if algorithm_type == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n    raise ValueError(f\"Unknown algorithm_type: {algorithm_type}\")\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Alternative runs_successfully approach, NumPy-based implementation\n\n### Inspiration 3 (Score: 9.4583, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\nfrom typing import Tuple, Callable\n\n\ndef _prepare_input(x, window: int) -> Tuple[np.ndarray, int]:\n    \"\"\"Validate *window* and convert *x* to a 1\u2011D float array.\n\n    Returns an empty array when the signal is shorter than *window* so callers can\n    handle the situation gracefully.\n    \"\"\"\n    ws = int(window)\n    if ws <= 0:\n        raise ValueError(\"window_size must be positive\")\n    arr = np.asarray(x, dtype=float).ravel()\n    if arr.size < ws:\n        return np.empty(0, dtype=float), ws\n    return arr, ws\n\n\n@lru_cache(maxsize=32)\ndef _exp_weights(ws: int) -> np.ndarray:\n    \"\"\"Exponentially\u2011decaying weights for EWMA.\"\"\"\n    w = np.exp(np.linspace(-2, 0, ws))\n    return w / w.sum()\n\n\ndef adaptive_filter(x, window_size: int = 20) -> np.ndarray:\n    \"\"\"Simple moving\u2011average (valid convolution).\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    return np.convolve(arr, np.ones(ws) / ws, mode=\"valid\")\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size: int = 20) -> np.ndarray:\n    \"\"\"EWMA \u2192 adaptive Savitzky\u2011Golay \u2192 short MA (length\u202f5).\n\n    This pipeline gives stronger noise reduction while keeping signal dynamics.\n    \"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n\n    # 1\ufe0f\u20e3 EWMA (valid convolution)\n    ewma = np.convolve(arr, _exp_weights(ws), mode=\"valid\")\n\n    # 2\ufe0f\u20e3 Adaptive Savitzky\u2011Golay window based on signal variability\n    sg = _apply_savgol(ewma, ws)\n\n    # 3\ufe0f\u20e3 Final short moving average to remove any high\u2011frequency residue\n    final = np.convolve(sg, np.ones(5) / 5, mode=\"valid\")\n    return final\n\n\ndef exponential_smoothing(x, window_size: int = 20) -> np.ndarray:\n    \"\"\"Recursive exponential smoothing; output aligns with other filters.\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    alpha = 2.0 / (ws + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[ws - 1 :]\n\n\ndef _apply_savgol(signal: np.ndarray, base_ws: int, polyorder: int = 3) -> np.ndarray:\n    \"\"\"Apply Savitzky\u2011Golay with an adaptive window length.\n\n    If SciPy is unavailable, falls back to a simple moving average.\n    \"\"\"\n    try:\n        from scipy import signal as scipy_signal\n    except Exception:\n        # Fallback \u2013 simple moving average with the original window size\n        return np.convolve(signal, np.ones(base_ws) / base_ws, mode=\"valid\")\n\n    # Compute a scale factor from variance\u2011to\u2011mean\u2011abs ratio\n    var_ratio = np.var(signal) / (np.mean(np.abs(signal)) + 1e-9)\n    scale = np.clip(var_ratio, 0.5, 2.0)  # keep window reasonable\n    adaptive_len = int(max(polyorder + 2, min(base_ws * 2, base_ws * scale)))\n    # Ensure odd length\n    if adaptive_len % 2 == 0:\n        adaptive_len += 1\n    # Final safety check\n    adaptive_len = max(adaptive_len, polyorder + 2)\n    if adaptive_len % 2 == 0:\n        adaptive_len += 1\n\n    return scipy_signal.savgol_filter(signal, window_length=adaptive_len,\n                                     polyorder=polyorder, mode=\"interp\")\n\n\ndef process_signal(input_signal, window_size: int = 20, algorithm_type: str = \"enhanced\") -> np.ndarray:\n    \"\"\"Dispatch to the requested filtering algorithm.\n\n    Supported ``algorithm_type`` values (case\u2011insensitive):\n        \"basic\"   \u2013 simple moving average\n        \"enhanced\"\u2013 EWMA \u2192 adaptive Savitzky\u2011Golay \u2192 short MA (default)\n        \"exp\"     \u2013 exponential smoothing\n        \"savgol\"  \u2013 pure Savitzky\u2011Golay (fallback to basic)\n        \"hybrid\"  \u2013 EWMA followed by exponential smoothing\n    \"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    if alg == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n    if alg == \"savgol\":\n        arr, ws = _prepare_input(input_signal, window_size)\n        return _apply_savgol(arr, ws) if arr.size else arr\n    if alg == \"hybrid\":\n        tmp = enhanced_filter_with_trend_preservation(input_signal, window_size)\n        return exponential_smoothing(tmp, window_size)\n\n    # Default fallback\n    return enhanced_filter_with_trend_preservation(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (87.000)\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\ndef _as_array(x, window_size):\n    \"\"\"Validate input and convert to a 1\u2011D NumPy float array.\n\n    Returns\n    -------\n    tuple (arr, ws)\n        arr \u2013 NumPy array of the data\n        ws  \u2013 validated integer window size\n    \"\"\"\n    arr = np.asarray(x, dtype=float)\n    if arr.ndim != 1:\n        raise ValueError(\"Input signal must be one\u2011dimensional\")\n    ws = int(window_size)\n    if ws <= 0:\n        raise ValueError(\"window_size must be a positive integer\")\n    if arr.size < ws:\n        raise ValueError(f\"Input length ({arr.size}) < window_size ({ws})\")\n    return arr, ws\n\n\nfrom functools import lru_cache\n\n@lru_cache(maxsize=32)\ndef _exp_weights(ws):\n    \"\"\"Pre\u2011compute exponential weights for a given window size.\"\"\"\n    w = np.exp(np.linspace(-2, 0, ws))\n    return w / w.sum()\n\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Fast simple moving\u2011average using cumulative sum.\"\"\"\n    arr, ws = _as_array(x, window_size)\n    csum = np.cumsum(np.insert(arr, 0, 0.0))\n    return (csum[ws:] - csum[:-ws]) / ws\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"Exponentially weighted moving\u2011average filter (valid convolution).\"\"\"\n    arr, ws = _as_array(x, window_size)\n    kernel = _exp_weights(ws)\n    return np.convolve(arr, kernel, mode=\"valid\")\n\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; output length matches other filters.\"\"\"\n    arr, ws = _as_array(x, window_size)\n    alpha = 2.0 / (ws + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[ws - 1:]\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"Dispatch to the selected filtering algorithm (case\u2011insensitive).\"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    if alg in (\"exp\", \"exponential\"):\n        return exponential_smoothing(input_signal, window_size)\n    # Fallback to enhanced for unknown types to keep processing robust\n    return enhanced_filter_with_trend_preservation(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\n\n# Task\nImprove the code to maximize FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\n\n## CRITICAL INSTRUCTIONS\nIf the code contains `# EVOLVE-BLOCK-START` and `# EVOLVE-BLOCK-END` markers:\n- Output ONLY the code that goes BETWEEN these markers\n- Do NOT include the markers themselves\n- Do NOT include code outside the markers (like `run_packing()`)\n- The system will automatically merge your output with the preserved sections\n\nIf there are NO EVOLVE-BLOCK markers:\n- Output the complete rewritten program\n\n```python\n# Your improved code here (ONLY the evolve block content if markers exist)\n```", "responses": ["import numpy as np\nfrom functools import lru_cache\n\ndef _as_array(x, window_size):\n    \"\"\"Validate input and convert to 1\u2011D float array.\n\n    Returns an empty array when the signal is shorter than the window so\n    callers can handle it gracefully.\n    \"\"\"\n    arr = np.asarray(x, dtype=float)\n    if arr.ndim != 1:\n        raise ValueError(\"Input signal must be one\u2011dimensional\")\n    ws = int(window_size)\n    if ws <= 0:\n        raise ValueError(\"window_size must be a positive integer\")\n    if arr.size < ws:\n        # Graceful handling of too\u2011short signals\n        return np.empty(0, dtype=float), ws\n    return arr, ws\n\n@lru_cache(maxsize=32)\ndef _exp_weights(ws):\n    \"\"\"Pre\u2011compute exponential weights for a given window size.\"\"\"\n    w = np.exp(np.linspace(-2, 0, ws))\n    return w / w.sum()\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Fast simple moving\u2011average using cumulative sum.\"\"\"\n    arr, ws = _as_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    csum = np.cumsum(np.insert(arr, 0, 0.0))\n    return (csum[ws:] - csum[:-ws]) / ws\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"Exponentially weighted moving\u2011average (valid convolution).\"\"\"\n    arr, ws = _as_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    kernel = _exp_weights(ws)\n    return np.convolve(arr, kernel, mode=\"valid\")\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; output length matches other filters.\"\"\"\n    arr, ws = _as_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    alpha = 2.0 / (ws + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[ws - 1 :]\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"Dispatch to the selected filtering algorithm (case\u2011insensitive).\"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    if alg in (\"exp\", \"exponential\"):\n        return exponential_smoothing(input_signal, window_size)\n    # Fallback to enhanced for unknown types\n    return enhanced_filter_with_trend_preservation(input_signal, window_size)"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}