{"id": "b52b4e73-ef07-41b9-964c-8cf7bad8a729", "code": "# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\nfrom typing import Callable, Dict, Tuple\n\n\ndef _validate_window(window_size: int) -> int:\n    \"\"\"Validate that ``window_size`` is a positive integer.\"\"\"\n    if not isinstance(window_size, (int, np.integer)):\n        raise TypeError(f\"window_size must be an integer, got {type(window_size).__name__}\")\n    ws = int(window_size)\n    if ws <= 0:\n        raise ValueError(f\"window_size must be positive, got {ws}\")\n    return ws\n\n\ndef _prepare_signal(x, window_size: int) -> np.ndarray:\n    \"\"\"\n    Convert *x* to a 1\u2011D ``np.ndarray`` of ``float`` and enforce the minimum\n    length required for a ``valid`` convolution.\n\n    If the input is shorter than ``window_size`` an empty array is returned,\n    allowing callers to handle the edge case gracefully.\n    \"\"\"\n    ws = _validate_window(window_size)\n    arr = np.asarray(x, dtype=float)\n    if arr.ndim != 1:\n        raise ValueError(\"Input signal must be one\u2011dimensional\")\n    if arr.size < ws:\n        return np.array([], dtype=float)\n    return arr\n\n\n@lru_cache(maxsize=32)\ndef _gaussian_weights(window_size: int) -> np.ndarray:\n    \"\"\"\n    Return a normalized Gaussian kernel of length ``window_size``.\n    The kernel is centred and uses ``sigma = max(window/6, 0.1)`` so that\n    \u00b13\u03c3 \u2248 window size.\n    \"\"\"\n    ws = _validate_window(window_size)\n    sigma = max(ws / 6.0, 0.1)\n    centre = (ws - 1) / 2.0\n    idx = np.arange(ws)\n    w = np.exp(-0.5 * ((idx - centre) / sigma) ** 2)\n    return w / w.sum()\n\n\n@lru_cache(maxsize=32)\ndef _exp_weights(window_size: int) -> np.ndarray:\n    \"\"\"\n    Return a normalized exponential\u2011decay weighting vector.\n    Used by the enhanced filter when SciPy is unavailable.\n    \"\"\"\n    ws = _validate_window(window_size)\n    w = np.exp(np.linspace(-2, 0, ws))\n    return w / w.sum()\n\n\ndef adaptive_filter(x, window_size: int = 20) -> np.ndarray:\n    \"\"\"Simple moving\u2011average filter using a cumulative\u2011sum implementation.\"\"\"\n    arr = _prepare_signal(x, window_size)\n    if arr.size == 0:\n        return arr\n    ws = len(arr) if isinstance(window_size, np.ndarray) else window_size\n    csum = np.cumsum(np.insert(arr, 0, 0.0))\n    return (csum[ws:] - csum[:-ws]) / ws\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size: int = 20) -> np.ndarray:\n    \"\"\"\n    Gaussian\u2011weighted moving average.  If SciPy's Savitzky\u2011Golay is available,\n    that implementation is preferred via ``_savgol_filter``; otherwise we fall back\n    to a Gaussian kernel.\n    \"\"\"\n    arr = _prepare_signal(x, window_size)\n    if arr.size == 0:\n        return arr\n    w = _gaussian_weights(window_size)\n    return np.convolve(arr, w, mode=\"valid\")\n\n\ndef _savgol_filter(x, window_size: int = 20, polyorder: int = 3) -> np.ndarray:\n    \"\"\"\n    Apply SciPy's Savitzky\u2011Golay filter with safe parameter handling.\n    If SciPy cannot be imported or the parameters are invalid, fall back to\n    the Gaussian\u2011weighted enhanced filter.\n    \"\"\"\n    arr = _prepare_signal(x, window_size)\n    if arr.size == 0:\n        return arr\n    try:\n        from scipy import signal\n\n        w = int(window_size)\n        if w % 2 == 0:\n            w += 1\n        w = max(w, polyorder + 2)\n        if w % 2 == 0:\n            w += 1\n        # Ensure the window does not exceed the signal length\n        w = min(w, arr.size if arr.size % 2 else arr.size - 1)\n        return signal.savgol_filter(arr, window_length=w, polyorder=polyorder, mode=\"interp\")\n    except Exception:\n        # Graceful fallback\n        return enhanced_filter_with_trend_preservation(arr, window_size)\n\n\ndef hybrid_filter(x, window_size: int = 20) -> np.ndarray:\n    \"\"\"\n    Two\u2011stage filter: first a Gaussian\u2011weighted MA, then a simple MA.\n    The second convolution further reduces the length, mirroring the\n    behaviour of the original implementation.\n    \"\"\"\n    first_pass = enhanced_filter_with_trend_preservation(x, window_size)\n    if first_pass.size == 0:\n        return first_pass\n    ws = _validate_window(window_size)\n    return np.convolve(first_pass, np.ones(ws) / ws, mode=\"valid\")\n\n\ndef _dispatch_map() -> Dict[str, Callable]:\n    \"\"\"Mapping from algorithm name to the corresponding function.\"\"\"\n    return {\n        \"basic\": adaptive_filter,\n        \"enhanced\": enhanced_filter_with_trend_preservation,\n        \"savgol\": _savgol_filter,\n        \"hybrid\": hybrid_filter,\n    }\n\n\ndef process_signal(\n    input_signal,\n    window_size: int = 20,\n    algorithm_type: str = \"enhanced\",\n) -> np.ndarray:\n    \"\"\"\n    Dispatch to a filtering algorithm.\n\n    Parameters\n    ----------\n    input_signal : array\u2011like\n        Raw time\u2011series data.\n    window_size : int, optional\n        Length of the sliding window (default 20).\n    algorithm_type : str, optional\n        One of ``\"basic\"``, ``\"enhanced\"``, ``\"savgol\"``, ``\"hybrid\"``.\n        Case\u2011insensitive; defaults to ``\"enhanced\"``.\n\n    Returns\n    -------\n    np.ndarray\n        Filtered signal; may be empty if the input is shorter than the window.\n    \"\"\"\n    alg = algorithm_type.lower()\n    func = _dispatch_map().get(alg)\n    if func is None:\n        raise ValueError(\n            f\"Unsupported algorithm_type '{algorithm_type}'. \"\n            \"Supported types: basic, enhanced, savgol, hybrid.\"\n        )\n    return func(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n", "language": "python", "parent_id": "c0cfd7a1-1a06-4c24-b486-21a87d7d89ea", "generation": 4, "timestamp": 1764937277.669745, "iteration_found": 101, "metrics": {"runs_successfully": 1.0, "composite_score": 0.46132250979957695, "output_length": 91.0, "overall_score": 0.410758833233438, "slope_changes": 39.4, "lag_error": 1.3430791880825177, "avg_error": 1.4104893257323385, "false_reversals": 34.2, "correlation": 0.29444880986769884, "noise_reduction": 0.0, "smoothness_score": 0.3367003367003367, "responsiveness_score": 0.42678881921116796, "accuracy_score": 0.29444880986769884, "efficiency_score": 1.0, "execution_time": 0.0003566265106201172, "success_rate": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Evolve block rewrite (preserved external code)", "parent_metrics": {"runs_successfully": 0.0, "error": "Stage 1 error: name 'np' is not defined"}, "island": 1}, "prompts": {"full_rewrite_user": {"system": "## CRITICAL FORMAT REQUIREMENTS (DO NOT VIOLATE)\n## OUTPUT FORMAT (CRITICAL)\n- Output ONLY the code that goes BETWEEN the `# EVOLVE-BLOCK-START` and `# EVOLVE-BLOCK-END` markers\n- Do NOT include the markers themselves in your output\n- Do NOT include any code outside the markers (imports, run_packing, etc.)\n- The system will automatically merge your output with the preserved code sections\n\n## FOCUS\n- Improve ONLY the `construct_packing()` function and helper functions within the evolve block\n- Functions like `run_packing()` are preserved automatically - do not include them\n\nViolating these requirements will cause the program to fail evaluation.\n\n---\n\nYou are an expert Python developer tasked with evolving the `construct_packing()` function and any helper functions that reside inside the **EVOLVE BLOCK**.  \n\n**Your output must follow these strict rules:**  \n- **Only** output the code that belongs **between** the `# EVOLVE-BLOCK-START` and `# EVOLVE-BLOCK-END` markers.  \n- **Do not** include the markers themselves, any import statements, the surrounding `run_packing()` wrapper, or any other code outside the block.  \n- The system will automatically merge your output with the preserved surrounding code.\n\n**What you must improve:**  \n1. **Correctness:** Ensure `construct_packing()` returns a list of item\u2011to\u2011box assignments that satisfy all constraints (capacity, weight limits, forbidden pairings, etc.).  \n2. **Determinism:** Avoid random choices; the function should produce the same valid packing for identical inputs.  \n3. **Clarity:** Use descriptive variable names, docstrings, and type hints.  \n4. **Modularity:** If new helper functions are needed, define them **inside** the evolve block and call them from `construct_packing()`.  \n\n**Strategies you should try (and must not repeat the failures above):**  \n- **Greedy fit with backtracking:** Sort items by descending size/weight, place each into the first box that can accommodate it, and backtrack when a dead\u2011end is reached.  \n- **Constraint\u2011driven filtering:** Before attempting placement, pre\u2011compute allowable boxes for each item (respecting forbidden pairings) and prune impossible options early.  \n- **Box state tracking:** Keep a dictionary `{box_id: {\"capacity\": remaining_volume, \"weight\": remaining_weight}}` and update it atomically when an item is placed.  \n- **Validation pass:** After constructing the packing list, run a quick verification loop that raises a clear `ValueError` if any constraint is violated; this helps catch logic errors before the program exits.  \n- **Avoid global mutable state:** All data structures should be created inside the function (or its helpers) to prevent side\u2011effects between runs.  \n\n**What you must NOT do (explicitly forbidden):**  \n- Produce code that triggers high invalidity rates (e.g., overly aggressive heuristics that often leave items unplaced).  \n- Introduce randomness or nondeterministic loops that can cause different outputs on each run.  \n- Omit required return statements or return data in the wrong format.  \n- Include any code outside the evolve block, such as imports, `run_packing()`, or the marker comments themselves.  \n\n**Output format reminder:**  \n```\n# EVOLVE-BLOCK-START\n<your code here>\n# EVOLVE-BLOCK-END\n```\nYou must output **only** the `<your code here>` portion\u2014nothing else.", "user": "# Current Program Information\n- Fitness: 0.0000\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness declined: 13.4402 \u2192 0.0000. Consider revising recent changes.\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4147, output_length: 91.0000, overall_score: 0.3667, slope_changes: 64.2000, lag_error: 1.0255, avg_error: 1.3708, false_reversals: 52.4000, correlation: 0.2667, noise_reduction: 0.0000, smoothness_score: 0.2375, responsiveness_score: 0.4937, accuracy_score: 0.2667, efficiency_score: 1.0000, execution_time: 0.0005, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4147, output_length: 91.0000, overall_score: 0.3667, slope_changes: 64.2000, lag_error: 1.0255, avg_error: 1.3708, false_reversals: 52.4000, correlation: 0.2667, noise_reduction: 0.0000, smoothness_score: 0.2375, responsiveness_score: 0.4937, accuracy_score: 0.2667, efficiency_score: 1.0000, execution_time: 0.0009, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Unknown changes\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4200, output_length: 91.0000, overall_score: 0.3899, slope_changes: 66.0000, lag_error: 0.8697, avg_error: 1.2418, false_reversals: 55.2000, correlation: 0.3768, noise_reduction: 0.0000, smoothness_score: 0.2326, responsiveness_score: 0.5349, accuracy_score: 0.3768, efficiency_score: 1.0000, execution_time: 0.0018, success_rate: 1.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 13.7278)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nReal-Time Adaptive Signal Processing Algorithm for Non-Stationary Time Series\n\nThis algorithm implements a sliding window approach to filter volatile, non-stationary\ntime series data while minimizing noise and preserving signal dynamics.\n\"\"\"\nimport numpy as np\nfrom scipy import signal\nfrom collections import deque\n\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"\n    Adaptive signal processing algorithm using sliding window approach.\n\n    Args:\n        x: Input signal (1D array of real-valued samples)\n        window_size: Size of the sliding window (W samples)\n\n    Returns:\n        y: Filtered output signal with length = len(x) - window_size + 1\n    \"\"\"\n    if len(x) < window_size:\n        raise ValueError(f\"Input signal length ({len(x)}) must be >= window_size ({window_size})\")\n\n    # Initialize output array\n    output_length = len(x) - window_size + 1\n    y = np.zeros(output_length)\n\n    # Simple moving average as baseline\n    for i in range(output_length):\n        window = x[i : i + window_size]\n\n        # Basic moving average filter\n        y[i] = np.mean(window)\n\n    return y\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"\n    Enhanced version with trend preservation using weighted moving average.\n\n    Args:\n        x: Input signal (1D array of real-valued samples)\n        window_size: Size of the sliding window\n\n    Returns:\n        y: Filtered output signal\n    \"\"\"\n    if len(x) < window_size:\n        raise ValueError(f\"Input signal length ({len(x)}) must be >= window_size ({window_size})\")\n\n    output_length = len(x) - window_size + 1\n    y = np.zeros(output_length)\n\n    # Create weights that emphasize recent samples\n    weights = np.exp(np.linspace(-2, 0, window_size))\n    weights = weights / np.sum(weights)\n\n    for i in range(output_length):\n        window = x[i : i + window_size]\n\n        # Weighted moving average with exponential weights\n        y[i] = np.sum(window * weights)\n\n    return y\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Main signal processing function that applies the selected algorithm.\n\n    Args:\n        input_signal: Input time series data\n        window_size: Window size for processing\n        algorithm_type: Type of algorithm to use (\"basic\" or \"enhanced\")\n\n    Returns:\n        Filtered signal\n    \"\"\"\n    if algorithm_type == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    else:\n        return adaptive_filter(input_signal, window_size)\n\n\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4200), Performs well on output_length (91.0000), Performs well on overall_score (0.3899), Performs well on slope_changes (66.0000), Performs well on lag_error (0.8697), Performs well on avg_error (1.2418), Performs well on false_reversals (55.2000), Performs well on correlation (0.3768), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.2326), Performs well on responsiveness_score (0.5349), Performs well on accuracy_score (0.3768), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0018), Performs well on success_rate (1.0000)\n\n### Program 2 (Score: 13.4402)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nReal-Time Adaptive Signal Processing Algorithm for Non\u2011Stationary Time Series\n\nProvides several filtering strategies (basic moving\u2011average, weighted EWMA,\nexponential smoothing and optional Savitzky\u2011Golay) with safe fall\u2011backs.\n\"\"\"\nimport numpy as np\nfrom scipy import signal\n\ndef _to_array(x, window):\n    \"\"\"Convert input to 1\u2011D float array and validate length.\"\"\"\n    arr = np.asarray(x, dtype=float)\n    if arr.ndim != 1:\n        raise ValueError(\"Input signal must be 1\u2011D\")\n    if window <= 0:\n        raise ValueError(\"window_size must be positive\")\n    if arr.size < window:\n        # Return empty array \u2013 caller can handle gracefully\n        return np.array([], dtype=float)\n    return arr\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Fast simple moving average using cumulative sum.\"\"\"\n    arr = _to_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    csum = np.cumsum(np.insert(arr, 0, 0.0))\n    return (csum[window_size:] - csum[:-window_size]) / window_size\n\ndef weighted_filter(x, window_size=20):\n    \"\"\"Exponentially weighted moving average (EWMA).\"\"\"\n    arr = _to_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    w = np.exp(np.linspace(-2, 0, window_size))\n    w /= w.sum()\n    return np.convolve(arr, w, mode='valid')\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; output length matches other filters.\"\"\"\n    arr = _to_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    alpha = 2.0 / (window_size + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[window_size - 1 :]\n\ndef _savgol_filter(x, window_size=20, polyorder=3):\n    \"\"\"Savitzky\u2011Golay filter with safe parameter handling.\"\"\"\n    arr = _to_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    # SciPy's savgol_filter may be unavailable; fall back to basic MA\n    if not hasattr(signal, \"savgol_filter\"):\n        return adaptive_filter(arr, window_size)\n    w = int(window_size)\n    if w % 2 == 0:\n        w += 1\n    w = max(w, polyorder + 2)\n    if w % 2 == 0:\n        w += 1\n    return signal.savgol_filter(arr, window_length=w, polyorder=polyorder, mode='interp')\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Dispatch to the selected filtering algorithm.\n\n    algorithm_type options:\n        \"basic\"   \u2013 simple moving average\n        \"enhanced\"\u2013 EWMA (default)\n        \"exp\"     \u2013 exponential smoothing\n        \"savgol\"  \u2013 Savitzky\u2011Golay (fallback to basic)\n        \"hybrid\"  \u2013 EWMA followed by exponential smoothing\n    \"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"enhanced\":\n        return weighted_filter(input_signal, window_size)\n    if alg == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n    if alg == \"savgol\":\n        return _savgol_filter(input_signal, window_size)\n    if alg == \"hybrid\":\n        tmp = weighted_filter(input_signal, window_size)\n        return exponential_smoothing(tmp, window_size)\n    # Default to enhanced for unknown types\n    return weighted_filter(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4147), Performs well on output_length (91.0000), Performs well on overall_score (0.3667), Performs well on slope_changes (64.2000), Performs well on lag_error (1.0255), Performs well on avg_error (1.3708), Performs well on false_reversals (52.4000), Performs well on correlation (0.2667), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.2375), Performs well on responsiveness_score (0.4937), Performs well on accuracy_score (0.2667), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0009), Performs well on success_rate (1.0000)\n\n### Program 3 (Score: 13.4402)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nReal-Time Adaptive Signal Processing Algorithm for Non-Stationary Time Series\n\"\"\"\nimport numpy as np\n\ndef adaptive_filter(x, window_size=20):\n    if len(x) < window_size:\n        raise ValueError(f\"Input length ({len(x)}) < window_size ({window_size})\")\n    return np.convolve(x, np.ones(window_size) / window_size, mode='valid')\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    if len(x) < window_size:\n        raise ValueError(f\"Input length ({len(x)}) < window_size ({window_size})\")\n    w = np.exp(np.linspace(-2, 0, window_size))\n    w /= w.sum()\n    return np.convolve(x, w, mode='valid')\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    func = enhanced_filter_with_trend_preservation if algorithm_type == \"enhanced\" else adaptive_filter\n    return func(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4147), Performs well on output_length (91.0000), Performs well on overall_score (0.3667), Performs well on slope_changes (64.2000), Performs well on lag_error (1.0255), Performs well on avg_error (1.3708), Performs well on false_reversals (52.4000), Performs well on correlation (0.2667), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.2375), Performs well on responsiveness_score (0.4937), Performs well on accuracy_score (0.2667), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0005), Performs well on success_rate (1.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 13.4402)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\ndef _validate_window(window_size: int) -> int:\n    \"\"\"Validate and normalize the window size.\"\"\"\n    if not isinstance(window_size, (int, np.integer)):\n        raise TypeError(f\"window_size must be an integer, got {type(window_size).__name__}\")\n    ws = int(window_size)\n    if ws <= 0:\n        raise ValueError(f\"window_size must be positive, got {ws}\")\n    return ws\n\ndef _to_array(x, window_size):\n    \"\"\"Convert input to a 1\u2011D float array and ensure it meets the window requirement.\"\"\"\n    ws = _validate_window(window_size)\n    arr = np.asarray(x, dtype=float)\n    if arr.ndim != 1:\n        raise ValueError(\"Input signal must be one\u2011dimensional\")\n    if arr.size < ws:\n        raise ValueError(f\"Input length ({arr.size}) must be >= window_size ({ws})\")\n    return arr, ws\n\n@lru_cache(maxsize=32)\ndef _exp_weights(ws: int):\n    \"\"\"Pre\u2011compute exponential weights for a given window size.\"\"\"\n    w = np.exp(np.linspace(-2, 0, ws))\n    return w / w.sum()\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Simple moving\u2011average filter (valid convolution).\"\"\"\n    arr, ws = _to_array(x, window_size)\n    kernel = np.ones(ws, dtype=float) / ws\n    return np.convolve(arr, kernel, mode='valid')\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"Exponentially weighted moving\u2011average filter (valid convolution).\"\"\"\n    arr, ws = _to_array(x, window_size)\n    kernel = _exp_weights(ws)\n    return np.convolve(arr, kernel, mode='valid')\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; output aligned with other filters.\"\"\"\n    arr, ws = _to_array(x, window_size)\n    alpha = 2.0 / (ws + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[ws - 1 :]\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Dispatch to the selected filtering algorithm.\n\n    Parameters\n    ----------\n    input_signal : array\u2011like\n        Raw time\u2011series data.\n    window_size : int, optional\n        Size of the sliding window (default 20).\n    algorithm_type : str, optional\n        One of ``\"basic\"``, ``\"enhanced\"``, ``\"exp\"`` (case\u2011insensitive).\n\n    Returns\n    -------\n    numpy.ndarray\n        Filtered signal with length ``len(input_signal) - window_size + 1``.\n    \"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    if alg == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n\n    raise ValueError(\n        f\"Unsupported algorithm_type '{algorithm_type}'. \"\n        \"Supported types are: 'basic', 'enhanced', 'exp'.\"\n    )\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to composite_score\n\n### Program D2 (Score: 13.4402)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _as_array(x, window_size):\n    \"\"\"Convert input to 1\u2011D float array and validate window size.\"\"\"\n    arr = np.asarray(x, dtype=float)\n    ws = int(window_size)\n    if ws <= 0:\n        raise ValueError(\"window_size must be a positive integer\")\n    if arr.size < ws:\n        raise ValueError(f\"Input length ({arr.size}) < window_size ({ws})\")\n    return arr, ws\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Simple moving\u2011average filter.\"\"\"\n    arr, ws = _as_array(x, window_size)\n    return np.convolve(arr, np.ones(ws) / ws, mode=\"valid\")\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"Exponentially weighted moving\u2011average filter.\"\"\"\n    arr, ws = _as_array(x, window_size)\n    w = np.exp(np.linspace(-2, 0, ws))\n    w /= w.sum()\n    return np.convolve(arr, w, mode=\"valid\")\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; output length matches other filters.\"\"\"\n    arr, ws = _as_array(x, window_size)\n    alpha = 2.0 / (ws + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[ws - 1 :]\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"Dispatch to the selected filtering algorithm (case\u2011insensitive).\"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n    # default to enhanced for unknown or \"enhanced\"\n    return enhanced_filter_with_trend_preservation(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to composite_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 10.2847, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\ntry:\n    from scipy.signal import savgol_filter\n    _HAS_SAVGOL = True\nexcept Exception:\n    _HAS_SAVGOL = False\n\n\ndef _validate_input(x, window_size):\n    \"\"\"Convert to ndarray and ensure minimum length.\"\"\"\n    x = np.asarray(x, dtype=float)\n    if x.size == 0:\n        return x\n    if x.size < window_size:\n        raise ValueError(f\"Input length ({x.size}) < window_size ({window_size})\")\n    return x\n\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Simple moving\u2011average filter.\"\"\"\n    x = _validate_input(x, window_size)\n    if x.size == 0:\n        return np.array([], dtype=float)\n    return np.convolve(x, np.ones(window_size) / window_size, mode='valid')\n\n\ndef _apply_savgol(x, window_size, polyorder=3):\n    \"\"\"Savitzky\u2011Golay filter with safe parameter handling.\"\"\"\n    if not _HAS_SAVGOL:\n        return adaptive_filter(x, window_size)\n\n    w = int(window_size)\n    if w % 2 == 0:\n        w += 1\n    min_len = polyorder + 2\n    if w < min_len:\n        w = min_len + (min_len % 2 == 0)\n    return savgol_filter(x, window_length=w, polyorder=polyorder, mode='interp')\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"\n    Weighted EWMA \u2192 adaptive Savitzky\u2011Golay \u2192 short moving\u2011average.\n    \"\"\"\n    x = _validate_input(x, window_size)\n    if x.size == 0:\n        return np.array([], dtype=float)\n\n    # 1\ufe0f\u20e3 Exponential weighting (more recent samples get higher weight)\n    weights = np.exp(np.linspace(-2, 0, window_size))\n    weights /= weights.sum()\n    ewma = np.convolve(x, weights, mode='valid')\n\n    # 2\ufe0f\u20e3 Adaptive Savitzky\u2011Golay window based on signal variability\n    cv = np.std(ewma) / (np.mean(np.abs(ewma)) + 1e-9)  # coefficient of variation\n    # Map cv\u2208[0,\u221e) \u2192 window\u2208[5, window_size] (odd)\n    adaptive_win = int(5 + (window_size - 5) * min(cv, 1.0))\n    if adaptive_win % 2 == 0:\n        adaptive_win += 1\n    adaptive_win = max(5, adaptive_win)\n\n    sg = _apply_savgol(ewma, adaptive_win, polyorder=2)\n\n    # 3\ufe0f\u20e3 Final short moving\u2011average (3\u2011point) to clean high\u2011frequency residue\n    if sg.size < 3:\n        return sg\n    final = np.convolve(sg, np.ones(3) / 3, mode='valid')\n    return final\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Dispatch to the selected filtering algorithm.\n\n    algorithm_type:\n        \"basic\"   \u2013 simple moving average\n        \"savgol\" \u2013 pure Savitzky\u2011Golay (fallback to basic)\n        \"enhanced\" (default) \u2013 EWMA + adaptive Savitzky\u2011Golay + short MA\n    \"\"\"\n    if algorithm_type == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if algorithm_type == \"savgol\":\n        return _apply_savgol(input_signal, window_size, polyorder=3)\n    # default / \"enhanced\"\n    return enhanced_filter_with_trend_preservation(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (89.000)\n\n### Inspiration 2 (Score: 9.2349, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\ntry:\n    from scipy.signal import savgol_filter\n    _HAS_SAVGOL = True\nexcept Exception:\n    _HAS_SAVGOL = False\n\n\ndef _validate_input(x, window_size):\n    \"\"\"Validate input array and window size.\"\"\"\n    if not isinstance(window_size, int) or window_size <= 0:\n        raise ValueError(f\"window_size must be a positive integer, got {window_size}\")\n    x = np.asarray(x, dtype=float)\n    if x.ndim != 1:\n        raise ValueError(\"Input signal must be a 1\u2011D array\")\n    if x.size < window_size:\n        # Return an empty array to keep downstream processing safe\n        return x, np.empty(0, dtype=float)\n    return x, None\n\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Simple moving\u2011average filter using cumulative sum for O(n).\"\"\"\n    x, early = _validate_input(x, window_size)\n    if early is not None:\n        return early\n    cumsum = np.cumsum(np.insert(x, 0, 0.0))\n    return (cumsum[window_size:] - cumsum[:-window_size]) / window_size\n\n\ndef weighted_filter(x, window_size=20):\n    \"\"\"Exponential\u2011weighted moving average (enhanced filter).\"\"\"\n    x, early = _validate_input(x, window_size)\n    if early is not None:\n        return early\n    w = np.exp(np.linspace(-2, 0, window_size))\n    w /= w.sum()\n    return np.convolve(x, w, mode='valid')\n\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; output length matches other filters.\"\"\"\n    x, early = _validate_input(x, window_size)\n    if early is not None:\n        return early\n    alpha = 2.0 / (window_size + 1.0)\n    y = np.empty_like(x)\n    y[0] = x[0]\n    for i in range(1, x.size):\n        y[i] = alpha * x[i] + (1.0 - alpha) * y[i - 1]\n    return y[window_size - 1:]\n\n\ndef hybrid_filter(x, window_size=20):\n    \"\"\"Weighted filter followed by exponential smoothing.\"\"\"\n    weighted = weighted_filter(x, window_size)\n    if weighted.size == 0:\n        return weighted\n    return exponential_smoothing(weighted, window_size)\n\n\ndef _savgol_wrapper(x, window_size=20, polyorder=3):\n    \"\"\"Savitzky\u2011Golay filter with safe parameter handling.\"\"\"\n    x, early = _validate_input(x, window_size)\n    if early is not None:\n        return early\n    if not _HAS_SAVGOL:\n        return adaptive_filter(x, window_size)\n    w = int(window_size)\n    if w % 2 == 0:\n        w += 1\n    min_len = polyorder + 2\n    if w < min_len:\n        w = min_len\n        if w % 2 == 0:\n            w += 1\n    return savgol_filter(x, window_length=w, polyorder=polyorder, mode='interp')\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Dispatch to the selected filtering algorithm.\n\n    Supported algorithm_type values:\n        - \"basic\"   : simple moving average\n        - \"enhanced\": hybrid weighted + exponential smoothing\n        - \"exp\"     : exponential smoothing\n        - \"savgol\"  : Savitzky\u2011Golay (fallback to basic)\n        - \"hybrid\"  : alias for \"enhanced\"\n    \"\"\"\n    if algorithm_type == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if algorithm_type in (\"enhanced\", \"hybrid\"):\n        return hybrid_filter(input_signal, window_size)\n    if algorithm_type == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n    if algorithm_type == \"savgol\":\n        return _savgol_wrapper(input_signal, window_size)\n    raise ValueError(f\"Unknown algorithm_type: {algorithm_type}\")\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (82.000)\n\n### Inspiration 3 (Score: 10.5559, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\ntry:\n    from scipy.signal import savgol_filter\n    _HAS_SAVGOL = True\nexcept Exception:\n    _HAS_SAVGOL = False\n\n\ndef _validate_input(x, window_size):\n    \"\"\"Convert to ndarray and ensure minimum length.\"\"\"\n    x = np.asarray(x, dtype=float)\n    if x.size == 0:\n        return x\n    if x.size < window_size:\n        raise ValueError(f\"Input length ({x.size}) < window_size ({window_size})\")\n    return x\n\n\ndef _apply_savgol(x, win, polyorder=3):\n    \"\"\"Savitzky\u2011Golay with safe handling of window size.\"\"\"\n    if not _HAS_SAVGOL:\n        return np.convolve(x, np.ones(win) / win, mode='valid')\n    w = int(win)\n    if w % 2 == 0:\n        w += 1\n    w = max(w, polyorder + 2)\n    if w % 2 == 0:\n        w += 1\n    if w > x.size:\n        w = x.size if x.size % 2 else x.size - 1\n    return savgol_filter(x, window_length=w, polyorder=polyorder, mode='interp')\n\n\ndef _adaptive_window(base, sig):\n    \"\"\"Map signal variability to an odd window size between 5 and base.\"\"\"\n    cv = np.std(sig) / (np.mean(np.abs(sig)) + 1e-9)\n    cv = max(0.0, min(cv, 1.0))\n    win = int(5 + (base - 5) * (1 - cv))\n    if win % 2 == 0:\n        win += 1\n    return max(5, win)\n\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Simple moving\u2011average filter.\"\"\"\n    x = _validate_input(x, window_size)\n    if x.size == 0:\n        return np.array([], dtype=float)\n    return np.convolve(x, np.ones(window_size) / window_size, mode='valid')\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"EWMA \u2192 adaptive Savitzky\u2011Golay \u2192 short MA.\"\"\"\n    x = _validate_input(x, window_size)\n    if x.size == 0:\n        return np.array([], dtype=float)\n\n    # 1\ufe0f\u20e3 exponential weighting\n    w = np.exp(np.linspace(-2, 0, window_size))\n    w /= w.sum()\n    ewma = np.convolve(x, w, mode='valid')\n\n    # 2\ufe0f\u20e3 adaptive Savitzky\u2011Golay\n    aw = _adaptive_window(window_size, ewma)\n    sg = _apply_savgol(ewma, aw, polyorder=2)\n\n    # 3\ufe0f\u20e3 final 3\u2011point moving average\n    if sg.size < 3:\n        return sg\n    return np.convolve(sg, np.ones(3) / 3, mode='valid')\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Dispatch to the selected filtering algorithm.\n    \"\"\"\n    if algorithm_type == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if algorithm_type == \"savgol\":\n        return _apply_savgol(_validate_input(input_signal, window_size), window_size, polyorder=3)\n    return enhanced_filter_with_trend_preservation(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (89.000)\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\ndef _prepare_signal(x, window_size):\n    \"\"\"Validate and convert input to a 1\u2011D NumPy array.\n\n    Returns an empty array if the input is shorter than the window,\n    allowing callers to handle the case gracefully.\n    \"\"\"\n    if not isinstance(window_size, int) or window_size <= 0:\n        raise ValueError(f\"window_size must be a positive integer, got {window_size}\")\n    arr = np.asarray(x, dtype=float)\n    if arr.ndim != 1:\n        raise ValueError(\"Input signal must be one\u2011dimensional\")\n    if arr.size < window_size:\n        return np.array([], dtype=float)\n    return arr\n\n\ndef _gaussian_weights(window_size):\n    \"\"\"Create a normalized Gaussian kernel centered in the window.\"\"\"\n    sigma = max(window_size / 6.0, 0.1)  # \u00b13\u03c3 \u2248 window size\n    centre = (window_size - 1) / 2.0\n    idx = np.arange(window_size)\n    w = np.exp(-0.5 * ((idx - centre) / sigma) ** 2)\n    return w / w.sum()\n\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Simple moving\u2011average filter (valid convolution).\"\"\"\n    arr = _prepare_signal(x, window_size)\n    if arr.size == 0:\n        return arr\n    return np.convolve(arr, np.ones(window_size) / window_size, mode=\"valid\")\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"Gaussian\u2011weighted moving average (valid convolution).\"\"\"\n    arr = _prepare_signal(x, window_size)\n    if arr.size == 0:\n        return arr\n    w = _gaussian_weights(window_size)\n    return np.convolve(arr, w, mode=\"valid\")\n\n\ndef _savgol_filter(x, window_size=20, polyorder=3):\n    \"\"\"Savitzky\u2011Golay filter with safe fallback to Gaussian\u2011weighted MA.\"\"\"\n    arr = _prepare_signal(x, window_size)\n    if arr.size == 0:\n        return arr\n    try:\n        from scipy import signal\n\n        w = int(window_size)\n        if w % 2 == 0:\n            w += 1\n        w = max(w, polyorder + 2)\n        if w % 2 == 0:\n            w += 1\n        return signal.savgol_filter(arr, window_length=w, polyorder=polyorder, mode=\"interp\")\n    except Exception:\n        # If SciPy is unavailable or parameters are invalid, fall back\n        return enhanced_filter_with_trend_preservation(arr, window_size)\n\n\ndef hybrid_filter(x, window_size=20):\n    \"\"\"Apply enhanced filter followed by a simple moving average.\"\"\"\n    first_pass = enhanced_filter_with_trend_preservation(x, window_size)\n    if first_pass.size == 0:\n        return first_pass\n    # Second pass uses the same window size; result length is further reduced\n    return np.convolve(first_pass, np.ones(window_size) / window_size, mode=\"valid\")\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"Dispatch to a filtering algorithm (case\u2011insensitive).\"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    if alg == \"savgol\":\n        return _savgol_filter(input_signal, window_size)\n    if alg == \"hybrid\":\n        return hybrid_filter(input_signal, window_size)\n    raise ValueError(f\"Unknown algorithm_type: {algorithm_type}\")\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\n\n# Task\nImprove the code to maximize FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\n\n## CRITICAL INSTRUCTIONS\nIf the code contains `# EVOLVE-BLOCK-START` and `# EVOLVE-BLOCK-END` markers:\n- Output ONLY the code that goes BETWEEN these markers\n- Do NOT include the markers themselves\n- Do NOT include code outside the markers (like `run_packing()`)\n- The system will automatically merge your output with the preserved sections\n\nIf there are NO EVOLVE-BLOCK markers:\n- Output the complete rewritten program\n\n```python\n# Your improved code here (ONLY the evolve block content if markers exist)\n```", "responses": ["import numpy as np\nfrom functools import lru_cache\nfrom typing import Callable, Dict, Tuple\n\n\ndef _validate_window(window_size: int) -> int:\n    \"\"\"Validate that ``window_size`` is a positive integer.\"\"\"\n    if not isinstance(window_size, (int, np.integer)):\n        raise TypeError(f\"window_size must be an integer, got {type(window_size).__name__}\")\n    ws = int(window_size)\n    if ws <= 0:\n        raise ValueError(f\"window_size must be positive, got {ws}\")\n    return ws\n\n\ndef _prepare_signal(x, window_size: int) -> np.ndarray:\n    \"\"\"\n    Convert *x* to a 1\u2011D ``np.ndarray`` of ``float`` and enforce the minimum\n    length required for a ``valid`` convolution.\n\n    If the input is shorter than ``window_size`` an empty array is returned,\n    allowing callers to handle the edge case gracefully.\n    \"\"\"\n    ws = _validate_window(window_size)\n    arr = np.asarray(x, dtype=float)\n    if arr.ndim != 1:\n        raise ValueError(\"Input signal must be one\u2011dimensional\")\n    if arr.size < ws:\n        return np.array([], dtype=float)\n    return arr\n\n\n@lru_cache(maxsize=32)\ndef _gaussian_weights(window_size: int) -> np.ndarray:\n    \"\"\"\n    Return a normalized Gaussian kernel of length ``window_size``.\n    The kernel is centred and uses ``sigma = max(window/6, 0.1)`` so that\n    \u00b13\u03c3 \u2248 window size.\n    \"\"\"\n    ws = _validate_window(window_size)\n    sigma = max(ws / 6.0, 0.1)\n    centre = (ws - 1) / 2.0\n    idx = np.arange(ws)\n    w = np.exp(-0.5 * ((idx - centre) / sigma) ** 2)\n    return w / w.sum()\n\n\n@lru_cache(maxsize=32)\ndef _exp_weights(window_size: int) -> np.ndarray:\n    \"\"\"\n    Return a normalized exponential\u2011decay weighting vector.\n    Used by the enhanced filter when SciPy is unavailable.\n    \"\"\"\n    ws = _validate_window(window_size)\n    w = np.exp(np.linspace(-2, 0, ws))\n    return w / w.sum()\n\n\ndef adaptive_filter(x, window_size: int = 20) -> np.ndarray:\n    \"\"\"Simple moving\u2011average filter using a cumulative\u2011sum implementation.\"\"\"\n    arr = _prepare_signal(x, window_size)\n    if arr.size == 0:\n        return arr\n    ws = len(arr) if isinstance(window_size, np.ndarray) else window_size\n    csum = np.cumsum(np.insert(arr, 0, 0.0))\n    return (csum[ws:] - csum[:-ws]) / ws\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size: int = 20) -> np.ndarray:\n    \"\"\"\n    Gaussian\u2011weighted moving average.  If SciPy's Savitzky\u2011Golay is available,\n    that implementation is preferred via ``_savgol_filter``; otherwise we fall back\n    to a Gaussian kernel.\n    \"\"\"\n    arr = _prepare_signal(x, window_size)\n    if arr.size == 0:\n        return arr\n    w = _gaussian_weights(window_size)\n    return np.convolve(arr, w, mode=\"valid\")\n\n\ndef _savgol_filter(x, window_size: int = 20, polyorder: int = 3) -> np.ndarray:\n    \"\"\"\n    Apply SciPy's Savitzky\u2011Golay filter with safe parameter handling.\n    If SciPy cannot be imported or the parameters are invalid, fall back to\n    the Gaussian\u2011weighted enhanced filter.\n    \"\"\"\n    arr = _prepare_signal(x, window_size)\n    if arr.size == 0:\n        return arr\n    try:\n        from scipy import signal\n\n        w = int(window_size)\n        if w % 2 == 0:\n            w += 1\n        w = max(w, polyorder + 2)\n        if w % 2 == 0:\n            w += 1\n        # Ensure the window does not exceed the signal length\n        w = min(w, arr.size if arr.size % 2 else arr.size - 1)\n        return signal.savgol_filter(arr, window_length=w, polyorder=polyorder, mode=\"interp\")\n    except Exception:\n        # Graceful fallback\n        return enhanced_filter_with_trend_preservation(arr, window_size)\n\n\ndef hybrid_filter(x, window_size: int = 20) -> np.ndarray:\n    \"\"\"\n    Two\u2011stage filter: first a Gaussian\u2011weighted MA, then a simple MA.\n    The second convolution further reduces the length, mirroring the\n    behaviour of the original implementation.\n    \"\"\"\n    first_pass = enhanced_filter_with_trend_preservation(x, window_size)\n    if first_pass.size == 0:\n        return first_pass\n    ws = _validate_window(window_size)\n    return np.convolve(first_pass, np.ones(ws) / ws, mode=\"valid\")\n\n\ndef _dispatch_map() -> Dict[str, Callable]:\n    \"\"\"Mapping from algorithm name to the corresponding function.\"\"\"\n    return {\n        \"basic\": adaptive_filter,\n        \"enhanced\": enhanced_filter_with_trend_preservation,\n        \"savgol\": _savgol_filter,\n        \"hybrid\": hybrid_filter,\n    }\n\n\ndef process_signal(\n    input_signal,\n    window_size: int = 20,\n    algorithm_type: str = \"enhanced\",\n) -> np.ndarray:\n    \"\"\"\n    Dispatch to a filtering algorithm.\n\n    Parameters\n    ----------\n    input_signal : array\u2011like\n        Raw time\u2011series data.\n    window_size : int, optional\n        Length of the sliding window (default 20).\n    algorithm_type : str, optional\n        One of ``\"basic\"``, ``\"enhanced\"``, ``\"savgol\"``, ``\"hybrid\"``.\n        Case\u2011insensitive; defaults to ``\"enhanced\"``.\n\n    Returns\n    -------\n    np.ndarray\n        Filtered signal; may be empty if the input is shorter than the window.\n    \"\"\"\n    alg = algorithm_type.lower()\n    func = _dispatch_map().get(alg)\n    if func is None:\n        raise ValueError(\n            f\"Unsupported algorithm_type '{algorithm_type}'. \"\n            \"Supported types: basic, enhanced, savgol, hybrid.\"\n        )\n    return func(input_signal, window_size)"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}