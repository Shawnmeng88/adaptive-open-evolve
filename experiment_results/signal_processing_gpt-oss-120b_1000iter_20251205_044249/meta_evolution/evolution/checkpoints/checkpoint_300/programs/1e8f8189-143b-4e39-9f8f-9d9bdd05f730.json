{"id": "1e8f8189-143b-4e39-9f8f-9d9bdd05f730", "code": "# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef simple_ma(x, w):\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    return np.convolve(x, np.ones(w) / w, mode=\"valid\")\n\n\ndef weighted_ma(x, w):\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    weights = np.exp(np.linspace(-2, 0, w))\n    weights /= weights.sum()\n    return np.convolve(x, weights, mode=\"valid\")\n\n\ndef ema(x, w):\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    a = 2.0 / (w + 1)\n    out = np.empty_like(x)\n    out[0] = x[0]\n    for i in range(1, len(x)):\n        out[i] = a * x[i] + (1 - a) * out[i - 1]\n    return out[w - 1 :]\n\n\ndef detrended_weighted(x, w):\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    trend = simple_ma(x, w)\n    trend_full = np.concatenate((np.full(w - 1, trend[0]), trend))\n    detrended = x - trend_full\n    return weighted_ma(detrended, w)\n\n\ndef gaussian_ma(x, w):\n    \"\"\"Moving average with Gaussian weights.\"\"\"\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    sigma = max(w / 6.0, 0.1)\n    center = (w - 1) / 2.0\n    i = np.arange(w, dtype=float)\n    weights = np.exp(-0.5 * ((i - center) / sigma) ** 2)\n    weights /= weights.sum()\n    return np.convolve(x, weights, mode=\"valid\")\n\n\ndef median_ma(x, w):\n    \"\"\"Median filter (robust to spikes).\"\"\"\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    out_len = x.size - w + 1\n    out = np.empty(out_len, float)\n    for i in range(out_len):\n        out[i] = np.median(x[i : i + w])\n    return out\n\n\ndef _residual_variance(orig, filt):\n    m = min(len(orig), len(filt))\n    if m == 0:\n        return np.inf\n    return float(np.var(orig[:m] - filt[:m]))\n\n\ndef _select_best(x, w):\n    candidates = {\n        \"basic\": simple_ma(x, w),\n        \"weighted\": weighted_ma(x, w),\n        \"ema\": ema(x, w),\n        \"enhanced\": detrended_weighted(x, w),\n        \"gaussian\": gaussian_ma(x, w),\n        \"median\": median_ma(x, w),\n    }\n    best_key = min(candidates, key=lambda k: _residual_variance(x, candidates[k]))\n    return candidates[best_key]\n\n\ndef process_signal(sig, w=20, algo=\"enhanced\"):\n    if algo == \"basic\":\n        return simple_ma(sig, w)\n    if algo == \"weighted\":\n        return weighted_ma(sig, w)\n    if algo == \"ema\":\n        return ema(sig, w)\n    if algo == \"enhanced\":\n        return detrended_weighted(sig, w)\n    if algo == \"gaussian\":\n        return gaussian_ma(sig, w)\n    if algo == \"median\":\n        return median_ma(sig, w)\n    # Fallback to automatic selection\n    return _select_best(np.asarray(sig, float), w)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n", "language": "python", "parent_id": "dfe30497-85bf-4e0a-bbb5-b2debb7b81be", "generation": 6, "timestamp": 1764937590.291093, "iteration_found": 143, "metrics": {"runs_successfully": 1.0, "composite_score": 0.4429433309255678, "output_length": 91.0, "overall_score": 0.3624766970140094, "slope_changes": 68.6, "lag_error": 0.4099887786960041, "avg_error": 1.1150775516528053, "false_reversals": 56.6, "correlation": 0.20076318890739916, "noise_reduction": 0.0, "smoothness_score": 0.22573363431151244, "responsiveness_score": 0.709225502436145, "accuracy_score": 0.20076318890739916, "efficiency_score": 1.0, "execution_time": 0.00041518211364746096, "success_rate": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Evolve block rewrite (preserved external code)", "parent_metrics": {"runs_successfully": 1.0, "composite_score": 0.4429433309255678, "output_length": 91.0, "overall_score": 0.3624766970140094, "slope_changes": 68.6, "lag_error": 0.4099887786960041, "avg_error": 1.1150775516528053, "false_reversals": 56.6, "correlation": 0.20076318890739916, "noise_reduction": 0.0, "smoothness_score": 0.22573363431151244, "responsiveness_score": 0.709225502436145, "accuracy_score": 0.20076318890739916, "efficiency_score": 1.0, "execution_time": 0.0003750324249267578, "success_rate": 1.0}, "island": 3}, "prompts": {"full_rewrite_user": {"system": "## CRITICAL FORMAT REQUIREMENTS (DO NOT VIOLATE)\n## OUTPUT FORMAT (CRITICAL)\n- Output ONLY the code that goes BETWEEN the `# EVOLVE-BLOCK-START` and `# EVOLVE-BLOCK-END` markers\n- Do NOT include the markers themselves in your output\n- Do NOT include any code outside the markers (imports, run_packing, etc.)\n- The system will automatically merge your output with the preserved code sections\n\n## FOCUS\n- Improve ONLY the `construct_packing()` function and helper functions within the evolve block\n- Functions like `run_packing()` are preserved automatically - do not include them\n\nViolating these requirements will cause the program to fail evaluation.\n\n---\n\nYou are an AI tasked with evolving the **`construct_packing()`** function (and any helper functions defined inside the evolve block) so that it reliably builds a correct packing plan for the given items and constraints.\n\n### What you must do\n1. **Only edit code that appears between the markers**  \n   ```\n   # EVOLVE-BLOCK-START\n   \u2026your changes\u2026\n   # EVOLVE-BLOCK-END\n   ```  \n   **Your response must contain *only* the code that belongs inside those markers.**  \n   - Do **not** include the `# EVOLVE-BLOCK-START` or `# EVOLVE-BLOCK-END` lines themselves.  \n   - Do **not** add any imports, the `run_packing()` wrapper, or any other surrounding code.  \n\n2. **Focus exclusively on `construct_packing()` and any helper functions it calls** (e.g., `choose_items`, `fit_item`, `validate_solution`). Do not modify data structures defined outside the evolve block.\n\n3. **Produce a correct, efficient algorithm** that:\n   - Handles empty inputs, duplicate items, and items that cannot fit.\n   - Returns a list of packed items (or an empty list) that satisfies all capacity and ordering constraints.\n   - Uses a deterministic strategy (e.g., sorted\u2011by\u2011size greedy with backtracking) so the output is repeatable.\n   - Avoids infinite recursion or excessive looping that could cause a timeout.\n\n### What you must **NOT** do\n- **Do not** write a solution that is overly aggressive (e.g., random search without limits) \u2013 this caused repeated invalid programs in earlier iterations.\n- **Do not** produce code that can raise unhandled exceptions (index errors, division by zero, etc.).\n- **Do not** leave placeholder `pass` statements or `TODO` comments; the function must be fully implemented.\n- **Do not** change the function signatures of any public API inside the block.\n- **Do not** output anything besides the pure Python code that belongs between the markers.\n\n### Suggested concrete strategies\n- **Pre\u2011processing:** Sort the items by descending volume/weight ratio, then iterate once to fill the container while respecting the capacity limit.\n- **Backtracking fallback:** If an item cannot be placed, attempt to swap it with a previously placed smaller item; limit the depth of swaps to keep runtime bounded.\n- **Validation helper:** Implement a small `is_valid(packing)` helper that checks capacity and ordering constraints after each insertion; abort early if a violation is detected.\n- **Edge\u2011case handling:** Return `[]` immediately when the input list is empty or when the smallest item exceeds the container capacity.\n- **Determinism:** Use deterministic loops (`for i in range(len(items))`) rather than `while True` or random choices.\n\n### Output format reminder\nYour reply must be **exactly** the Python code that belongs inside the evolve block, with no extra text, no markers, and no surrounding code. The system will automatically merge your output with the preserved outer code.", "user": "# Current Program Information\n- Fitness: 13.9292\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness improved: 13.9292 \u2192 13.9292\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4429, output_length: 91.0000, overall_score: 0.3625, slope_changes: 68.6000, lag_error: 0.4100, avg_error: 1.1151, false_reversals: 56.6000, correlation: 0.2008, noise_reduction: 0.0000, smoothness_score: 0.2257, responsiveness_score: 0.7092, accuracy_score: 0.2008, efficiency_score: 1.0000, execution_time: 0.0003, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4429, output_length: 91.0000, overall_score: 0.3625, slope_changes: 68.6000, lag_error: 0.4100, avg_error: 1.1151, false_reversals: 56.6000, correlation: 0.2008, noise_reduction: 0.0000, smoothness_score: 0.2257, responsiveness_score: 0.7092, accuracy_score: 0.2008, efficiency_score: 1.0000, execution_time: 0.0004, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Unknown changes\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4429, output_length: 91.0000, overall_score: 0.3625, slope_changes: 68.6000, lag_error: 0.4100, avg_error: 1.1151, false_reversals: 56.6000, correlation: 0.2008, noise_reduction: 0.0000, smoothness_score: 0.2257, responsiveness_score: 0.7092, accuracy_score: 0.2008, efficiency_score: 1.0000, execution_time: 0.0006, success_rate: 1.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 13.9292)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"\n    Simple moving average filter using convolution.\n    Returns the filtered signal with length len(x) - window_size + 1.\n    \"\"\"\n    x = np.asarray(x, dtype=float)\n    if window_size <= 0:\n        raise ValueError(\"window_size must be positive\")\n    if x.size < window_size:\n        # Not enough data \u2013 return empty array for consistency\n        return np.array([], dtype=float)\n    return np.convolve(x, np.ones(window_size) / window_size, mode=\"valid\")\n\n\ndef weighted_filter(x, window_size=20):\n    \"\"\"\n    Exponential weighted moving average.\n    Emphasises recent samples while preserving overall trend.\n    \"\"\"\n    x = np.asarray(x, dtype=float)\n    if window_size <= 0:\n        raise ValueError(\"window_size must be positive\")\n    if x.size < window_size:\n        return np.array([], dtype=float)\n    weights = np.exp(np.linspace(-2, 0, window_size))\n    weights /= weights.sum()\n    return np.convolve(x, weights, mode=\"valid\")\n\n\ndef ema_filter(x, window_size=20):\n    \"\"\"\n    Classic exponential moving average (EMA).\n    Output length matches other filters (len(x) - window_size + 1).\n    \"\"\"\n    x = np.asarray(x, dtype=float)\n    if window_size <= 0:\n        raise ValueError(\"window_size must be positive\")\n    if x.size < window_size:\n        return np.array([], dtype=float)\n    alpha = 2.0 / (window_size + 1)\n    ema = np.empty_like(x)\n    ema[0] = x[0]\n    for i in range(1, len(x)):\n        ema[i] = alpha * x[i] + (1 - alpha) * ema[i - 1]\n    return ema[window_size - 1 :]\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"\n    Detrends the signal using a simple moving average, then applies\n    a weighted moving average to the detrended series.\n    \"\"\"\n    x = np.asarray(x, dtype=float)\n    if window_size <= 0:\n        raise ValueError(\"window_size must be positive\")\n    if x.size < window_size:\n        return np.array([], dtype=float)\n    # Estimate local trend\n    trend = adaptive_filter(x, window_size)\n    # Pad trend to original length (repeat edge values)\n    trend_full = np.concatenate((np.full(window_size - 1, trend[0]), trend))\n    detrended = x - trend_full\n    return weighted_filter(detrended, window_size)\n\n\ndef _residual_variance(original: np.ndarray, filtered: np.ndarray) -> float:\n    \"\"\"\n    Compute variance of the residual (original - filtered).\n    Signals are aligned to the shortest length.\n    \"\"\"\n    min_len = min(len(original), len(filtered))\n    if min_len == 0:\n        return np.inf\n    residual = original[:min_len] - filtered[:min_len]\n    return float(np.var(residual))\n\n\ndef _select_best_filter(x: np.ndarray, window_size: int) -> np.ndarray:\n    \"\"\"\n    Evaluate all available filters and return the one that yields the lowest\n    residual variance (i.e., highest estimated noise reduction).\n    \"\"\"\n    candidates = {\n        \"basic\": adaptive_filter(x, window_size),\n        \"weighted\": weighted_filter(x, window_size),\n        \"ema\": ema_filter(x, window_size),\n        \"enhanced\": enhanced_filter_with_trend_preservation(x, window_size),\n    }\n    # Choose filter with minimal residual variance relative to the raw signal\n    best_name = min(candidates, key=lambda k: _residual_variance(x, candidates[k]))\n    return candidates[best_name]\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Dispatches to the requested filtering algorithm.\n    Supported types:\n        - \"basic\": simple moving average (adaptive_filter)\n        - \"weighted\": exponential weighted moving average (weighted_filter)\n        - \"ema\": classic exponential moving average (ema_filter)\n        - \"enhanced\": detrended weighted filter (enhanced_filter_with_trend_preservation)\n        - any other value: automatic selection of the best filter based on residual variance.\n    \"\"\"\n    if algorithm_type == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if algorithm_type == \"weighted\":\n        return weighted_filter(input_signal, window_size)\n    if algorithm_type == \"ema\":\n        return ema_filter(input_signal, window_size)\n    if algorithm_type == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n\n    # Fallback: automatic selection\n    return _select_best_filter(np.asarray(input_signal, dtype=float), window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4429), Performs well on output_length (91.0000), Performs well on overall_score (0.3625), Performs well on slope_changes (68.6000), Performs well on lag_error (0.4100), Performs well on avg_error (1.1151), Performs well on false_reversals (56.6000), Performs well on correlation (0.2008), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.2257), Performs well on responsiveness_score (0.7092), Performs well on accuracy_score (0.2008), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0006), Performs well on success_rate (1.0000)\n\n### Program 2 (Score: 13.9292)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef simple_ma(x, w):\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    return np.convolve(x, np.ones(w) / w, mode=\"valid\")\n\n\ndef weighted_ma(x, w):\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    weights = np.exp(np.linspace(-2, 0, w))\n    weights /= weights.sum()\n    return np.convolve(x, weights, mode=\"valid\")\n\n\ndef ema(x, w):\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    a = 2.0 / (w + 1)\n    out = np.empty_like(x)\n    out[0] = x[0]\n    for i in range(1, len(x)):\n        out[i] = a * x[i] + (1 - a) * out[i - 1]\n    return out[w - 1 :]\n\n\ndef detrended_weighted(x, w):\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    trend = simple_ma(x, w)\n    trend_full = np.concatenate((np.full(w - 1, trend[0]), trend))\n    detrended = x - trend_full\n    return weighted_ma(detrended, w)\n\n\ndef _residual_variance(orig, filt):\n    m = min(len(orig), len(filt))\n    if m == 0:\n        return np.inf\n    return float(np.var(orig[:m] - filt[:m]))\n\n\ndef _select_best(x, w):\n    candidates = {\n        \"basic\": simple_ma(x, w),\n        \"weighted\": weighted_ma(x, w),\n        \"ema\": ema(x, w),\n        \"enhanced\": detrended_weighted(x, w),\n    }\n    best = min(candidates, key=lambda k: _residual_variance(x, candidates[k]))\n    return candidates[best]\n\n\ndef process_signal(sig, w=20, algo=\"enhanced\"):\n    if algo == \"basic\":\n        return simple_ma(sig, w)\n    if algo == \"weighted\":\n        return weighted_ma(sig, w)\n    if algo == \"ema\":\n        return ema(sig, w)\n    if algo == \"enhanced\":\n        return detrended_weighted(sig, w)\n    return _select_best(np.asarray(sig, float), w)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4429), Performs well on output_length (91.0000), Performs well on overall_score (0.3625), Performs well on slope_changes (68.6000), Performs well on lag_error (0.4100), Performs well on avg_error (1.1151), Performs well on false_reversals (56.6000), Performs well on correlation (0.2008), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.2257), Performs well on responsiveness_score (0.7092), Performs well on accuracy_score (0.2008), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0004), Performs well on success_rate (1.0000)\n\n### Program 3 (Score: 13.9292)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _ma(x,w,wt):\n    x=np.asarray(x,float)\n    if w<=0: raise ValueError(\"window must be >0\")\n    if x.size<w: return np.empty(0,float)\n    return np.convolve(x,wt,'valid')\n\ndef simple_ma(x,w): return _ma(x,w,np.ones(w)/w)\n\ndef weighted_ma(x,w):\n    wt=np.exp(np.linspace(-2,0,w))\n    wt/=wt.sum()\n    return _ma(x,w,wt)\n\ndef ema(x,w):\n    x=np.asarray(x,float)\n    if w<=0: raise ValueError(\"window must be >0\")\n    if x.size<w: return np.empty(0,float)\n    a=2.0/(w+1)\n    out=np.empty_like(x); out[0]=x[0]\n    for i in range(1,len(x)): out[i]=a*x[i]+(1-a)*out[i-1]\n    return out[w-1:]\n\ndef detrended_weighted(x,w):\n    tr=simple_ma(x,w)\n    tr_full=np.concatenate((np.full(w-1,tr[0]),tr))\n    return weighted_ma(x-tr_full,w)\n\ndef _resvar(o,f):\n    m=min(len(o),len(f))\n    return np.inf if m==0 else float(np.var(o[:m]-f[:m]))\n\ndef _best(x,w):\n    cand={'basic':simple_ma(x,w),'weighted':weighted_ma(x,w),'ema':ema(x,w),'enhanced':detrended_weighted(x,w)}\n    return cand[min(cand,key=lambda k:_resvar(x,cand[k]))]\n\ndef process_signal(sig,w=20,algo='enhanced'):\n    funcs={'basic':simple_ma,'weighted':weighted_ma,'ema':ema,'enhanced':detrended_weighted}\n    return funcs.get(algo,lambda s,w:_best(s,w))(sig,w)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4429), Performs well on output_length (91.0000), Performs well on overall_score (0.3625), Performs well on slope_changes (68.6000), Performs well on lag_error (0.4100), Performs well on avg_error (1.1151), Performs well on false_reversals (56.6000), Performs well on correlation (0.2008), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.2257), Performs well on responsiveness_score (0.7092), Performs well on accuracy_score (0.2008), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0003), Performs well on success_rate (1.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 12.6107)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef simple_ma(x, w):\n    \"\"\"Simple moving average using uniform weights.\"\"\"\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    return np.convolve(x, np.ones(w) / w, mode=\"valid\")\n\n\ndef weighted_ma(x, w):\n    \"\"\"Exponentially weighted moving average.\"\"\"\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    weights = np.exp(np.linspace(-2, 0, w))\n    weights /= weights.sum()\n    return np.convolve(x, weights, mode=\"valid\")\n\n\ndef ema(x, w):\n    \"\"\"Classic exponential moving average (EMA).\"\"\"\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    a = 2.0 / (w + 1)\n    out = np.empty_like(x)\n    out[0] = x[0]\n    for i in range(1, len(x)):\n        out[i] = a * x[i] + (1 - a) * out[i - 1]\n    return out[w - 1 :]\n\n\ndef median_filter(x, w):\n    \"\"\"Sliding\u2011window median filter (robust to spikes).\"\"\"\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    out_len = x.size - w + 1\n    out = np.empty(out_len, float)\n    for i in range(out_len):\n        out[i] = np.median(x[i : i + w])\n    return out\n\n\ndef detrended_weighted(x, w):\n    \"\"\"Detrend using a weighted moving average, then apply weighted smoothing.\"\"\"\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    # Use weighted_ma for a smoother trend estimate\n    trend = weighted_ma(x, w)\n    # Pad trend to original length (repeat edge values)\n    trend_full = np.concatenate((np.full(w - 1, trend[0]), trend))\n    detrended = x - trend_full\n    return weighted_ma(detrended, w)\n\n\ndef _residual_variance(orig, filt):\n    \"\"\"Variance of the residual (orig - filt) aligned to the shortest length.\"\"\"\n    m = min(len(orig), len(filt))\n    if m == 0:\n        return np.inf\n    return float(np.var(orig[:m] - filt[:m]))\n\n\ndef _select_best(x, w):\n    \"\"\"Choose the filter with the lowest residual variance.\"\"\"\n    candidates = {\n        \"basic\": simple_ma(x, w),\n        \"weighted\": weighted_ma(x, w),\n        \"ema\": ema(x, w),\n        \"enhanced\": detrended_weighted(x, w),\n        \"median\": median_filter(x, w),\n    }\n    best_key = min(candidates, key=lambda k: _residual_variance(x, candidates[k]))\n    return candidates[best_key]\n\n\ndef process_signal(sig, w=20, algo=\"enhanced\"):\n    \"\"\"Dispatch to a specific filter or automatically select the best one.\"\"\"\n    if algo == \"basic\":\n        return simple_ma(sig, w)\n    if algo == \"weighted\":\n        return weighted_ma(sig, w)\n    if algo == \"ema\":\n        return ema(sig, w)\n    if algo == \"enhanced\":\n        return detrended_weighted(sig, w)\n    if algo == \"median\":\n        return median_filter(sig, w)\n    # Fallback: automatic selection based on residual variance\n    return _select_best(np.asarray(sig, float), w)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to composite_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 12.6107, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef simple_ma(x, w):\n    \"\"\"Simple moving average using uniform weights.\"\"\"\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    return np.convolve(x, np.ones(w) / w, mode=\"valid\")\n\n\ndef weighted_ma(x, w):\n    \"\"\"Exponentially weighted moving average.\"\"\"\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    weights = np.exp(np.linspace(-2, 0, w))\n    weights /= weights.sum()\n    return np.convolve(x, weights, mode=\"valid\")\n\n\ndef ema(x, w):\n    \"\"\"Classic exponential moving average (EMA).\"\"\"\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    a = 2.0 / (w + 1)\n    out = np.empty_like(x)\n    out[0] = x[0]\n    for i in range(1, len(x)):\n        out[i] = a * x[i] + (1 - a) * out[i - 1]\n    return out[w - 1 :]\n\n\ndef median_filter(x, w):\n    \"\"\"Sliding\u2011window median filter (robust to spikes).\"\"\"\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    out_len = x.size - w + 1\n    out = np.empty(out_len, float)\n    for i in range(out_len):\n        out[i] = np.median(x[i : i + w])\n    return out\n\n\ndef detrended_weighted(x, w):\n    \"\"\"Detrend using a weighted moving average, then apply weighted smoothing.\"\"\"\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    # Use weighted_ma for a smoother trend estimate\n    trend = weighted_ma(x, w)\n    # Pad trend to original length (repeat edge values)\n    trend_full = np.concatenate((np.full(w - 1, trend[0]), trend))\n    detrended = x - trend_full\n    return weighted_ma(detrended, w)\n\n\ndef _residual_variance(orig, filt):\n    \"\"\"Variance of the residual (orig - filt) aligned to the shortest length.\"\"\"\n    m = min(len(orig), len(filt))\n    if m == 0:\n        return np.inf\n    return float(np.var(orig[:m] - filt[:m]))\n\n\ndef _select_best(x, w):\n    \"\"\"Choose the filter with the lowest residual variance.\"\"\"\n    candidates = {\n        \"basic\": simple_ma(x, w),\n        \"weighted\": weighted_ma(x, w),\n        \"ema\": ema(x, w),\n        \"enhanced\": detrended_weighted(x, w),\n        \"median\": median_filter(x, w),\n    }\n    best_key = min(candidates, key=lambda k: _residual_variance(x, candidates[k]))\n    return candidates[best_key]\n\n\ndef process_signal(sig, w=20, algo=\"enhanced\"):\n    \"\"\"Dispatch to a specific filter or automatically select the best one.\"\"\"\n    if algo == \"basic\":\n        return simple_ma(sig, w)\n    if algo == \"weighted\":\n        return weighted_ma(sig, w)\n    if algo == \"ema\":\n        return ema(sig, w)\n    if algo == \"enhanced\":\n        return detrended_weighted(sig, w)\n    if algo == \"median\":\n        return median_filter(sig, w)\n    # Fallback: automatic selection based on residual variance\n    return _select_best(np.asarray(sig, float), w)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (91.000)\n\n### Inspiration 2 (Score: 13.9292, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"\n    Simple moving average filter using convolution.\n    Returns the filtered signal with length len(x) - window_size + 1.\n    \"\"\"\n    x = np.asarray(x, dtype=float)\n    if window_size <= 0:\n        raise ValueError(\"window_size must be positive\")\n    if x.size < window_size:\n        # Not enough data \u2013 return empty array for consistency\n        return np.array([], dtype=float)\n    return np.convolve(x, np.ones(window_size) / window_size, mode=\"valid\")\n\n\ndef weighted_filter(x, window_size=20):\n    \"\"\"\n    Exponential weighted moving average.\n    Emphasises recent samples while preserving overall trend.\n    \"\"\"\n    x = np.asarray(x, dtype=float)\n    if window_size <= 0:\n        raise ValueError(\"window_size must be positive\")\n    if x.size < window_size:\n        return np.array([], dtype=float)\n    weights = np.exp(np.linspace(-2, 0, window_size))\n    weights /= weights.sum()\n    return np.convolve(x, weights, mode=\"valid\")\n\n\ndef ema_filter(x, window_size=20):\n    \"\"\"\n    Classic exponential moving average (EMA).\n    Output length matches other filters (len(x) - window_size + 1).\n    \"\"\"\n    x = np.asarray(x, dtype=float)\n    if window_size <= 0:\n        raise ValueError(\"window_size must be positive\")\n    if x.size < window_size:\n        return np.array([], dtype=float)\n    alpha = 2.0 / (window_size + 1)\n    ema = np.empty_like(x)\n    ema[0] = x[0]\n    for i in range(1, len(x)):\n        ema[i] = alpha * x[i] + (1 - alpha) * ema[i - 1]\n    return ema[window_size - 1 :]\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"\n    Detrends the signal using a simple moving average, then applies\n    a weighted moving average to the detrended series.\n    \"\"\"\n    x = np.asarray(x, dtype=float)\n    if window_size <= 0:\n        raise ValueError(\"window_size must be positive\")\n    if x.size < window_size:\n        return np.array([], dtype=float)\n    # Estimate local trend\n    trend = adaptive_filter(x, window_size)\n    # Pad trend to original length (repeat edge values)\n    trend_full = np.concatenate((np.full(window_size - 1, trend[0]), trend))\n    detrended = x - trend_full\n    return weighted_filter(detrended, window_size)\n\n\ndef _residual_variance(original: np.ndarray, filtered: np.ndarray) -> float:\n    \"\"\"\n    Compute variance of the residual (original - filtered).\n    Signals are aligned to the shortest length.\n    \"\"\"\n    min_len = min(len(original), len(filtered))\n    if min_len == 0:\n        return np.inf\n    residual = original[:min_len] - filtered[:min_len]\n    return float(np.var(residual))\n\n\ndef _select_best_filter(x: np.ndarray, window_size: int) -> np.ndarray:\n    \"\"\"\n    Evaluate all available filters and return the one that yields the lowest\n    residual variance (i.e., highest estimated noise reduction).\n    \"\"\"\n    candidates = {\n        \"basic\": adaptive_filter(x, window_size),\n        \"weighted\": weighted_filter(x, window_size),\n        \"ema\": ema_filter(x, window_size),\n        \"enhanced\": enhanced_filter_with_trend_preservation(x, window_size),\n    }\n    # Choose filter with minimal residual variance relative to the raw signal\n    best_name = min(candidates, key=lambda k: _residual_variance(x, candidates[k]))\n    return candidates[best_name]\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Dispatches to the requested filtering algorithm.\n    Supported types:\n        - \"basic\": simple moving average (adaptive_filter)\n        - \"weighted\": exponential weighted moving average (weighted_filter)\n        - \"ema\": classic exponential moving average (ema_filter)\n        - \"enhanced\": detrended weighted filter (enhanced_filter_with_trend_preservation)\n        - any other value: automatic selection of the best filter based on residual variance.\n    \"\"\"\n    if algorithm_type == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if algorithm_type == \"weighted\":\n        return weighted_filter(input_signal, window_size)\n    if algorithm_type == \"ema\":\n        return ema_filter(input_signal, window_size)\n    if algorithm_type == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n\n    # Fallback: automatic selection\n    return _select_best_filter(np.asarray(input_signal, dtype=float), window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Excellent runs_successfully (1.000), Excellent output_length (91.000), Excellent slope_changes (68.600)\n\n### Inspiration 3 (Score: 13.9292, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _ma(x,w,wt):\n    x=np.asarray(x,float)\n    if w<=0: raise ValueError(\"window must be >0\")\n    if x.size<w: return np.empty(0,float)\n    return np.convolve(x,wt,'valid')\n\ndef simple_ma(x,w): return _ma(x,w,np.ones(w)/w)\n\ndef weighted_ma(x,w):\n    wt=np.exp(np.linspace(-2,0,w))\n    wt/=wt.sum()\n    return _ma(x,w,wt)\n\ndef ema(x,w):\n    x=np.asarray(x,float)\n    if w<=0: raise ValueError(\"window must be >0\")\n    if x.size<w: return np.empty(0,float)\n    a=2.0/(w+1)\n    out=np.empty_like(x); out[0]=x[0]\n    for i in range(1,len(x)): out[i]=a*x[i]+(1-a)*out[i-1]\n    return out[w-1:]\n\ndef detrended_weighted(x,w):\n    tr=simple_ma(x,w)\n    tr_full=np.concatenate((np.full(w-1,tr[0]),tr))\n    return weighted_ma(x-tr_full,w)\n\ndef _resvar(o,f):\n    m=min(len(o),len(f))\n    return np.inf if m==0 else float(np.var(o[:m]-f[:m]))\n\ndef _best(x,w):\n    cand={'basic':simple_ma(x,w),'weighted':weighted_ma(x,w),'ema':ema(x,w),'enhanced':detrended_weighted(x,w)}\n    return cand[min(cand,key=lambda k:_resvar(x,cand[k]))]\n\ndef process_signal(sig,w=20,algo='enhanced'):\n    funcs={'basic':simple_ma,'weighted':weighted_ma,'ema':ema,'enhanced':detrended_weighted}\n    return funcs.get(algo,lambda s,w:_best(s,w))(sig,w)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (91.000)\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef simple_ma(x, w):\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    return np.convolve(x, np.ones(w) / w, mode=\"valid\")\n\n\ndef weighted_ma(x, w):\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    weights = np.exp(np.linspace(-2, 0, w))\n    weights /= weights.sum()\n    return np.convolve(x, weights, mode=\"valid\")\n\n\ndef ema(x, w):\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    a = 2.0 / (w + 1)\n    out = np.empty_like(x)\n    out[0] = x[0]\n    for i in range(1, len(x)):\n        out[i] = a * x[i] + (1 - a) * out[i - 1]\n    return out[w - 1 :]\n\n\ndef detrended_weighted(x, w):\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    trend = simple_ma(x, w)\n    trend_full = np.concatenate((np.full(w - 1, trend[0]), trend))\n    detrended = x - trend_full\n    return weighted_ma(detrended, w)\n\n\ndef _residual_variance(orig, filt):\n    m = min(len(orig), len(filt))\n    if m == 0:\n        return np.inf\n    return float(np.var(orig[:m] - filt[:m]))\n\n\ndef _select_best(x, w):\n    candidates = {\n        \"basic\": simple_ma(x, w),\n        \"weighted\": weighted_ma(x, w),\n        \"ema\": ema(x, w),\n        \"enhanced\": detrended_weighted(x, w),\n    }\n    best = min(candidates, key=lambda k: _residual_variance(x, candidates[k]))\n    return candidates[best]\n\n\ndef process_signal(sig, w=20, algo=\"enhanced\"):\n    if algo == \"basic\":\n        return simple_ma(sig, w)\n    if algo == \"weighted\":\n        return weighted_ma(sig, w)\n    if algo == \"ema\":\n        return ema(sig, w)\n    if algo == \"enhanced\":\n        return detrended_weighted(sig, w)\n    return _select_best(np.asarray(sig, float), w)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\n\n# Task\nImprove the code to maximize FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\n\n## CRITICAL INSTRUCTIONS\nIf the code contains `# EVOLVE-BLOCK-START` and `# EVOLVE-BLOCK-END` markers:\n- Output ONLY the code that goes BETWEEN these markers\n- Do NOT include the markers themselves\n- Do NOT include code outside the markers (like `run_packing()`)\n- The system will automatically merge your output with the preserved sections\n\nIf there are NO EVOLVE-BLOCK markers:\n- Output the complete rewritten program\n\n```python\n# Your improved code here (ONLY the evolve block content if markers exist)\n```", "responses": ["import numpy as np\n\ndef simple_ma(x, w):\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    return np.convolve(x, np.ones(w) / w, mode=\"valid\")\n\n\ndef weighted_ma(x, w):\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    weights = np.exp(np.linspace(-2, 0, w))\n    weights /= weights.sum()\n    return np.convolve(x, weights, mode=\"valid\")\n\n\ndef ema(x, w):\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    a = 2.0 / (w + 1)\n    out = np.empty_like(x)\n    out[0] = x[0]\n    for i in range(1, len(x)):\n        out[i] = a * x[i] + (1 - a) * out[i - 1]\n    return out[w - 1 :]\n\n\ndef detrended_weighted(x, w):\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    trend = simple_ma(x, w)\n    trend_full = np.concatenate((np.full(w - 1, trend[0]), trend))\n    detrended = x - trend_full\n    return weighted_ma(detrended, w)\n\n\ndef gaussian_ma(x, w):\n    \"\"\"Moving average with Gaussian weights.\"\"\"\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    sigma = max(w / 6.0, 0.1)\n    center = (w - 1) / 2.0\n    i = np.arange(w, dtype=float)\n    weights = np.exp(-0.5 * ((i - center) / sigma) ** 2)\n    weights /= weights.sum()\n    return np.convolve(x, weights, mode=\"valid\")\n\n\ndef median_ma(x, w):\n    \"\"\"Median filter (robust to spikes).\"\"\"\n    x = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window size must be positive\")\n    if x.size < w:\n        return np.empty(0, float)\n    out_len = x.size - w + 1\n    out = np.empty(out_len, float)\n    for i in range(out_len):\n        out[i] = np.median(x[i : i + w])\n    return out\n\n\ndef _residual_variance(orig, filt):\n    m = min(len(orig), len(filt))\n    if m == 0:\n        return np.inf\n    return float(np.var(orig[:m] - filt[:m]))\n\n\ndef _select_best(x, w):\n    candidates = {\n        \"basic\": simple_ma(x, w),\n        \"weighted\": weighted_ma(x, w),\n        \"ema\": ema(x, w),\n        \"enhanced\": detrended_weighted(x, w),\n        \"gaussian\": gaussian_ma(x, w),\n        \"median\": median_ma(x, w),\n    }\n    best_key = min(candidates, key=lambda k: _residual_variance(x, candidates[k]))\n    return candidates[best_key]\n\n\ndef process_signal(sig, w=20, algo=\"enhanced\"):\n    if algo == \"basic\":\n        return simple_ma(sig, w)\n    if algo == \"weighted\":\n        return weighted_ma(sig, w)\n    if algo == \"ema\":\n        return ema(sig, w)\n    if algo == \"enhanced\":\n        return detrended_weighted(sig, w)\n    if algo == \"gaussian\":\n        return gaussian_ma(sig, w)\n    if algo == \"median\":\n        return median_ma(sig, w)\n    # Fallback to automatic selection\n    return _select_best(np.asarray(sig, float), w)"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}