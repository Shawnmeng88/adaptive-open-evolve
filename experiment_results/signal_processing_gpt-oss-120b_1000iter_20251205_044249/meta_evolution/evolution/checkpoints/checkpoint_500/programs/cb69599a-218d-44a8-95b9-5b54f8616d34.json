{"id": "cb69599a-218d-44a8-95b9-5b54f8616d34", "code": "# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\nfrom typing import Tuple\n\ndef _prepare_input(x, window: int) -> Tuple[np.ndarray, int]:\n    ws = int(window)\n    if ws <= 0:\n        raise ValueError(\"window_size must be positive\")\n    arr = np.asarray(x, dtype=float).ravel()\n    if arr.size < ws:\n        return np.empty(0, dtype=float), ws\n    return arr, ws\n\n@lru_cache(maxsize=32)\ndef _exp_weights(ws: int) -> np.ndarray:\n    w = np.exp(np.linspace(-2, 0, ws))\n    return w / w.sum()\n\ndef adaptive_filter(x, window_size: int = 20) -> np.ndarray:\n    arr, ws = _prepare_input(x, window_size)\n    return np.convolve(arr, np.ones(ws) / ws, mode=\"valid\") if arr.size else arr\n\ndef _apply_savgol(signal: np.ndarray, base_ws: int, polyorder: int = 3) -> np.ndarray:\n    try:\n        from scipy import signal as scipy_signal\n    except Exception:\n        return np.convolve(signal, np.ones(base_ws) / base_ws, mode=\"valid\")\n    var = np.var(signal)\n    mean = np.mean(np.abs(signal)) + 1e-9\n    scale = var / mean\n    win = int(max(polyorder + 2, min(base_ws * 2, base_ws * scale)))\n    if win % 2 == 0:\n        win += 1\n    win = max(win, polyorder + 2)\n    if win % 2 == 0:\n        win += 1\n    return scipy_signal.savgol_filter(signal, win, polyorder, mode=\"interp\")\n\ndef enhanced_filter_with_trend_preservation(x, window_size: int = 20) -> np.ndarray:\n    arr, ws = _prepare_input(x, window_size)\n    if not arr.size:\n        return arr\n    ewma = np.convolve(arr, _exp_weights(ws), mode=\"valid\")\n    sg = _apply_savgol(ewma, ws)\n    return np.convolve(sg, np.ones(5) / 5, mode=\"valid\") if sg.size >= 5 else sg\n\ndef exponential_smoothing(x, window_size: int = 20) -> np.ndarray:\n    arr, ws = _prepare_input(x, window_size)\n    if not arr.size:\n        return arr\n    alpha = 2.0 / (ws + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[ws - 1 :]\n\ndef process_signal(input_signal, window_size: int = 20, algorithm_type: str = \"enhanced\") -> np.ndarray:\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    if alg == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n    if alg == \"savgol\":\n        arr, ws = _prepare_input(input_signal, window_size)\n        return _apply_savgol(arr, ws) if arr.size else arr\n    if alg == \"hybrid\":\n        tmp = enhanced_filter_with_trend_preservation(input_signal, window_size)\n        return exponential_smoothing(tmp, window_size)\n    return enhanced_filter_with_trend_preservation(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n", "language": "python", "parent_id": "63402ed6-692d-406a-b1e4-8ee4b675ae59", "generation": 6, "timestamp": 1764937373.09864, "iteration_found": 115, "metrics": {"runs_successfully": 1.0, "composite_score": 0.538875678083449, "output_length": 87.0, "overall_score": 0.4589572991776447, "slope_changes": 30.8, "lag_error": 0.8982877586864653, "avg_error": 1.268608055743444, "false_reversals": 25.8, "correlation": 0.32333435231975055, "noise_reduction": 0.0, "smoothness_score": 0.39370078740157477, "responsiveness_score": 0.5267905223663022, "accuracy_score": 0.32333435231975055, "efficiency_score": 1.0, "execution_time": 0.0005595684051513672, "success_rate": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Evolve block rewrite (preserved external code)", "parent_metrics": {"runs_successfully": 1.0, "composite_score": 0.538875678083449, "output_length": 87.0, "overall_score": 0.4589572991776447, "slope_changes": 30.8, "lag_error": 0.8982877586864653, "avg_error": 1.268608055743444, "false_reversals": 25.8, "correlation": 0.32333435231975055, "noise_reduction": 0.0, "smoothness_score": 0.39370078740157477, "responsiveness_score": 0.5267905223663022, "accuracy_score": 0.32333435231975055, "efficiency_score": 1.0, "execution_time": 0.0007987499237060546, "success_rate": 1.0}, "island": 1}, "prompts": {"full_rewrite_user": {"system": "## CRITICAL FORMAT REQUIREMENTS (DO NOT VIOLATE)\n## OUTPUT FORMAT (CRITICAL)\n- Output ONLY the code that goes BETWEEN the `# EVOLVE-BLOCK-START` and `# EVOLVE-BLOCK-END` markers\n- Do NOT include the markers themselves in your output\n- Do NOT include any code outside the markers (imports, run_packing, etc.)\n- The system will automatically merge your output with the preserved code sections\n\n## FOCUS\n- Improve ONLY the `construct_packing()` function and helper functions within the evolve block\n- Functions like `run_packing()` are preserved automatically - do not include them\n\nViolating these requirements will cause the program to fail evaluation.\n\n---\n\nYou are a code\u2011evolution LLM tasked with improving **only** the `construct_packing()` function and any helper functions that live inside the `# EVOLVE\u2011BLOCK\u2011START`\u202f/\u202f`# EVOLVE\u2011BLOCK\u2011END` region.  \n\n**OUTPUT RULES (must be obeyed exactly)**  \n- Output **only** the Python statements that belong between the two markers.  \n- Do **not** include the markers themselves.  \n- Do **not** add imports, top\u2011level code, or any statements outside the functions already present in the block.  \n- The surrounding scaffold (e.g., `run_packing()`) will be merged automatically; do not reference or modify it.\n\n**WHAT TO AVOID (these caused previous failures)**  \n- Do not write an overly aggressive prompt that ignores the strict output format \u2013 any extra text or markers will invalidate the solution.  \n- Do not produce syntax errors, undefined names, or missing return statements.  \n- Do not ignore the packing constraints (capacity, weight, volume, item\u2011count limits).  \n- Do not rely on external libraries that are not already imported in the outer file.  \n- Do not add unrelated or generic code (e.g., \u201cprint debugging\u201d, \u201cTODO\u201d comments outside the functions).  \n\n**CONCRETE STRATEGIES TO TRY**  \n\n1. **First\u2011Fit Decreasing (FFD) with pruning**  \n   - Sort items by a combined score (e.g., `size_factor = volume * weight`) in descending order.  \n   - Iterate through sorted items, placing each into the first container that satisfies **all** remaining constraints (capacity, weight, volume, max\u2011items).  \n   - If no existing container fits, create a new one (respecting the global `max_containers` limit).  \n\n2. **Back\u2011tracking with early exit**  \n   - After each placement, recompute the remaining free space/weight for every container.  \n   - If any container exceeds a constraint, backtrack immediately.  \n   - Use a depth\u2011first search limited to a configurable `max_depth` (e.g., 6) to keep runtime reasonable.  \n\n3. **Memoization of container states**  \n   - Cache a hashable representation of the current packing state (e.g., tuple of remaining capacities).  \n   - Skip exploring a state that has already been visited with an equal or better item\u2011count.  \n\n4. **Item rotation handling**  \n   - If items have a `can_rotate` flag, treat their dimensions as interchangeable when computing volume; otherwise use the given orientation.  \n\n5. **Heuristic tie\u2011breaker**  \n   - When multiple containers can accept an item, prefer the one with the **least** remaining free volume after placement (tight packing).  \n\n6. **Graceful failure**  \n   - If the algorithm cannot place all items within the allowed number of containers, return the best partial packing found (largest number of items placed).  \n\n**Implementation Tips**  \n- Keep helper functions pure (no side\u2011effects beyond returning new container states).  \n- Use clear variable names (`remaining_cap`, `remaining_weight`, `remaining_vol`, `items_in_container`).  \n- Return a list of containers, each represented in the same format the surrounding code expects (e.g., list of item IDs).  \n- Include a docstring that explains the algorithm briefly; comments inside the block are allowed, but no external commentary.  \n\nProceed to rewrite `construct_packing()` (and any needed helpers) following these guidelines, and output **only** the code that belongs between the markers.", "user": "# Current Program Information\n- Fitness: 9.4583\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness declined: 13.4402 \u2192 9.4583. Consider revising recent changes.\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4147, output_length: 91.0000, overall_score: 0.3667, slope_changes: 64.2000, lag_error: 1.0255, avg_error: 1.3708, false_reversals: 52.4000, correlation: 0.2667, noise_reduction: 0.0000, smoothness_score: 0.2375, responsiveness_score: 0.4937, accuracy_score: 0.2667, efficiency_score: 1.0000, execution_time: 0.0005, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4147, output_length: 91.0000, overall_score: 0.3667, slope_changes: 64.2000, lag_error: 1.0255, avg_error: 1.3708, false_reversals: 52.4000, correlation: 0.2667, noise_reduction: 0.0000, smoothness_score: 0.2375, responsiveness_score: 0.4937, accuracy_score: 0.2667, efficiency_score: 1.0000, execution_time: 0.0009, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Unknown changes\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4200, output_length: 91.0000, overall_score: 0.3899, slope_changes: 66.0000, lag_error: 0.8697, avg_error: 1.2418, false_reversals: 55.2000, correlation: 0.3768, noise_reduction: 0.0000, smoothness_score: 0.2326, responsiveness_score: 0.5349, accuracy_score: 0.3768, efficiency_score: 1.0000, execution_time: 0.0018, success_rate: 1.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 13.7278)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nReal-Time Adaptive Signal Processing Algorithm for Non-Stationary Time Series\n\nThis algorithm implements a sliding window approach to filter volatile, non-stationary\ntime series data while minimizing noise and preserving signal dynamics.\n\"\"\"\nimport numpy as np\nfrom scipy import signal\nfrom collections import deque\n\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"\n    Adaptive signal processing algorithm using sliding window approach.\n\n    Args:\n        x: Input signal (1D array of real-valued samples)\n        window_size: Size of the sliding window (W samples)\n\n    Returns:\n        y: Filtered output signal with length = len(x) - window_size + 1\n    \"\"\"\n    if len(x) < window_size:\n        raise ValueError(f\"Input signal length ({len(x)}) must be >= window_size ({window_size})\")\n\n    # Initialize output array\n    output_length = len(x) - window_size + 1\n    y = np.zeros(output_length)\n\n    # Simple moving average as baseline\n    for i in range(output_length):\n        window = x[i : i + window_size]\n\n        # Basic moving average filter\n        y[i] = np.mean(window)\n\n    return y\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"\n    Enhanced version with trend preservation using weighted moving average.\n\n    Args:\n        x: Input signal (1D array of real-valued samples)\n        window_size: Size of the sliding window\n\n    Returns:\n        y: Filtered output signal\n    \"\"\"\n    if len(x) < window_size:\n        raise ValueError(f\"Input signal length ({len(x)}) must be >= window_size ({window_size})\")\n\n    output_length = len(x) - window_size + 1\n    y = np.zeros(output_length)\n\n    # Create weights that emphasize recent samples\n    weights = np.exp(np.linspace(-2, 0, window_size))\n    weights = weights / np.sum(weights)\n\n    for i in range(output_length):\n        window = x[i : i + window_size]\n\n        # Weighted moving average with exponential weights\n        y[i] = np.sum(window * weights)\n\n    return y\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Main signal processing function that applies the selected algorithm.\n\n    Args:\n        input_signal: Input time series data\n        window_size: Window size for processing\n        algorithm_type: Type of algorithm to use (\"basic\" or \"enhanced\")\n\n    Returns:\n        Filtered signal\n    \"\"\"\n    if algorithm_type == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    else:\n        return adaptive_filter(input_signal, window_size)\n\n\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4200), Performs well on output_length (91.0000), Performs well on overall_score (0.3899), Performs well on slope_changes (66.0000), Performs well on lag_error (0.8697), Performs well on avg_error (1.2418), Performs well on false_reversals (55.2000), Performs well on correlation (0.3768), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.2326), Performs well on responsiveness_score (0.5349), Performs well on accuracy_score (0.3768), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0018), Performs well on success_rate (1.0000)\n\n### Program 2 (Score: 13.4402)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nReal-Time Adaptive Signal Processing Algorithm for Non\u2011Stationary Time Series\n\nProvides several filtering strategies (basic moving\u2011average, weighted EWMA,\nexponential smoothing and optional Savitzky\u2011Golay) with safe fall\u2011backs.\n\"\"\"\nimport numpy as np\nfrom scipy import signal\n\ndef _to_array(x, window):\n    \"\"\"Convert input to 1\u2011D float array and validate length.\"\"\"\n    arr = np.asarray(x, dtype=float)\n    if arr.ndim != 1:\n        raise ValueError(\"Input signal must be 1\u2011D\")\n    if window <= 0:\n        raise ValueError(\"window_size must be positive\")\n    if arr.size < window:\n        # Return empty array \u2013 caller can handle gracefully\n        return np.array([], dtype=float)\n    return arr\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Fast simple moving average using cumulative sum.\"\"\"\n    arr = _to_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    csum = np.cumsum(np.insert(arr, 0, 0.0))\n    return (csum[window_size:] - csum[:-window_size]) / window_size\n\ndef weighted_filter(x, window_size=20):\n    \"\"\"Exponentially weighted moving average (EWMA).\"\"\"\n    arr = _to_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    w = np.exp(np.linspace(-2, 0, window_size))\n    w /= w.sum()\n    return np.convolve(arr, w, mode='valid')\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; output length matches other filters.\"\"\"\n    arr = _to_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    alpha = 2.0 / (window_size + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[window_size - 1 :]\n\ndef _savgol_filter(x, window_size=20, polyorder=3):\n    \"\"\"Savitzky\u2011Golay filter with safe parameter handling.\"\"\"\n    arr = _to_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    # SciPy's savgol_filter may be unavailable; fall back to basic MA\n    if not hasattr(signal, \"savgol_filter\"):\n        return adaptive_filter(arr, window_size)\n    w = int(window_size)\n    if w % 2 == 0:\n        w += 1\n    w = max(w, polyorder + 2)\n    if w % 2 == 0:\n        w += 1\n    return signal.savgol_filter(arr, window_length=w, polyorder=polyorder, mode='interp')\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Dispatch to the selected filtering algorithm.\n\n    algorithm_type options:\n        \"basic\"   \u2013 simple moving average\n        \"enhanced\"\u2013 EWMA (default)\n        \"exp\"     \u2013 exponential smoothing\n        \"savgol\"  \u2013 Savitzky\u2011Golay (fallback to basic)\n        \"hybrid\"  \u2013 EWMA followed by exponential smoothing\n    \"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"enhanced\":\n        return weighted_filter(input_signal, window_size)\n    if alg == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n    if alg == \"savgol\":\n        return _savgol_filter(input_signal, window_size)\n    if alg == \"hybrid\":\n        tmp = weighted_filter(input_signal, window_size)\n        return exponential_smoothing(tmp, window_size)\n    # Default to enhanced for unknown types\n    return weighted_filter(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4147), Performs well on output_length (91.0000), Performs well on overall_score (0.3667), Performs well on slope_changes (64.2000), Performs well on lag_error (1.0255), Performs well on avg_error (1.3708), Performs well on false_reversals (52.4000), Performs well on correlation (0.2667), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.2375), Performs well on responsiveness_score (0.4937), Performs well on accuracy_score (0.2667), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0009), Performs well on success_rate (1.0000)\n\n### Program 3 (Score: 13.4402)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nReal-Time Adaptive Signal Processing Algorithm for Non-Stationary Time Series\n\"\"\"\nimport numpy as np\n\ndef adaptive_filter(x, window_size=20):\n    if len(x) < window_size:\n        raise ValueError(f\"Input length ({len(x)}) < window_size ({window_size})\")\n    return np.convolve(x, np.ones(window_size) / window_size, mode='valid')\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    if len(x) < window_size:\n        raise ValueError(f\"Input length ({len(x)}) < window_size ({window_size})\")\n    w = np.exp(np.linspace(-2, 0, window_size))\n    w /= w.sum()\n    return np.convolve(x, w, mode='valid')\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    func = enhanced_filter_with_trend_preservation if algorithm_type == \"enhanced\" else adaptive_filter\n    return func(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4147), Performs well on output_length (91.0000), Performs well on overall_score (0.3667), Performs well on slope_changes (64.2000), Performs well on lag_error (1.0255), Performs well on avg_error (1.3708), Performs well on false_reversals (52.4000), Performs well on correlation (0.2667), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.2375), Performs well on responsiveness_score (0.4937), Performs well on accuracy_score (0.2667), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0005), Performs well on success_rate (1.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 13.4402)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _as_array(x, window_size):\n    \"\"\"Convert input to 1\u2011D float array and validate window size.\"\"\"\n    arr = np.asarray(x, dtype=float)\n    ws = int(window_size)\n    if ws <= 0:\n        raise ValueError(\"window_size must be a positive integer\")\n    if arr.size < ws:\n        raise ValueError(f\"Input length ({arr.size}) < window_size ({ws})\")\n    return arr, ws\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Simple moving\u2011average filter.\"\"\"\n    arr, ws = _as_array(x, window_size)\n    return np.convolve(arr, np.ones(ws) / ws, mode=\"valid\")\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"Exponentially weighted moving\u2011average filter.\"\"\"\n    arr, ws = _as_array(x, window_size)\n    w = np.exp(np.linspace(-2, 0, ws))\n    w /= w.sum()\n    return np.convolve(arr, w, mode=\"valid\")\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; output length matches other filters.\"\"\"\n    arr, ws = _as_array(x, window_size)\n    alpha = 2.0 / (ws + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[ws - 1 :]\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"Dispatch to the selected filtering algorithm (case\u2011insensitive).\"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n    # default to enhanced for unknown or \"enhanced\"\n    return enhanced_filter_with_trend_preservation(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to composite_score\n\n### Program D2 (Score: 13.4402)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\ndef _validate_window(window_size: int) -> int:\n    \"\"\"Validate and normalize the window size.\"\"\"\n    if not isinstance(window_size, (int, np.integer)):\n        raise TypeError(f\"window_size must be an integer, got {type(window_size).__name__}\")\n    ws = int(window_size)\n    if ws <= 0:\n        raise ValueError(f\"window_size must be positive, got {ws}\")\n    return ws\n\ndef _to_array(x, window_size):\n    \"\"\"Convert input to a 1\u2011D float array and ensure it meets the window requirement.\"\"\"\n    ws = _validate_window(window_size)\n    arr = np.asarray(x, dtype=float)\n    if arr.ndim != 1:\n        raise ValueError(\"Input signal must be one\u2011dimensional\")\n    if arr.size < ws:\n        raise ValueError(f\"Input length ({arr.size}) must be >= window_size ({ws})\")\n    return arr, ws\n\n@lru_cache(maxsize=32)\ndef _exp_weights(ws: int):\n    \"\"\"Pre\u2011compute exponential weights for a given window size.\"\"\"\n    w = np.exp(np.linspace(-2, 0, ws))\n    return w / w.sum()\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Simple moving\u2011average filter (valid convolution).\"\"\"\n    arr, ws = _to_array(x, window_size)\n    kernel = np.ones(ws, dtype=float) / ws\n    return np.convolve(arr, kernel, mode='valid')\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"Exponentially weighted moving\u2011average filter (valid convolution).\"\"\"\n    arr, ws = _to_array(x, window_size)\n    kernel = _exp_weights(ws)\n    return np.convolve(arr, kernel, mode='valid')\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; output aligned with other filters.\"\"\"\n    arr, ws = _to_array(x, window_size)\n    alpha = 2.0 / (ws + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[ws - 1 :]\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Dispatch to the selected filtering algorithm.\n\n    Parameters\n    ----------\n    input_signal : array\u2011like\n        Raw time\u2011series data.\n    window_size : int, optional\n        Size of the sliding window (default 20).\n    algorithm_type : str, optional\n        One of ``\"basic\"``, ``\"enhanced\"``, ``\"exp\"`` (case\u2011insensitive).\n\n    Returns\n    -------\n    numpy.ndarray\n        Filtered signal with length ``len(input_signal) - window_size + 1``.\n    \"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    if alg == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n\n    raise ValueError(\n        f\"Unsupported algorithm_type '{algorithm_type}'. \"\n        \"Supported types are: 'basic', 'enhanced', 'exp'.\"\n    )\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to composite_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 13.4402, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\ntry:\n    from scipy.signal import savgol_filter\n    _HAS_SAVGOL = True\nexcept Exception:\n    _HAS_SAVGOL = False\n\n\ndef _check_length(x, window_size):\n    \"\"\"Validate that input length meets the required window size.\"\"\"\n    if x.size < window_size:\n        raise ValueError(f\"Input length ({x.size}) < window_size ({window_size})\")\n\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Simple moving\u2011average filter.\"\"\"\n    x = np.asarray(x, dtype=float)\n    _check_length(x, window_size)\n    return np.convolve(x, np.ones(window_size) / window_size, mode='valid')\n\n\ndef weighted_filter(x, window_size=20):\n    \"\"\"Exponential\u2011weighted moving average (enhanced filter).\"\"\"\n    x = np.asarray(x, dtype=float)\n    _check_length(x, window_size)\n    w = np.exp(np.linspace(-2, 0, window_size))\n    w /= w.sum()\n    return np.convolve(x, w, mode='valid')\n\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; output length matches other filters.\"\"\"\n    x = np.asarray(x, dtype=float)\n    _check_length(x, window_size)\n    alpha = 2.0 / (window_size + 1.0)\n    y = np.empty_like(x)\n    y[0] = x[0]\n    for i in range(1, x.size):\n        y[i] = alpha * x[i] + (1.0 - alpha) * y[i - 1]\n    return y[window_size - 1:]\n\n\ndef _savgol_wrapper(x, window_size=20, polyorder=3):\n    \"\"\"Savitzky\u2011Golay filter with safe parameter handling.\"\"\"\n    if not _HAS_SAVGOL:\n        return adaptive_filter(x, window_size)\n\n    w = int(window_size)\n    if w % 2 == 0:\n        w += 1\n    if w < polyorder + 2:\n        w = polyorder + 2\n        if w % 2 == 0:\n            w += 1\n    return savgol_filter(x, window_length=w, polyorder=polyorder, mode='interp')\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Dispatch to the selected filtering algorithm.\n\n    Supported algorithm_type values:\n        - \"basic\"   : simple moving average\n        - \"enhanced\": exponential\u2011weighted moving average\n        - \"exp\"     : exponential smoothing\n        - \"savgol\"  : Savitzky\u2011Golay (fallback to basic if unavailable)\n    \"\"\"\n    if algorithm_type == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if algorithm_type == \"enhanced\":\n        return weighted_filter(input_signal, window_size)\n    if algorithm_type == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n    if algorithm_type == \"savgol\":\n        return _savgol_wrapper(input_signal, window_size)\n    raise ValueError(f\"Unknown algorithm_type: {algorithm_type}\")\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (91.000)\n\n### Inspiration 2 (Score: 10.2884, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\ntry:\n    from scipy.signal import savgol_filter\n    _HAS_SAVGOL = True\nexcept Exception:\n    _HAS_SAVGOL = False\n\n\ndef _validate_input(x, window_size):\n    \"\"\"Convert input to a NumPy array and ensure it meets the minimum length.\"\"\"\n    x = np.asarray(x, dtype=float)\n    if x.size == 0:\n        return x\n    if x.size < window_size:\n        raise ValueError(f\"Input length ({x.size}) < window_size ({window_size})\")\n    return x\n\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Simple moving\u2011average filter.\"\"\"\n    x = _validate_input(x, window_size)\n    if x.size == 0:\n        return np.array([], dtype=float)\n    return np.convolve(x, np.ones(window_size) / window_size, mode='valid')\n\n\ndef _apply_savgol(x, window_size, polyorder=3):\n    \"\"\"Safely apply Savitzky\u2011Golay filtering with sensible parameter handling.\"\"\"\n    if not _HAS_SAVGOL:\n        return adaptive_filter(x, window_size)\n\n    w = int(window_size)\n    # Ensure odd window length\n    if w % 2 == 0:\n        w += 1\n    # Minimum size required by the polynomial order\n    min_len = polyorder + 2\n    if w < min_len:\n        w = min_len + (min_len % 2 == 0)\n    return savgol_filter(x, window_length=w, polyorder=polyorder, mode='interp')\n\n\ndef _adaptive_window(base_window, signal):\n    \"\"\"\n    Determine an adaptive Savitzky\u2011Golay window size based on signal variability.\n    The coefficient of variation (cv) guides the scaling:\n        cv \u2248 0 \u2192 use larger window (smoother)\n        cv \u2248 1 \u2192 use base window\n    \"\"\"\n    if signal.size == 0:\n        return base_window\n    cv = np.std(signal) / (np.mean(np.abs(signal)) + 1e-9)\n    # Clamp cv to [0, 1] for scaling\n    cv = max(0.0, min(1.0, cv))\n    # Map cv \u2208 [0,1] \u2192 window \u2208 [base_window, max(5, base_window)]\n    adaptive = int(base_window * (1.0 - 0.5 * cv))  # shrink up to 50% for high variability\n    adaptive = max(5, adaptive)\n    if adaptive % 2 == 0:\n        adaptive += 1\n    return adaptive\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"\n    Multi\u2011stage filter:\n        1\ufe0f\u20e3 Exponential weighted moving average (EWMA) \u2013 emphasizes recent samples.\n        2\ufe0f\u20e3 Adaptive Savitzky\u2011Golay smoothing \u2013 window size adapts to signal variability.\n        3\ufe0f\u20e3 Short moving average (5\u2011point) \u2013 removes residual high\u2011frequency noise.\n    \"\"\"\n    x = _validate_input(x, window_size)\n    if x.size == 0:\n        return np.array([], dtype=float)\n\n    # Stage 1: EWMA\n    weights = np.exp(np.linspace(-2, 0, window_size))\n    weights /= weights.sum()\n    ewma = np.convolve(x, weights, mode='valid')\n\n    # Stage 2: Adaptive Savitzky\u2011Golay\n    adaptive_win = _adaptive_window(window_size, ewma)\n    sg = _apply_savgol(ewma, adaptive_win, polyorder=2)\n\n    # Stage 3: Final short moving average (5\u2011point) for residual smoothing\n    if sg.size < 5:\n        return sg\n    final = np.convolve(sg, np.ones(5) / 5, mode='valid')\n    return final\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Dispatch to the selected filtering algorithm.\n\n    Parameters\n    ----------\n    input_signal : array\u2011like\n        Raw signal to be filtered.\n    window_size : int, optional\n        Base window length for filters (default is 20).\n    algorithm_type : {\"basic\", \"savgol\", \"enhanced\"}, optional\n        Choose the filtering strategy.\n    \"\"\"\n    if algorithm_type == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if algorithm_type == \"savgol\":\n        return _apply_savgol(input_signal, window_size, polyorder=3)\n    # Default / \"enhanced\"\n    return enhanced_filter_with_trend_preservation(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (87.000)\n\n### Inspiration 3 (Score: 0.0000, Type: Exploratory)\n```python\n# EVOLVE-BLOCK-START\ndef _prepare_signal(x, window_size):\n    \"\"\"Validate and convert input to a 1\u2011D NumPy array.\n\n    Returns an empty array if the input is shorter than the window,\n    allowing callers to handle the case gracefully.\n    \"\"\"\n    if not isinstance(window_size, int) or window_size <= 0:\n        raise ValueError(f\"window_size must be a positive integer, got {window_size}\")\n    arr = np.asarray(x, dtype=float)\n    if arr.ndim != 1:\n        raise ValueError(\"Input signal must be one\u2011dimensional\")\n    if arr.size < window_size:\n        return np.array([], dtype=float)\n    return arr\n\n\ndef _gaussian_weights(window_size):\n    \"\"\"Create a normalized Gaussian kernel centered in the window.\"\"\"\n    sigma = max(window_size / 6.0, 0.1)  # \u00b13\u03c3 \u2248 window size\n    centre = (window_size - 1) / 2.0\n    idx = np.arange(window_size)\n    w = np.exp(-0.5 * ((idx - centre) / sigma) ** 2)\n    return w / w.sum()\n\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Simple moving\u2011average filter (valid convolution).\"\"\"\n    arr = _prepare_signal(x, window_size)\n    if arr.size == 0:\n        return arr\n    return np.convolve(arr, np.ones(window_size) / window_size, mode=\"valid\")\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"Gaussian\u2011weighted moving average (valid convolution).\"\"\"\n    arr = _prepare_signal(x, window_size)\n    if arr.size == 0:\n        return arr\n    w = _gaussian_weights(window_size)\n    return np.convolve(arr, w, mode=\"valid\")\n\n\ndef _savgol_filter(x, window_size=20, polyorder=3):\n    \"\"\"Savitzky\u2011Golay filter with safe fallback to Gaussian\u2011weighted MA.\"\"\"\n    arr = _prepare_signal(x, window_size)\n    if arr.size == 0:\n        return arr\n    try:\n        from scipy import signal\n\n        w = int(window_size)\n        if w % 2 == 0:\n            w += 1\n        w = max(w, polyorder + 2)\n        if w % 2 == 0:\n            w += 1\n        return signal.savgol_filter(arr, window_length=w, polyorder=polyorder, mode=\"interp\")\n    except Exception:\n        # If SciPy is unavailable or parameters are invalid, fall back\n        return enhanced_filter_with_trend_preservation(arr, window_size)\n\n\ndef hybrid_filter(x, window_size=20):\n    \"\"\"Apply enhanced filter followed by a simple moving average.\"\"\"\n    first_pass = enhanced_filter_with_trend_preservation(x, window_size)\n    if first_pass.size == 0:\n        return first_pass\n    # Second pass uses the same window size; result length is further reduced\n    return np.convolve(first_pass, np.ones(window_size) / window_size, mode=\"valid\")\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"Dispatch to a filtering algorithm (case\u2011insensitive).\"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    if alg == \"savgol\":\n        return _savgol_filter(input_signal, window_size)\n    if alg == \"hybrid\":\n        return hybrid_filter(input_signal, window_size)\n    raise ValueError(f\"Unknown algorithm_type: {algorithm_type}\")\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Alternative runs_successfully approach, NumPy-based implementation\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\nfrom typing import Tuple, Callable\n\n\ndef _prepare_input(x, window: int) -> Tuple[np.ndarray, int]:\n    \"\"\"Validate *window* and convert *x* to a 1\u2011D float array.\n\n    Returns an empty array when the signal is shorter than *window* so callers can\n    handle the situation gracefully.\n    \"\"\"\n    ws = int(window)\n    if ws <= 0:\n        raise ValueError(\"window_size must be positive\")\n    arr = np.asarray(x, dtype=float).ravel()\n    if arr.size < ws:\n        return np.empty(0, dtype=float), ws\n    return arr, ws\n\n\n@lru_cache(maxsize=32)\ndef _exp_weights(ws: int) -> np.ndarray:\n    \"\"\"Exponentially\u2011decaying weights for EWMA.\"\"\"\n    w = np.exp(np.linspace(-2, 0, ws))\n    return w / w.sum()\n\n\ndef adaptive_filter(x, window_size: int = 20) -> np.ndarray:\n    \"\"\"Simple moving\u2011average (valid convolution).\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    return np.convolve(arr, np.ones(ws) / ws, mode=\"valid\")\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size: int = 20) -> np.ndarray:\n    \"\"\"EWMA \u2192 adaptive Savitzky\u2011Golay \u2192 short MA (length\u202f5).\n\n    This pipeline gives stronger noise reduction while keeping signal dynamics.\n    \"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n\n    # 1\ufe0f\u20e3 EWMA (valid convolution)\n    ewma = np.convolve(arr, _exp_weights(ws), mode=\"valid\")\n\n    # 2\ufe0f\u20e3 Adaptive Savitzky\u2011Golay window based on signal variability\n    sg = _apply_savgol(ewma, ws)\n\n    # 3\ufe0f\u20e3 Final short moving average to remove any high\u2011frequency residue\n    final = np.convolve(sg, np.ones(5) / 5, mode=\"valid\")\n    return final\n\n\ndef exponential_smoothing(x, window_size: int = 20) -> np.ndarray:\n    \"\"\"Recursive exponential smoothing; output aligns with other filters.\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    alpha = 2.0 / (ws + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[ws - 1 :]\n\n\ndef _apply_savgol(signal: np.ndarray, base_ws: int, polyorder: int = 3) -> np.ndarray:\n    \"\"\"Apply Savitzky\u2011Golay with an adaptive window length.\n\n    If SciPy is unavailable, falls back to a simple moving average.\n    \"\"\"\n    try:\n        from scipy import signal as scipy_signal\n    except Exception:\n        # Fallback \u2013 simple moving average with the original window size\n        return np.convolve(signal, np.ones(base_ws) / base_ws, mode=\"valid\")\n\n    # Compute a scale factor from variance\u2011to\u2011mean\u2011abs ratio\n    var_ratio = np.var(signal) / (np.mean(np.abs(signal)) + 1e-9)\n    scale = np.clip(var_ratio, 0.5, 2.0)  # keep window reasonable\n    adaptive_len = int(max(polyorder + 2, min(base_ws * 2, base_ws * scale)))\n    # Ensure odd length\n    if adaptive_len % 2 == 0:\n        adaptive_len += 1\n    # Final safety check\n    adaptive_len = max(adaptive_len, polyorder + 2)\n    if adaptive_len % 2 == 0:\n        adaptive_len += 1\n\n    return scipy_signal.savgol_filter(signal, window_length=adaptive_len,\n                                     polyorder=polyorder, mode=\"interp\")\n\n\ndef process_signal(input_signal, window_size: int = 20, algorithm_type: str = \"enhanced\") -> np.ndarray:\n    \"\"\"Dispatch to the requested filtering algorithm.\n\n    Supported ``algorithm_type`` values (case\u2011insensitive):\n        \"basic\"   \u2013 simple moving average\n        \"enhanced\"\u2013 EWMA \u2192 adaptive Savitzky\u2011Golay \u2192 short MA (default)\n        \"exp\"     \u2013 exponential smoothing\n        \"savgol\"  \u2013 pure Savitzky\u2011Golay (fallback to basic)\n        \"hybrid\"  \u2013 EWMA followed by exponential smoothing\n    \"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    if alg == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n    if alg == \"savgol\":\n        arr, ws = _prepare_input(input_signal, window_size)\n        return _apply_savgol(arr, ws) if arr.size else arr\n    if alg == \"hybrid\":\n        tmp = enhanced_filter_with_trend_preservation(input_signal, window_size)\n        return exponential_smoothing(tmp, window_size)\n\n    # Default fallback\n    return enhanced_filter_with_trend_preservation(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\n\n# Task\nImprove the code to maximize FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\n\n## CRITICAL INSTRUCTIONS\nIf the code contains `# EVOLVE-BLOCK-START` and `# EVOLVE-BLOCK-END` markers:\n- Output ONLY the code that goes BETWEEN these markers\n- Do NOT include the markers themselves\n- Do NOT include code outside the markers (like `run_packing()`)\n- The system will automatically merge your output with the preserved sections\n\nIf there are NO EVOLVE-BLOCK markers:\n- Output the complete rewritten program\n\n```python\n# Your improved code here (ONLY the evolve block content if markers exist)\n```", "responses": ["import numpy as np\nfrom functools import lru_cache\nfrom typing import Tuple\n\ndef _prepare_input(x, window: int) -> Tuple[np.ndarray, int]:\n    ws = int(window)\n    if ws <= 0:\n        raise ValueError(\"window_size must be positive\")\n    arr = np.asarray(x, dtype=float).ravel()\n    if arr.size < ws:\n        return np.empty(0, dtype=float), ws\n    return arr, ws\n\n@lru_cache(maxsize=32)\ndef _exp_weights(ws: int) -> np.ndarray:\n    w = np.exp(np.linspace(-2, 0, ws))\n    return w / w.sum()\n\ndef adaptive_filter(x, window_size: int = 20) -> np.ndarray:\n    arr, ws = _prepare_input(x, window_size)\n    return np.convolve(arr, np.ones(ws) / ws, mode=\"valid\") if arr.size else arr\n\ndef _apply_savgol(signal: np.ndarray, base_ws: int, polyorder: int = 3) -> np.ndarray:\n    try:\n        from scipy import signal as scipy_signal\n    except Exception:\n        return np.convolve(signal, np.ones(base_ws) / base_ws, mode=\"valid\")\n    var = np.var(signal)\n    mean = np.mean(np.abs(signal)) + 1e-9\n    scale = var / mean\n    win = int(max(polyorder + 2, min(base_ws * 2, base_ws * scale)))\n    if win % 2 == 0:\n        win += 1\n    win = max(win, polyorder + 2)\n    if win % 2 == 0:\n        win += 1\n    return scipy_signal.savgol_filter(signal, win, polyorder, mode=\"interp\")\n\ndef enhanced_filter_with_trend_preservation(x, window_size: int = 20) -> np.ndarray:\n    arr, ws = _prepare_input(x, window_size)\n    if not arr.size:\n        return arr\n    ewma = np.convolve(arr, _exp_weights(ws), mode=\"valid\")\n    sg = _apply_savgol(ewma, ws)\n    return np.convolve(sg, np.ones(5) / 5, mode=\"valid\") if sg.size >= 5 else sg\n\ndef exponential_smoothing(x, window_size: int = 20) -> np.ndarray:\n    arr, ws = _prepare_input(x, window_size)\n    if not arr.size:\n        return arr\n    alpha = 2.0 / (ws + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[ws - 1 :]\n\ndef process_signal(input_signal, window_size: int = 20, algorithm_type: str = \"enhanced\") -> np.ndarray:\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    if alg == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n    if alg == \"savgol\":\n        arr, ws = _prepare_input(input_signal, window_size)\n        return _apply_savgol(arr, ws) if arr.size else arr\n    if alg == \"hybrid\":\n        tmp = enhanced_filter_with_trend_preservation(input_signal, window_size)\n        return exponential_smoothing(tmp, window_size)\n    return enhanced_filter_with_trend_preservation(input_signal, window_size)"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}