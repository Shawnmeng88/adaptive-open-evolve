{"id": "59e6e738-e87c-43e0-91b3-0fdd12bb7301", "code": "# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _to_np(x):\n    \"\"\"Convert input to 1\u2011D float NumPy array.\"\"\"\n    return np.asarray(x, dtype=float).ravel()\n\n\ndef _gaussian_weights(w):\n    \"\"\"Generate normalized Gaussian kernel of length w.\"\"\"\n    sigma = 0.3 * w\n    centre = (w - 1) / 2.0\n    idx = np.arange(w)\n    weights = np.exp(-0.5 * ((idx - centre) / sigma) ** 2)\n    return weights / weights.sum()\n\n\ndef adaptive_filter(x, w=20):\n    \"\"\"Simple moving\u2011average (valid convolution).\"\"\"\n    x = _to_np(x)\n    if w <= 0 or x.size < w:\n        return np.array([], dtype=float)\n    return np.convolve(x, np.ones(w) / w, mode=\"valid\")\n\n\ndef weighted_filter(x, w=20):\n    \"\"\"Gaussian\u2011weighted moving average.\"\"\"\n    x = _to_np(x)\n    if w <= 0 or x.size < w:\n        return np.array([], dtype=float)\n    weights = _gaussian_weights(w)\n    return np.convolve(x, weights, mode=\"valid\")\n\n\ndef ema_filter(x, w=20):\n    \"\"\"Classic exponential moving average (EMA) aligned with MA length.\"\"\"\n    x = _to_np(x)\n    if w <= 0 or x.size < w:\n        return np.array([], dtype=float)\n    alpha = 2.0 / (w + 1)\n    ema = np.empty_like(x)\n    ema[0] = x[0]\n    for i in range(1, len(x)):\n        ema[i] = alpha * x[i] + (1 - alpha) * ema[i - 1]\n    return ema[w - 1 :]\n\n\ndef enhanced_filter_with_trend_preservation(x, w=20):\n    \"\"\"\n    Detrend with a simple moving average, then apply a Gaussian weighted filter.\n    Returns empty array if detrending fails.\n    \"\"\"\n    trend = adaptive_filter(x, w)\n    if trend.size == 0:\n        return np.array([], dtype=float)\n    trend_full = np.concatenate((np.full(w - 1, trend[0]), trend))\n    detrended = _to_np(x) - trend_full\n    return weighted_filter(detrended, w)\n\n\ndef median_filter(x, w=20):\n    \"\"\"Sliding\u2011window median filter.\"\"\"\n    x = _to_np(x)\n    if w <= 0 or x.size < w:\n        return np.array([], dtype=float)\n    stride = x.strides[0]\n    shape = (x.size - w + 1, w)\n    windows = np.lib.stride_tricks.as_strided(x, shape=shape, strides=(stride, stride))\n    return np.median(windows, axis=1)\n\n\ndef combined_filter(x, w=20):\n    \"\"\"\n    Detrend \u2192 Gaussian weighted moving average \u2192 median smoothing.\n    Returns empty array if any stage fails.\n    \"\"\"\n    trend = adaptive_filter(x, w)\n    if trend.size == 0:\n        return np.array([], dtype=float)\n    trend_full = np.concatenate((np.full(w - 1, trend[0]), trend))\n    detrended = _to_np(x) - trend_full\n\n    weighted = weighted_filter(detrended, w)\n    if weighted.size == 0:\n        return np.array([], dtype=float)\n\n    return median_filter(weighted, w)\n\n\ndef _residual_variance(original, filtered):\n    \"\"\"Variance of (original \u2013 filtered) after aligning lengths.\"\"\"\n    if filtered.size == 0:\n        return float(\"inf\")\n    n = min(len(original), len(filtered))\n    if n == 0:\n        return float(\"inf\")\n    return float(np.var(original[:n] - filtered[:n]))\n\n\ndef _select_best_filter(x, w):\n    \"\"\"Choose the filter with the lowest residual variance.\"\"\"\n    x_np = _to_np(x)\n    candidates = {\n        \"basic\": adaptive_filter(x_np, w),\n        \"weighted\": weighted_filter(x_np, w),\n        \"ema\": ema_filter(x_np, w),\n        \"enhanced\": enhanced_filter_with_trend_preservation(x_np, w),\n        \"combined\": combined_filter(x_np, w),\n        \"median\": median_filter(x_np, w),\n    }\n    best_key = min(candidates, key=lambda k: _residual_variance(x_np, candidates[k]))\n    return candidates[best_key]\n\n\ndef process_signal(sig, window_size=20, algorithm_type=\"basic\"):\n    \"\"\"\n    Dispatch to the requested filtering algorithm.\n\n    Supported algorithm_type values (case\u2011insensitive):\n        - \"basic\"   : simple moving average\n        - \"weighted\": Gaussian weighted average\n        - \"ema\"     : classic EMA\n        - \"enhanced\": detrended weighted filter (now auto\u2011selected for best result)\n        - \"combined\": detrend \u2192 weighted \u2192 median\n        - \"median\"  : median filter\n        - any other value falls back to automatic selection.\n    \"\"\"\n    alg = (algorithm_type or \"\").lower()\n    x = _to_np(sig)\n\n    if alg == \"basic\":\n        return adaptive_filter(x, window_size)\n    if alg == \"weighted\":\n        return weighted_filter(x, window_size)\n    if alg == \"ema\":\n        return ema_filter(x, window_size)\n    if alg == \"combined\":\n        return combined_filter(x, window_size)\n    if alg == \"median\":\n        return median_filter(x, window_size)\n    # Treat \"enhanced\" as a request for the best available filter\n    if alg == \"enhanced\":\n        return _select_best_filter(x, window_size)\n\n    # Fallback: auto\u2011select best filter\n    return _select_best_filter(x, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n", "language": "python", "parent_id": "038d9e70-e083-495e-85f1-cdca64b27191", "generation": 10, "timestamp": 1764941685.75118, "iteration_found": 0, "metrics": {"runs_successfully": 1.0, "composite_score": 0.4205150578718804, "output_length": 91.0, "overall_score": 0.38035985150742135, "slope_changes": 68.0, "lag_error": 0.9780360456577568, "avg_error": 1.2635358917076887, "false_reversals": 57.8, "correlation": 0.3334964145206185, "noise_reduction": 0.0, "smoothness_score": 0.22727272727272727, "responsiveness_score": 0.5055519600844633, "accuracy_score": 0.3334964145206185, "efficiency_score": 1.0, "execution_time": 0.0014206886291503907, "success_rate": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Evolve block rewrite (preserved external code)", "parent_metrics": {"runs_successfully": 1.0, "composite_score": 0.4429433309255678, "output_length": 91.0, "overall_score": 0.3624766970140094, "slope_changes": 68.6, "lag_error": 0.4099887786960041, "avg_error": 1.1150775516528053, "false_reversals": 56.6, "correlation": 0.20076318890739916, "noise_reduction": 0.0, "smoothness_score": 0.22573363431151244, "responsiveness_score": 0.709225502436145, "accuracy_score": 0.20076318890739916, "efficiency_score": 1.0, "execution_time": 0.0003239154815673828, "success_rate": 1.0}, "island": 3, "migrant": true}, "prompts": null, "artifacts_json": null, "artifact_dir": null, "embedding": null}