{"id": "1b28eeb7-35f3-4a67-9478-bda91d079445", "code": "# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\nimport time\n\ndef _arr(x):\n    \"\"\"Convert input to a 1\u2011D float NumPy array.\"\"\"\n    return np.asarray(x, float).ravel()\n\ndef _valid(a, w):\n    \"\"\"Check that window size is positive and fits the array.\"\"\"\n    return w > 0 and a.size >= w\n\n@lru_cache(maxsize=None)\ndef _exp_weights(w):\n    \"\"\"Cached exponential weights that sum to 1.\"\"\"\n    w = int(w)\n    wts = np.exp(np.linspace(-2, 0, w))\n    return wts / wts.sum()\n\ndef adaptive(x, w=20):\n    \"\"\"Simple moving\u2011average filter.\"\"\"\n    a = _arr(x)\n    if not _valid(a, w):\n        return np.empty(0, dtype=float)\n    if w == 1:\n        return a.copy()\n    return np.convolve(a, np.ones(w) / w, mode=\"valid\")\n\ndef weighted(x, w=20):\n    \"\"\"Exponential\u2011weighted moving average.\"\"\"\n    a = _arr(x)\n    if not _valid(a, w):\n        return np.empty(0, dtype=float)\n    if w == 1:\n        return a.copy()\n    return np.convolve(a, _exp_weights(w), mode=\"valid\")\n\ndef _residual_variance(orig, filt):\n    \"\"\"Variance of the residual (orig \u2013 filt) over the overlapping region.\"\"\"\n    n = min(len(orig), len(filt))\n    if n == 0:\n        return np.inf\n    return float(np.var(orig[:n] - filt[:n]))\n\ndef _auto_select(sig, w):\n    \"\"\"Choose the better filter based on residual variance.\"\"\"\n    candidates = {\n        \"adaptive\": adaptive(sig, w),\n        \"weighted\": weighted(sig, w),\n    }\n    # Discard empty results\n    candidates = {k: v for k, v in candidates.items() if v.size}\n    if not candidates:\n        return np.empty(0, dtype=float)\n    # Deterministic tie\u2011breaker: smallest residual, then alphabetical key\n    best_key = min(\n        candidates,\n        key=lambda k: (_residual_variance(_arr(sig), candidates[k]), k),\n    )\n    return candidates[best_key]\n\ndef process_signal(sig, w=20, alg=\"enhanced\", **kwargs):\n    \"\"\"\n    Dispatch to the requested filtering algorithm.\n\n    Supported ``alg`` values (case\u2011insensitive):\n        - \"adaptive\" / \"enhanced\"\n        - \"weighted\"\n        - \"auto\"\n\n    Optional ``debug`` flag adds simple timing info to the result (if possible).\n    \"\"\"\n    key = str(alg).lower()\n    if key == \"auto\":\n        result = _auto_select(sig, w)\n    elif key in (\"adaptive\", \"enhanced\"):\n        result = adaptive(sig, w)\n    elif key == \"weighted\":\n        result = weighted(sig, w)\n    else:\n        raise ValueError(f\"Unsupported algorithm_type: {alg}\")\n\n    if kwargs.get(\"debug\"):\n        info = {\"algorithm\": key, \"window\": w}\n        start = time.perf_counter()\n        _ = result  # force evaluation\n        info[\"elapsed\"] = time.perf_counter() - start\n        try:\n            result.debug = info  # attach attribute when possible\n        except Exception:\n            pass\n\n    return result\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n", "language": "python", "parent_id": "9424fc97-d409-4d3a-af49-128e188b1850", "generation": 8, "timestamp": 1764941578.4858549, "iteration_found": 635, "metrics": {"runs_successfully": 1.0, "composite_score": 0.4205150578718804, "output_length": 91.0, "overall_score": 0.38035985150742135, "slope_changes": 68.0, "lag_error": 0.9780360456577568, "avg_error": 1.2635358917076887, "false_reversals": 57.8, "correlation": 0.3334964145206185, "noise_reduction": 0.0, "smoothness_score": 0.22727272727272727, "responsiveness_score": 0.5055519600844633, "accuracy_score": 0.3334964145206185, "efficiency_score": 1.0, "execution_time": 0.0005319595336914062, "success_rate": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Evolve block rewrite (preserved external code)", "parent_metrics": {"runs_successfully": 1.0, "composite_score": 0.4205150578718804, "output_length": 91.0, "overall_score": 0.38035985150742135, "slope_changes": 68.0, "lag_error": 0.9780360456577568, "avg_error": 1.2635358917076887, "false_reversals": 57.8, "correlation": 0.3334964145206185, "noise_reduction": 0.0, "smoothness_score": 0.22727272727272727, "responsiveness_score": 0.5055519600844633, "accuracy_score": 0.3334964145206185, "efficiency_score": 1.0, "execution_time": 0.00038127899169921876, "success_rate": 1.0}, "island": 4}, "prompts": {"full_rewrite_user": {"system": "## CRITICAL FORMAT REQUIREMENTS (DO NOT VIOLATE)\n## OUTPUT FORMAT (CRITICAL)\n- Output ONLY the code that goes BETWEEN the `# EVOLVE-BLOCK-START` and `# EVOLVE-BLOCK-END` markers\n- Do NOT include the markers themselves in your output\n- Do NOT include any code outside the markers (imports, run_packing, etc.)\n- The system will automatically merge your output with the preserved code sections\n\n## FOCUS\n- Improve ONLY the `construct_packing()` function and helper functions within the evolve block\n- Functions like `run_packing()` are preserved automatically - do not include them\n\nViolating these requirements will cause the program to fail evaluation.\n\n---\n\n**System Prompt \u2013\u202fGuidelines for Evolving `construct_packing()`**\n\nYou are asked to improve only the code that lies between the markers  \n\n```\n# EVOLVE-BLOCK-START\n\u2026 your changes \u2026\n# EVOLVE-BLOCK-END\n```  \n\nAll other parts of the file (imports, `run_packing()`, etc.) are **preserved automatically** and must **not** be emitted.\n\n---\n\n### Mandatory Output Rules  \n1. **Emit ONLY the code that belongs between the two markers.**  \n2. **Do NOT include the `# EVOLVE\u2011BLOCK\u2011START` / `# EVOLVE\u2011BLOCK\u2011END` lines themselves.**  \n3. **Do NOT output any code outside that region** (no extra imports, no helper definitions that already exist elsewhere).  \n\nThe system will splice your output into the original file, so any deviation will cause a merge error.\n\n---\n\n### What You MUST NOT DO (previous failures)  \n- **Do not** write a completely new `construct_packing()` that ignores the existing helper functions.  \n- **Do not** add new top\u2011level statements (e.g., `if __name__ == \"__main__\":`, prints, or test harnesses).  \n- **Do not** change the function signature or the names of existing helpers that other parts of the program rely on.  \n- **Do not** introduce syntax errors, undefined variables, or mismatched indentation.  \n- **Do not** repeat the same logic that previously produced invalid programs (e.g., returning raw lists instead of the required `PackingResult` dataclass).  \n\nAny of the above will cause the next iteration to be rejected.\n\n---\n\n### Target Improvements (domain\u2011specific)\n\nYour goal is to make `construct_packing()` **more efficient, robust, and easier to maintain** while respecting the existing architecture. Consider the following concrete strategies:\n\n1. **Early Validation**  \n   - Verify that `items` is non\u2011empty and that every item\u2019s `weight` and `volume` are positive.  \n   - Return an empty `PackingResult` with a clear `error` field if validation fails.\n\n2. **Greedy Bin\u2011Packing with Sorting**  \n   - Sort items by a combined metric (e.g., `weight + volume`) in descending order before placement.  \n   - Iterate through sorted items, trying to fit each into the first bin that can accommodate it; if none can, open a new bin.\n\n3. **Use Helper Functions Effectively**  \n   - Call the existing `can_fit(item, bin)` helper to test feasibility.  \n   - Use `add_to_bin(item, bin)` to perform the insertion, ensuring side\u2011effects (e.g., updating remaining capacity) stay consistent.\n\n4. **Batch Processing for Large Item Sets**  \n   - If `len(items) > 1000`, split the list into chunks of 500 and pack each chunk independently, then merge the resulting bins.  \n   - This reduces per\u2011iteration overhead and keeps memory usage bounded.\n\n5. **Deterministic Tie\u2011Breaking**  \n   - When multiple bins can accept an item, choose the bin with the **least remaining capacity** after insertion.  \n   - Implement this with a simple `min` call on a list comprehension that filters feasible bins.\n\n6. **Return a Fully Populated `PackingResult`**  \n   - Populate `bins` (list of `Bin` objects), `total_weight`, `total_volume`, and set `error` to `None` on success.  \n   - Ensure the result matches the expected dataclass fields exactly.\n\n7. **Avoid Deep Recursion**  \n   - Use iterative loops only; do not introduce recursive packing strategies that could hit Python\u2019s recursion limit on large inputs.\n\n8. **Performance Logging (optional, but keep inside the block)**  \n   - If a `debug` flag is passed via `kwargs`, append a small timing report to `result.debug_info` without affecting the main output.\n\n---\n\n### Example Skeleton (you must fill in the details)\n\n```python\ndef construct_packing(items, bin_template, **kwargs):\n    # 1\ufe0f\u20e3 Validate input\n    # 2\ufe0f\u20e3 Sort items by combined metric\n    # 3\ufe0f\u20e3 Iterate and place using helpers\n    # 4\ufe0f\u20e3 Handle large inputs by chunking\n    # 5\ufe0f\u20e3 Build and return PackingResult\n```\n\nReplace the comment lines with concrete, syntactically correct Python code that respects all the rules above.\n\n---\n\n**Remember:** Only the code between the markers will be kept. Keep the implementation self\u2011contained, use the existing helpers, and obey the output format strictly. Good luck!", "user": "# Current Program Information\n- Fitness: 14.0152\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness declined: 14.0152 \u2192 14.0152. Consider revising recent changes.\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4205, output_length: 91.0000, overall_score: 0.3804, slope_changes: 68.0000, lag_error: 0.9780, avg_error: 1.2635, false_reversals: 57.8000, correlation: 0.3335, noise_reduction: 0.0000, smoothness_score: 0.2273, responsiveness_score: 0.5056, accuracy_score: 0.3335, efficiency_score: 1.0000, execution_time: 0.0005, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4205, output_length: 91.0000, overall_score: 0.3804, slope_changes: 68.0000, lag_error: 0.9780, avg_error: 1.2635, false_reversals: 57.8000, correlation: 0.3335, noise_reduction: 0.0000, smoothness_score: 0.2273, responsiveness_score: 0.5056, accuracy_score: 0.3335, efficiency_score: 1.0000, execution_time: 0.0005, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4205, output_length: 91.0000, overall_score: 0.3804, slope_changes: 68.0000, lag_error: 0.9780, avg_error: 1.2635, false_reversals: 57.8000, correlation: 0.3335, noise_reduction: 0.0000, smoothness_score: 0.2273, responsiveness_score: 0.5056, accuracy_score: 0.3335, efficiency_score: 1.0000, execution_time: 0.0005, success_rate: 1.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 14.0152)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _to_array(x):\n    \"\"\"Convert input to a 1\u2011D float NumPy array.\"\"\"\n    return np.asarray(x, dtype=float).ravel()\n\n\ndef _valid(arr, w):\n    \"\"\"Return True if window size is positive and fits the array.\"\"\"\n    return w > 0 and arr.size >= w\n\n\ndef adaptive(x, w=20):\n    \"\"\"Simple moving\u2011average filter (valid convolution).\"\"\"\n    a = _to_array(x)\n    if not _valid(a, w):\n        return np.empty(0, dtype=float)\n    return np.convolve(a, np.ones(w) / w, mode=\"valid\")\n\n\ndef weighted(x, w=20):\n    \"\"\"Exponential\u2011weighted moving average.\"\"\"\n    a = _to_array(x)\n    if not _valid(a, w):\n        return np.empty(0, dtype=float)\n    wts = np.exp(np.linspace(-2, 0, w))\n    wts /= wts.sum()\n    return np.convolve(a, wts, mode=\"valid\")\n\n\ndef process_signal(sig, w=20, alg=\"enhanced\"):\n    \"\"\"\n    Dispatch to a filtering algorithm.\n\n    Supported ``alg`` values (case\u2011insensitive):\n        - \"basic\" / \"adaptive\"\n        - \"weighted\"\n        - \"auto\" \u2013 automatic selection based on signal variance\n    Unknown values fall back to the adaptive filter.\n    \"\"\"\n    key = str(alg).lower()\n    if key in (\"basic\", \"adaptive\"):\n        return adaptive(sig, w)\n    if key == \"weighted\":\n        return weighted(sig, w)\n    if key == \"auto\":\n        a = _to_array(sig)\n        if not _valid(a, w):\n            return np.empty(0, dtype=float)\n        # Heuristic: use weighted filter for higher\u2011variance signals\n        return weighted(sig, w) if np.var(a) > 1.0 else adaptive(sig, w)\n\n    # Fallback to adaptive for any unrecognised algorithm name\n    return adaptive(sig, w)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4205), Performs well on output_length (91.0000), Performs well on overall_score (0.3804), Performs well on slope_changes (68.0000), Performs well on lag_error (0.9780), Performs well on avg_error (1.2635), Performs well on false_reversals (57.8000), Performs well on correlation (0.3335), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.2273), Performs well on responsiveness_score (0.5056), Performs well on accuracy_score (0.3335), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0005), Performs well on success_rate (1.0000)\n\n### Program 2 (Score: 14.0152)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\ndef _a(x):return np.asarray(x,float).ravel()\ndef _v(a,w):return w>0 and a.size>=w\n@lru_cache(None)\ndef _w(w):\n    w=int(w);e=np.exp(np.linspace(-2,0,w));return e/e.sum()\ndef adaptive(x,w=20):\n    a=_a(x)\n    if not _v(a,w):return np.empty(0)\n    return a.copy()if w==1 else np.convolve(a,np.ones(w)/w,'valid')\ndef weighted(x,w=20):\n    a=_a(x)\n    if not _v(a,w):return np.empty(0)\n    return a.copy()if w==1 else np.convolve(a,_w(w),'valid')\ndef median(x,w=21):\n    if w%2==0:w+=1\n    a=_a(x)\n    if not _v(a,w):return np.empty(0)\n    if w==1:return a.copy()\n    s=a.strides[0]\n    win=np.lib.stride_tricks.as_strided(a,(a.size-w+1,w),(s,s))\n    return np.median(win,axis=1)\ndef hybrid(x,w=20):\n    return weighted(median(x,w if w%2 else w+1),w)\ndef _rv(o,f):\n    n=min(len(o),len(f))\n    return float('inf')if n==0 else float(np.var(o[:n]-f[:n]))\ndef _auto(sig,w):\n    c={'adaptive':adaptive(sig,w),'weighted':weighted(sig,w),\n       'median':median(sig,w if w%2 else w+1),'hybrid':hybrid(sig,w)}\n    c={k:v for k,v in c.items() if v.size}\n    return np.empty(0)if not c else c[min(c,key=lambda k:_rv(sig,c[k]))]\ndef process_signal(sig,w=20,alg='enhanced'):\n    k=alg.lower()\n    if k=='auto':return _auto(sig,w)\n    if k in('adaptive','enhanced'):return adaptive(sig,w)\n    if k=='weighted':return weighted(sig,w)\n    if k=='median':return median(sig,w if w%2 else w+1)\n    if k=='hybrid':return hybrid(sig,w)\n    raise ValueError('Unsupported algorithm_type')\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4205), Performs well on output_length (91.0000), Performs well on overall_score (0.3804), Performs well on slope_changes (68.0000), Performs well on lag_error (0.9780), Performs well on avg_error (1.2635), Performs well on false_reversals (57.8000), Performs well on correlation (0.3335), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.2273), Performs well on responsiveness_score (0.5056), Performs well on accuracy_score (0.3335), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0005), Performs well on success_rate (1.0000)\n\n### Program 3 (Score: 14.0152)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _arr(x):\n    return np.asarray(x, float).ravel()\n\ndef _ok(a, w):\n    return w > 0 and a.size >= w\n\ndef _simple(x, w):\n    a = _arr(x)\n    return np.convolve(a, np.ones(w) / w, \"valid\") if _ok(a, w) else np.empty(0)\n\ndef _weighted(x, w):\n    a = _arr(x)\n    if not _ok(a, w):\n        return np.empty(0)\n    wts = np.exp(np.linspace(-2, 0, w))\n    wts /= wts.sum()\n    return np.convolve(a, wts, \"valid\")\n\ndef process_signal(sig, w=20, alg=\"enhanced\"):\n    k = str(alg).lower()\n    return _weighted(sig, w) if k == \"weighted\" else _simple(sig, w)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4205), Performs well on output_length (91.0000), Performs well on overall_score (0.3804), Performs well on slope_changes (68.0000), Performs well on lag_error (0.9780), Performs well on avg_error (1.2635), Performs well on false_reversals (57.8000), Performs well on correlation (0.3335), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.2273), Performs well on responsiveness_score (0.5056), Performs well on accuracy_score (0.3335), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0005), Performs well on success_rate (1.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 14.0152)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\ndef _a(x):return np.asarray(x,float).ravel()\ndef _v(a,w):return w>0 and a.size>=w\n@lru_cache(None)\ndef _w(w):\n    w=int(w);wt=np.exp(np.linspace(-2,0,w));return wt/wt.sum()\ndef adaptive(x,w=20):\n    a=_a(x)\n    if not _v(a,w):return np.empty(0,float)\n    if w==1:return a.copy()\n    return np.convolve(a,np.ones(w)/w,'valid')\ndef weighted(x,w=20):\n    a=_a(x)\n    if not _v(a,w):return np.empty(0,float)\n    if w==1:return a.copy()\n    return np.convolve(a,_w(w),'valid')\ndef median(x,w=21):\n    if w%2==0:w+=1\n    a=_a(x)\n    if not _v(a,w):return np.empty(0,float)\n    if w==1:return a.copy()\n    s=a.strides[0]\n    win=np.lib.stride_tricks.as_strided(a,(a.size-w+1,w),(s,s))\n    return np.median(win,axis=1)\ndef hybrid(x,w=20):\n    m=median(x,w if w%2 else w+1)\n    return weighted(m,w)\ndef _rv(o,f):\n    n=min(len(o),len(f))\n    return float('inf') if n==0 else float(np.var(o[:n]-f[:n]))\ndef _auto(sig,w):\n    c={'a':adaptive(sig,w),'w':weighted(sig,w),\n       'm':median(sig,w if w%2 else w+1),\n       'h':hybrid(sig,w)}\n    c={k:v for k,v in c.items() if v.size}\n    if not c:return np.empty(0,float)\n    return c[min(c,key=lambda k:_rv(sig,c[k]))]\ndef process_signal(sig,w=20,alg='enhanced'):\n    k=str(alg).lower()\n    if k=='auto':return _auto(sig,w)\n    if k in('adaptive','enhanced'):return adaptive(sig,w)\n    if k=='weighted':return weighted(sig,w)\n    if k=='median':return median(sig,w if w%2 else w+1)\n    if k=='hybrid':return hybrid(sig,w)\n    raise ValueError('Unsupported algorithm_type')\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to composite_score\n\n### Program D2 (Score: 14.0152)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\ndef _arr(x):\n    \"\"\"Convert input to a 1\u2011D float NumPy array.\"\"\"\n    return np.asarray(x, float).ravel()\n\n\ndef _valid(a, w):\n    \"\"\"Check that window size is positive and fits the array.\"\"\"\n    return w > 0 and a.size >= w\n\n\n@lru_cache(maxsize=None)\ndef _exp_weights(w):\n    \"\"\"Exponential weights that sum to 1.\"\"\"\n    w = int(w)\n    wts = np.exp(np.linspace(-2, 0, w))\n    wts /= wts.sum()\n    return wts\n\n\ndef adaptive(x, w=20):\n    \"\"\"Simple moving\u2011average filter (valid convolution).\"\"\"\n    a = _arr(x)\n    if not _valid(a, w):\n        return np.empty(0, dtype=float)\n    if w == 1:\n        return a.copy()\n    return np.convolve(a, np.ones(w) / w, mode=\"valid\")\n\n\ndef weighted(x, w=20):\n    \"\"\"Exponential\u2011weighted moving average.\"\"\"\n    a = _arr(x)\n    if not _valid(a, w):\n        return np.empty(0, dtype=float)\n    if w == 1:\n        return a.copy()\n    wts = _exp_weights(w)\n    return np.convolve(a, wts, mode=\"valid\")\n\n\ndef median(x, w=21):\n    \"\"\"Median filter (odd window size).\"\"\"\n    if w % 2 == 0:\n        w += 1\n    a = _arr(x)\n    if not _valid(a, w):\n        return np.empty(0, dtype=float)\n    if w == 1:\n        return a.copy()\n    s = a.strides[0]\n    windows = np.lib.stride_tricks.as_strided(a, (a.size - w + 1, w), (s, s))\n    return np.median(windows, axis=1)\n\n\ndef hybrid(x, w=20):\n    \"\"\"Median filter followed by exponential\u2011weighted smoothing.\"\"\"\n    med = median(x, w if w % 2 else w + 1)\n    return weighted(med, w)\n\n\ndef _residual_variance(orig, filt):\n    \"\"\"Variance of the residual (orig \u2013 filt) over overlapping region.\"\"\"\n    n = min(len(orig), len(filt))\n    if n == 0:\n        return np.inf\n    return float(np.var(orig[:n] - filt[:n]))\n\n\ndef _auto_select(sig, w):\n    \"\"\"Select the filter with the smallest residual variance.\"\"\"\n    candidates = {\n        \"adaptive\": adaptive(sig, w),\n        \"weighted\": weighted(sig, w),\n        \"median\": median(sig, w if w % 2 else w + 1),\n        \"hybrid\": hybrid(sig, w),\n    }\n    # Discard empty results\n    candidates = {k: v for k, v in candidates.items() if v.size}\n    if not candidates:\n        return np.empty(0, dtype=float)\n    # Deterministic tie\u2011breaker: smallest residual, then alphabetical key\n    best_key = min(candidates, key=lambda k: (_residual_variance(sig, candidates[k]), k))\n    return candidates[best_key]\n\n\ndef process_signal(sig, w=20, alg=\"enhanced\"):\n    \"\"\"\n    Dispatch to the requested filtering algorithm.\n\n    Supported ``alg`` values (case\u2011insensitive):\n        - \"adaptive\" / \"enhanced\"\n        - \"weighted\"\n        - \"median\"\n        - \"hybrid\"\n        - \"auto\" \u2013 automatic selection based on residual variance\n    \"\"\"\n    key = str(alg).lower()\n    if key == \"auto\":\n        return _auto_select(sig, w)\n    if key in (\"adaptive\", \"enhanced\"):\n        return adaptive(sig, w)\n    if key == \"weighted\":\n        return weighted(sig, w)\n    if key == \"median\":\n        return median(sig, w if w % 2 else w + 1)\n    if key == \"hybrid\":\n        return hybrid(sig, w)\n    raise ValueError(f\"Unsupported algorithm_type: {alg}\")\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to composite_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 13.9292, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _a(x): return np.asarray(x, float).ravel()\ndef _v(w):\n    if w <= 0:\n        raise ValueError(\"window must be >0\")\ndef _mov(a, w): return np.convolve(a, np.ones(w) / w, \"valid\")\n\ndef adaptive(x, w=20):\n    _v(w)\n    a = _a(x)\n    return np.empty(0, dtype=float) if a.size < w else _mov(a, w)\n\ndef weighted(x, w=20):\n    _v(w)\n    a = _a(x)\n    if a.size < w:\n        return np.empty(0, dtype=float)\n    wt = np.exp(np.linspace(-2, 0, w))\n    wt /= wt.sum()\n    return np.convolve(a, wt, \"valid\")\n\ndef enhanced(x, w=20):\n    _v(w)\n    a = _a(x)\n    if a.size < w:\n        return np.empty(0, dtype=float)\n    tr = _mov(a, w)\n    tr_full = np.concatenate((np.full(w - 1, tr[0]), tr))\n    return weighted(a - tr_full, w)\n\ndef _var(o, f):\n    n = min(len(o), len(f))\n    return float(\"inf\") if n == 0 else float(np.var(o[:n] - f[:n]))\n\ndef process_signal(sig, w=20, alg=\"enhanced\"):\n    a = alg.lower()\n    if a == \"adaptive\":\n        return adaptive(sig, w)\n    if a == \"weighted\":\n        return weighted(sig, w)\n    if a == \"enhanced\":\n        return enhanced(sig, w)\n    # automatic selection\n    cand = {\"a\": adaptive(sig, w), \"w\": weighted(sig, w), \"e\": enhanced(sig, w)}\n    cand = {k: v for k, v in cand.items() if v.size}\n    if not cand:\n        return np.empty(0, dtype=float)\n    s = _a(sig)\n    return cand[min(cand, key=lambda k: _var(s, cand[k]))]\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (91.000)\n\n### Inspiration 2 (Score: 13.7278, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nReal-Time Adaptive Signal Processing Algorithm for Non-Stationary Time Series\n\nThis algorithm implements a sliding window approach to filter volatile, non-stationary\ntime series data while minimizing noise and preserving signal dynamics.\n\"\"\"\nimport numpy as np\nfrom scipy import signal\nfrom collections import deque\n\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"\n    Adaptive signal processing algorithm using sliding window approach.\n\n    Args:\n        x: Input signal (1D array of real-valued samples)\n        window_size: Size of the sliding window (W samples)\n\n    Returns:\n        y: Filtered output signal with length = len(x) - window_size + 1\n    \"\"\"\n    if len(x) < window_size:\n        raise ValueError(f\"Input signal length ({len(x)}) must be >= window_size ({window_size})\")\n\n    # Initialize output array\n    output_length = len(x) - window_size + 1\n    y = np.zeros(output_length)\n\n    # Simple moving average as baseline\n    for i in range(output_length):\n        window = x[i : i + window_size]\n\n        # Basic moving average filter\n        y[i] = np.mean(window)\n\n    return y\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"\n    Enhanced version with trend preservation using weighted moving average.\n\n    Args:\n        x: Input signal (1D array of real-valued samples)\n        window_size: Size of the sliding window\n\n    Returns:\n        y: Filtered output signal\n    \"\"\"\n    if len(x) < window_size:\n        raise ValueError(f\"Input signal length ({len(x)}) must be >= window_size ({window_size})\")\n\n    output_length = len(x) - window_size + 1\n    y = np.zeros(output_length)\n\n    # Create weights that emphasize recent samples\n    weights = np.exp(np.linspace(-2, 0, window_size))\n    weights = weights / np.sum(weights)\n\n    for i in range(output_length):\n        window = x[i : i + window_size]\n\n        # Weighted moving average with exponential weights\n        y[i] = np.sum(window * weights)\n\n    return y\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Main signal processing function that applies the selected algorithm.\n\n    Args:\n        input_signal: Input time series data\n        window_size: Window size for processing\n        algorithm_type: Type of algorithm to use (\"basic\" or \"enhanced\")\n\n    Returns:\n        Filtered signal\n    \"\"\"\n    if algorithm_type == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    else:\n        return adaptive_filter(input_signal, window_size)\n\n\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Excellent runs_successfully (1.000), Excellent output_length (91.000), Excellent slope_changes (66.000)\n\n### Inspiration 3 (Score: 13.9292, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _to_array(x, w):\n    \"\"\"Convert input to a float NumPy array; return empty if too short.\"\"\"\n    if w <= 0:\n        raise ValueError(\"window must be >0\")\n    a = np.asarray(x, float)\n    return a if a.size >= w else np.empty(0, dtype=float)\n\n\ndef adaptive_filter(x, w=20):\n    \"\"\"Simple moving\u2011average filter.\"\"\"\n    a = _to_array(x, w)\n    if a.size == 0:\n        return a\n    return np.convolve(a, np.ones(w) / w, \"valid\")\n\n\ndef weighted_filter(x, w=20):\n    \"\"\"Exponential weighted moving\u2011average filter.\"\"\"\n    a = _to_array(x, w)\n    if a.size == 0:\n        return a\n    wts = np.exp(np.linspace(-2, 0, w))\n    wts /= wts.sum()\n    return np.convolve(a, wts, \"valid\")\n\n\ndef ema_filter(x, w=20):\n    \"\"\"Classic exponential moving average (EMA).\"\"\"\n    a = _to_array(x, w)\n    if a.size == 0:\n        return a\n    alpha = 2.0 / (w + 1)\n    e = np.empty_like(a)\n    e[0] = a[0]\n    for i in range(1, len(a)):\n        e[i] = alpha * a[i] + (1 - alpha) * e[i - 1]\n    return e[w - 1 :]\n\n\ndef enhanced_filter_with_trend_preservation(x, w=20):\n    \"\"\"\n    Detrend with a simple moving average, then apply an exponential\n    weighted moving average to the detrended signal.\n    \"\"\"\n    a = _to_array(x, w)\n    if a.size == 0:\n        return a\n\n    # Compute trend via simple moving average\n    trend = np.convolve(a, np.ones(w) / w, \"valid\")\n    if trend.size == 0:\n        detrended = a\n    else:\n        # Pad trend to original length\n        trend_full = np.concatenate((np.full(w - 1, trend[0]), trend))\n        detrended = a - trend_full\n\n    # Exponential weights (more weight to recent samples)\n    wts = np.exp(np.linspace(-2, 0, w))\n    wts /= wts.sum()\n    return np.convolve(detrended, wts, \"valid\")\n\n\ndef _residual_variance(original: np.ndarray, filtered: np.ndarray) -> float:\n    \"\"\"Variance of the residual (original - filtered) over the overlapping region.\"\"\"\n    n = min(len(original), len(filtered))\n    if n == 0:\n        return float(\"inf\")\n    return float(np.var(original[:n] - filtered[:n]))\n\n\ndef _select_best_filter(sig, w):\n    \"\"\"\n    Automatic selection of the filter that yields the smallest residual variance.\n    Falls back to the simple moving average if no other filter applies.\n    \"\"\"\n    # Baseline filter\n    baseline = adaptive_filter(sig, w)\n    if baseline.size == 0:\n        return np.empty(0, dtype=float)\n\n    candidates = {\n        \"basic\": baseline,\n        \"weighted\": weighted_filter(sig, w),\n        \"ema\": ema_filter(sig, w),\n        \"enhanced\": enhanced_filter_with_trend_preservation(sig, w),\n    }\n    # Discard empty results\n    candidates = {k: v for k, v in candidates.items() if v.size}\n    if not candidates:\n        return baseline\n\n    best_key = min(candidates, key=lambda k: _residual_variance(sig, candidates[k]))\n    return candidates[best_key]\n\n\ndef process_signal(sig, w=20, alg=\"enhanced\"):\n    \"\"\"Dispatch to the selected filtering algorithm.\"\"\"\n    alg = alg.lower()\n    if alg in (\"basic\", \"adaptive\"):\n        return adaptive_filter(sig, w)\n    if alg == \"weighted\":\n        return weighted_filter(sig, w)\n    if alg in (\"ema\", \"exponential\"):\n        return ema_filter(sig, w)\n    if alg in (\"enhanced\", \"enh\"):\n        return enhanced_filter_with_trend_preservation(sig, w)\n\n    # Automatic selection for unknown/auto modes\n    return _select_best_filter(sig, w)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (91.000)\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _arr(x):\n    return np.asarray(x, float).ravel()\n\ndef _valid(a, w):\n    return w > 0 and a.size >= w\n\ndef adaptive(x, w=20):\n    a = _arr(x)\n    if not _valid(a, w):\n        return np.empty(0, dtype=float)\n    if w == 1:\n        return a.copy()\n    return np.convolve(a, np.ones(w) / w, mode=\"valid\")\n\ndef weighted(x, w=20):\n    a = _arr(x)\n    if not _valid(a, w):\n        return np.empty(0, dtype=float)\n    wts = np.exp(np.linspace(-2, 0, w))\n    wts /= wts.sum()\n    return np.convolve(a, wts, mode=\"valid\")\n\ndef _auto(sig, w):\n    a = _arr(sig)\n    return weighted if np.var(a) > 1 else adaptive\n\ndef process_signal(sig, w=20, alg=\"enhanced\"):\n    key = str(alg).lower()\n    if key == \"auto\":\n        return _auto(sig, w)(sig, w)\n    if key in (\"adaptive\", \"enhanced\"):\n        return adaptive(sig, w)\n    if key == \"weighted\":\n        return weighted(sig, w)\n    raise ValueError(f\"Unsupported algorithm_type: {alg}\")\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\n\n# Task\nImprove the code to maximize FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\n\n## CRITICAL INSTRUCTIONS\nIf the code contains `# EVOLVE-BLOCK-START` and `# EVOLVE-BLOCK-END` markers:\n- Output ONLY the code that goes BETWEEN these markers\n- Do NOT include the markers themselves\n- Do NOT include code outside the markers (like `run_packing()`)\n- The system will automatically merge your output with the preserved sections\n\nIf there are NO EVOLVE-BLOCK markers:\n- Output the complete rewritten program\n\n```python\n# Your improved code here (ONLY the evolve block content if markers exist)\n```", "responses": ["import numpy as np\nfrom functools import lru_cache\nimport time\n\ndef _arr(x):\n    \"\"\"Convert input to a 1\u2011D float NumPy array.\"\"\"\n    return np.asarray(x, float).ravel()\n\ndef _valid(a, w):\n    \"\"\"Check that window size is positive and fits the array.\"\"\"\n    return w > 0 and a.size >= w\n\n@lru_cache(maxsize=None)\ndef _exp_weights(w):\n    \"\"\"Cached exponential weights that sum to 1.\"\"\"\n    w = int(w)\n    wts = np.exp(np.linspace(-2, 0, w))\n    return wts / wts.sum()\n\ndef adaptive(x, w=20):\n    \"\"\"Simple moving\u2011average filter.\"\"\"\n    a = _arr(x)\n    if not _valid(a, w):\n        return np.empty(0, dtype=float)\n    if w == 1:\n        return a.copy()\n    return np.convolve(a, np.ones(w) / w, mode=\"valid\")\n\ndef weighted(x, w=20):\n    \"\"\"Exponential\u2011weighted moving average.\"\"\"\n    a = _arr(x)\n    if not _valid(a, w):\n        return np.empty(0, dtype=float)\n    if w == 1:\n        return a.copy()\n    return np.convolve(a, _exp_weights(w), mode=\"valid\")\n\ndef _residual_variance(orig, filt):\n    \"\"\"Variance of the residual (orig \u2013 filt) over the overlapping region.\"\"\"\n    n = min(len(orig), len(filt))\n    if n == 0:\n        return np.inf\n    return float(np.var(orig[:n] - filt[:n]))\n\ndef _auto_select(sig, w):\n    \"\"\"Choose the better filter based on residual variance.\"\"\"\n    candidates = {\n        \"adaptive\": adaptive(sig, w),\n        \"weighted\": weighted(sig, w),\n    }\n    # Discard empty results\n    candidates = {k: v for k, v in candidates.items() if v.size}\n    if not candidates:\n        return np.empty(0, dtype=float)\n    # Deterministic tie\u2011breaker: smallest residual, then alphabetical key\n    best_key = min(\n        candidates,\n        key=lambda k: (_residual_variance(_arr(sig), candidates[k]), k),\n    )\n    return candidates[best_key]\n\ndef process_signal(sig, w=20, alg=\"enhanced\", **kwargs):\n    \"\"\"\n    Dispatch to the requested filtering algorithm.\n\n    Supported ``alg`` values (case\u2011insensitive):\n        - \"adaptive\" / \"enhanced\"\n        - \"weighted\"\n        - \"auto\"\n\n    Optional ``debug`` flag adds simple timing info to the result (if possible).\n    \"\"\"\n    key = str(alg).lower()\n    if key == \"auto\":\n        result = _auto_select(sig, w)\n    elif key in (\"adaptive\", \"enhanced\"):\n        result = adaptive(sig, w)\n    elif key == \"weighted\":\n        result = weighted(sig, w)\n    else:\n        raise ValueError(f\"Unsupported algorithm_type: {alg}\")\n\n    if kwargs.get(\"debug\"):\n        info = {\"algorithm\": key, \"window\": w}\n        start = time.perf_counter()\n        _ = result  # force evaluation\n        info[\"elapsed\"] = time.perf_counter() - start\n        try:\n            result.debug = info  # attach attribute when possible\n        except Exception:\n            pass\n\n    return result"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}