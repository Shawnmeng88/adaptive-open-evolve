{"id": "ca7f7136-5d12-471c-9d86-0f44856924ae", "code": "# EVOLVE-BLOCK-START\nimport numpy as np\n\n_kcache = {}\n\ndef _as_arr(x, w):\n    a = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window_size must be positive\")\n    if a.ndim != 1:\n        raise ValueError(\"input must be 1\u2011D\")\n    if a.size < w:\n        raise ValueError(f\"input length ({a.size}) < window_size ({w})\")\n    return a\n\ndef _kernel(w):\n    k = _kcache.get(w)\n    if k is None:\n        idx = np.arange(w)\n        exp = np.exp(-0.6 * (w - 1 - idx))\n        sigma = max(w / 6.0, 1e-8)\n        mid = (w - 1) / 2.0\n        gauss = np.exp(-0.5 * ((idx - mid) / sigma) ** 2)\n        k = exp * gauss\n        k /= k.sum()\n        _kcache[w] = k\n    return k\n\ndef process_signal(sig, w=20, alg=\"enhanced\"):\n    a = _as_arr(sig, w)\n    if w == 1:\n        return a.copy()\n    if alg.lower() == \"adaptive\":\n        return np.convolve(a, np.ones(w) / w, mode=\"valid\")\n    return np.convolve(a, _kernel(w)[::-1], mode=\"valid\")\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n", "language": "python", "parent_id": "4bee2614-07c8-47bc-88db-afa3521d80f3", "generation": 4, "timestamp": 1764936967.082117, "iteration_found": 64, "metrics": {"runs_successfully": 1.0, "composite_score": 0.4513180918885123, "output_length": 91.0, "overall_score": 0.4137039896180448, "slope_changes": 48.8, "lag_error": 0.9247792418778291, "avg_error": 1.361234553008599, "false_reversals": 41.0, "correlation": 0.37518608989459457, "noise_reduction": 0.0, "smoothness_score": 0.29069767441860467, "responsiveness_score": 0.519540100102281, "accuracy_score": 0.37518608989459457, "efficiency_score": 1.0, "execution_time": 0.0005463123321533203, "success_rate": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Evolve block rewrite (preserved external code)", "parent_metrics": {"runs_successfully": 1.0, "composite_score": 0.4513180918885123, "output_length": 91.0, "overall_score": 0.4137039896180448, "slope_changes": 48.8, "lag_error": 0.9247792418778291, "avg_error": 1.361234553008599, "false_reversals": 41.0, "correlation": 0.37518608989459457, "noise_reduction": 0.0, "smoothness_score": 0.29069767441860467, "responsiveness_score": 0.519540100102281, "accuracy_score": 0.37518608989459457, "efficiency_score": 1.0, "execution_time": 0.0003424167633056641, "success_rate": 1.0}, "island": 0}, "prompts": {"full_rewrite_user": {"system": "## CRITICAL FORMAT REQUIREMENTS (DO NOT VIOLATE)\n## OUTPUT FORMAT (CRITICAL)\n- Output ONLY the code that goes BETWEEN the `# EVOLVE-BLOCK-START` and `# EVOLVE-BLOCK-END` markers\n- Do NOT include the markers themselves in your output\n- Do NOT include any code outside the markers (imports, run_packing, etc.)\n- The system will automatically merge your output with the preserved code sections\n\n## FOCUS\n- Improve ONLY the `construct_packing()` function and helper functions within the evolve block\n- Functions like `run_packing()` are preserved automatically - do not include them\n\nViolating these requirements will cause the program to fail evaluation.\n\n---\n\nYou are a code\u2011generation assistant tasked with evolving the `construct_packing()` function (and any helper functions defined inside the evolve block). Follow **exactly** the rules below; any deviation will cause the program to be rejected.\n\n---\n\n### \ud83d\udccb OUTPUT REQUIREMENTS (CRITICAL)\n\n- **Only** output the Python code that belongs **between** the markers `# EVOLVE-BLOCK-START` and `# EVOLVE-BLOCK-END`.\n- **Do not** include the markers themselves.\n- **Do not** output any other code (imports, `run_packing()`, comments outside the block, etc.). The surrounding file is merged automatically.\n\nIf you violate any of these constraints, the submission will be marked invalid.\n\n---\n\n### \ud83d\udeab WHAT TO AVOID (based on previous failures)\n\n- Do **not** produce a solution that relies on undefined variables or external libraries not already imported in the surrounding file.\n- Do **not** leave placeholder code (`pass`, `TODO`, `...`) or raise `NotImplementedError`.\n- Do **not** generate code that will cause a runtime error for typical inputs (e.g., division by zero, index out of range, infinite recursion).\n- Do **not** use overly aggressive heuristics that ignore edge\u2011case handling (empty item list, zero capacity, duplicate items, etc.).\n- Do **not** repeat the same logic that previously resulted in invalid programs (e.g., a single\u2011pass greedy that never backtracks when a better packing exists).\n\n---\n\n### \ud83c\udfaf GOAL OF `construct_packing()`\n\nCreate a packing plan that maps each item (identified by its index in the provided `items` list) to a container such that:\n\n1. **Capacity constraints** are never exceeded.\n2. **All items** are assigned to **exactly one** container if possible; if not, return a best\u2011effort packing.\n3. The function returns a dictionary `{container_id: [item_indices]}`.\n\nThe surrounding code expects this function to be deterministic, fast for modest input sizes (\u2264\u202f200 items, \u2264\u202f20 containers), and robust to edge cases.\n\n---\n\n### \ud83d\udee0\ufe0f SPECIFIC STRATEGIES TO TRY\n\n1. **Pre\u2011process & sort**  \n   - Sort items by descending weight (or volume) to place the largest items first.  \n   - Optionally sort containers by remaining capacity to fill tighter spaces early.\n\n2. **Greedy with fallback**  \n   - Attempt to place each item in the first container that fits.  \n   - If an item cannot fit in any container, collect it in a `unplaced` list and later try a **second pass** using a simple back\u2011track: remove the smallest already\u2011placed item from a container and try to swap it with the unplaced one.\n\n3. **Simple backtracking (depth\u2011limited)**  \n   - Limit recursion depth to avoid exponential blow\u2011up (e.g., max 3 swaps).  \n   - Use memoization of container states (`frozenset` of remaining capacities) to prune duplicate branches.\n\n4. **Bin\u2011completion heuristic**  \n   - After the greedy pass, iterate over containers and try to \u201cfill gaps\u201d by packing any remaining items that fit into the leftover capacity.\n\n5. **Edge\u2011case handling**  \n   - If `items` is empty \u2192 return `{}`.  \n   - If all container capacities are zero \u2192 return `{}` (nothing can be placed).  \n   - Validate that every item weight \u2264 max(container capacities); otherwise, place those items in a special `unplaced` bucket that the caller can ignore.\n\n6. **Return format**  \n   - Build the result as `{cid: [idx1, idx2, \u2026]}` where `cid` matches the identifier used by the surrounding code (typically the index of the container in the `containers` list).  \n   - Do **not** include empty container entries unless the surrounding logic explicitly expects them.\n\n---\n\n### \ud83d\udccc IMPLEMENTATION TIPS\n\n- Use local helper functions inside the evolve block (e.g., `_can_place(item_weight, container_id, state)`).\n- Keep the algorithm **iterative** where possible; only use recursion for the limited back\u2011track described above.\n- Maintain a clear variable naming convention to avoid shadowing outer\u2011scope names.\n- Add **inline comments** *inside* the block to explain non\u2011obvious steps; they are allowed because they stay within the markers.\n- Ensure the final dictionary is **fully populated** before returning; do not return a partially built structure inadvertently.\n\n---\n\n### \u2705 FINAL CHECK BEFORE SUBMITTING\n\n- [ ] Code is **only** the body between the markers (no markers, no extra imports).  \n- [ ] No `pass`, `TODO`, or `NotImplementedError`.  \n- [ ] All variables used are defined within the block or passed as parameters.  \n- [ ] The function respects capacity limits and returns the required dictionary format.  \n- [ ] Edge cases are explicitly handled.\n\nProceed to write the improved `construct_packing()` implementation adhering to all the constraints above.", "user": "# Current Program Information\n- Fitness: 11.7820\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness declined: 13.7277 \u2192 11.7820. Consider revising recent changes.\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4200, output_length: 91.0000, overall_score: 0.3899, slope_changes: 66.0000, lag_error: 0.8697, avg_error: 1.2418, false_reversals: 55.2000, correlation: 0.3768, noise_reduction: 0.0000, smoothness_score: 0.2326, responsiveness_score: 0.5349, accuracy_score: 0.3768, efficiency_score: 1.0000, execution_time: 0.0006, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4200, output_length: 91.0000, overall_score: 0.3899, slope_changes: 66.0000, lag_error: 0.8697, avg_error: 1.2418, false_reversals: 55.2000, correlation: 0.3768, noise_reduction: 0.0000, smoothness_score: 0.2326, responsiveness_score: 0.5349, accuracy_score: 0.3768, efficiency_score: 1.0000, execution_time: 0.0006, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Unknown changes\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4200, output_length: 91.0000, overall_score: 0.3899, slope_changes: 66.0000, lag_error: 0.8697, avg_error: 1.2418, false_reversals: 55.2000, correlation: 0.3768, noise_reduction: 0.0000, smoothness_score: 0.2326, responsiveness_score: 0.5349, accuracy_score: 0.3768, efficiency_score: 1.0000, execution_time: 0.0018, success_rate: 1.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 13.7278)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nReal-Time Adaptive Signal Processing Algorithm for Non-Stationary Time Series\n\nThis algorithm implements a sliding window approach to filter volatile, non-stationary\ntime series data while minimizing noise and preserving signal dynamics.\n\"\"\"\nimport numpy as np\nfrom scipy import signal\nfrom collections import deque\n\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"\n    Adaptive signal processing algorithm using sliding window approach.\n\n    Args:\n        x: Input signal (1D array of real-valued samples)\n        window_size: Size of the sliding window (W samples)\n\n    Returns:\n        y: Filtered output signal with length = len(x) - window_size + 1\n    \"\"\"\n    if len(x) < window_size:\n        raise ValueError(f\"Input signal length ({len(x)}) must be >= window_size ({window_size})\")\n\n    # Initialize output array\n    output_length = len(x) - window_size + 1\n    y = np.zeros(output_length)\n\n    # Simple moving average as baseline\n    for i in range(output_length):\n        window = x[i : i + window_size]\n\n        # Basic moving average filter\n        y[i] = np.mean(window)\n\n    return y\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"\n    Enhanced version with trend preservation using weighted moving average.\n\n    Args:\n        x: Input signal (1D array of real-valued samples)\n        window_size: Size of the sliding window\n\n    Returns:\n        y: Filtered output signal\n    \"\"\"\n    if len(x) < window_size:\n        raise ValueError(f\"Input signal length ({len(x)}) must be >= window_size ({window_size})\")\n\n    output_length = len(x) - window_size + 1\n    y = np.zeros(output_length)\n\n    # Create weights that emphasize recent samples\n    weights = np.exp(np.linspace(-2, 0, window_size))\n    weights = weights / np.sum(weights)\n\n    for i in range(output_length):\n        window = x[i : i + window_size]\n\n        # Weighted moving average with exponential weights\n        y[i] = np.sum(window * weights)\n\n    return y\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Main signal processing function that applies the selected algorithm.\n\n    Args:\n        input_signal: Input time series data\n        window_size: Window size for processing\n        algorithm_type: Type of algorithm to use (\"basic\" or \"enhanced\")\n\n    Returns:\n        Filtered signal\n    \"\"\"\n    if algorithm_type == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    else:\n        return adaptive_filter(input_signal, window_size)\n\n\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4200), Performs well on output_length (91.0000), Performs well on overall_score (0.3899), Performs well on slope_changes (66.0000), Performs well on lag_error (0.8697), Performs well on avg_error (1.2418), Performs well on false_reversals (55.2000), Performs well on correlation (0.3768), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.2326), Performs well on responsiveness_score (0.5349), Performs well on accuracy_score (0.3768), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0018), Performs well on success_rate (1.0000)\n\n### Program 2 (Score: 13.7277)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"\n    Simple moving average filter using convolution.\n\n    Args:\n        x: 1\u2011D array\u2011like input signal.\n        window_size: Size of the sliding window.\n\n    Returns:\n        Filtered signal (valid convolution, length = len(x) - window_size + 1).\n    \"\"\"\n    if len(x) < window_size:\n        raise ValueError(f\"Input length ({len(x)}) < window_size ({window_size})\")\n    kernel = np.full(window_size, 1.0 / window_size, dtype=float)\n    return np.convolve(x, kernel, mode=\"valid\")\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"\n    Exponential\u2011weighted moving average that emphasizes recent samples.\n\n    The weight vector is reversed before convolution because `np.convolve`\n    flips the second argument.\n\n    Args:\n        x: 1\u2011D array\u2011like input signal.\n        window_size: Size of the sliding window.\n\n    Returns:\n        Filtered signal (valid convolution).\n    \"\"\"\n    if len(x) < window_size:\n        raise ValueError(f\"Input length ({len(x)}) < window_size ({window_size})\")\n    w = np.exp(np.linspace(-2, 0, window_size))\n    w /= w.sum()\n    return np.convolve(x, w[::-1], mode=\"valid\")\n\n\ndef median_filter(x, window_size=20):\n    \"\"\"\n    Median filter that reduces impulsive noise while preserving edges.\n\n    Args:\n        x: 1\u2011D array\u2011like input signal.\n        window_size: Size of the sliding window (must be odd for a true median).\n\n    Returns:\n        Filtered signal (valid window, length = len(x) - window_size + 1).\n    \"\"\"\n    if len(x) < window_size:\n        raise ValueError(f\"Input length ({len(x)}) < window_size ({window_size})\")\n    # Ensure integer window size\n    w = int(window_size)\n    # Compute median for each sliding window\n    med = [np.median(x[i : i + w]) for i in range(len(x) - w + 1)]\n    return np.asarray(med, dtype=float)\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Dispatch to the selected filter.\n\n    Supported algorithm_type values:\n        - \"enhanced\": exponential\u2011weighted moving average (default)\n        - \"adaptive\": simple moving average\n        - \"median\"  : median filter\n\n    Args:\n        input_signal: 1\u2011D array\u2011like signal to be filtered.\n        window_size: Size of the sliding window.\n        algorithm_type: Identifier of the filtering algorithm.\n\n    Returns:\n        Filtered signal as a NumPy array.\n    \"\"\"\n    algo = algorithm_type.lower()\n    if algo == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    if algo == \"adaptive\":\n        return adaptive_filter(input_signal, window_size)\n    if algo == \"median\":\n        return median_filter(input_signal, window_size)\n    raise ValueError(f\"Unsupported algorithm_type: {algorithm_type}\")\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4200), Performs well on output_length (91.0000), Performs well on overall_score (0.3899), Performs well on slope_changes (66.0000), Performs well on lag_error (0.8697), Performs well on avg_error (1.2418), Performs well on false_reversals (55.2000), Performs well on correlation (0.3768), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.2326), Performs well on responsiveness_score (0.5349), Performs well on accuracy_score (0.3768), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0006), Performs well on success_rate (1.0000)\n\n### Program 3 (Score: 13.7277)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nCompact adaptive signal processing.\n\"\"\"\nimport numpy as np\n\ndef process_signal(sig, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Filter `sig` with either an exponential\u2011weighted (enhanced) or simple\n    moving\u2011average (adaptive) filter.\n\n    Returns a NumPy array of length len(sig) - window_size + 1.\n    \"\"\"\n    a = np.asarray(sig, dtype=float).ravel()\n    if window_size <= 0:\n        raise ValueError(\"window_size must be positive\")\n    if a.size < window_size:\n        raise ValueError(f\"Input length ({a.size}) < window_size ({window_size})\")\n    if algorithm_type.lower() == \"enhanced\":\n        w = np.exp(np.linspace(-2, 0, window_size))\n        w /= w.sum()\n        return np.convolve(a, w[::-1], mode=\"valid\")\n    # adaptive (simple moving average)\n    return np.convolve(a, np.ones(window_size) / window_size, mode=\"valid\")\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4200), Performs well on output_length (91.0000), Performs well on overall_score (0.3899), Performs well on slope_changes (66.0000), Performs well on lag_error (0.8697), Performs well on avg_error (1.2418), Performs well on false_reversals (55.2000), Performs well on correlation (0.3768), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.2326), Performs well on responsiveness_score (0.5349), Performs well on accuracy_score (0.3768), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0006), Performs well on success_rate (1.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 13.7277)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nEfficient sliding\u2011window filters using NumPy convolution.\n\"\"\"\nimport numpy as np\n\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"\n    Simple moving average via convolution.\n    \"\"\"\n    if len(x) < window_size:\n        raise ValueError(f\"Input length ({len(x)}) < window_size ({window_size})\")\n    kernel = np.full(window_size, 1.0 / window_size, dtype=float)\n    return np.convolve(x, kernel, mode=\"valid\")\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"\n    Exponential\u2011weighted moving average preserving recent trends.\n    \"\"\"\n    if len(x) < window_size:\n        raise ValueError(f\"Input length ({len(x)}) < window_size ({window_size})\")\n    w = np.exp(np.linspace(-2, 0, window_size))\n    w /= w.sum()\n    # reverse weights because np.convolve flips the second argument\n    return np.convolve(x, w[::-1], mode=\"valid\")\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Dispatch to the chosen filter.\n    \"\"\"\n    return (\n        enhanced_filter_with_trend_preservation(input_signal, window_size)\n        if algorithm_type == \"enhanced\"\n        else adaptive_filter(input_signal, window_size)\n    )\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to composite_score\n\n### Program D2 (Score: 13.7277)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _check_window(x, w):\n    \"\"\"Validate input length and window size, return float array.\"\"\"\n    if w <= 0:\n        raise ValueError(\"window_size must be positive\")\n    a = np.asarray(x, dtype=float)\n    if a.size < w:\n        raise ValueError(f\"Input length ({a.size}) < window_size ({w})\")\n    return a\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Simple moving\u2011average filter.\"\"\"\n    a = _check_window(x, window_size)\n    return np.convolve(a, np.ones(window_size) / window_size, mode=\"valid\")\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"Exponential\u2011weighted moving average, recent samples weighted more.\"\"\"\n    a = _check_window(x, window_size)\n    w = np.exp(np.linspace(-2, 0, window_size))\n    w /= w.sum()\n    return np.convolve(a, w[::-1], mode=\"valid\")  # reverse for right\u2011bias\n\ndef median_filter(x, window_size=21):\n    \"\"\"Median filter (odd window).\"\"\"\n    if window_size % 2 == 0:\n        window_size += 1\n    a = _check_window(x, window_size)\n    shape = (a.size - window_size + 1, window_size)\n    strides = (a.strides[0], a.strides[0])\n    windows = np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n    return np.median(windows, axis=1)\n\ndef hybrid_filter(x, window_size=20):\n    \"\"\"Adaptive filter followed by the enhanced filter.\"\"\"\n    return enhanced_filter_with_trend_preservation(adaptive_filter(x, window_size), window_size)\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"Dispatch to the selected filtering algorithm.\"\"\"\n    algo = algorithm_type.lower()\n    if algo == \"adaptive\":\n        return adaptive_filter(input_signal, window_size)\n    if algo == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    if algo == \"median\":\n        return median_filter(input_signal, window_size)\n    if algo == \"hybrid\":\n        return hybrid_filter(input_signal, window_size)\n    raise ValueError(f\"Unsupported algorithm_type: {algorithm_type}\")\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to composite_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 12.0357, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\n\n@lru_cache(maxsize=None)\ndef _gaussian_kernel(window_size: int) -> np.ndarray:\n    \"\"\"Symmetric Gaussian kernel that sums to 1.\"\"\"\n    mid = (window_size - 1) / 2.0\n    sigma = window_size / 6.0\n    idx = np.arange(window_size)\n    g = np.exp(-0.5 * ((idx - mid) / sigma) ** 2)\n    return g / g.sum()\n\n\n@lru_cache(maxsize=None)\ndef _exponential_kernel(window_size: int, alpha: float = 0.6) -> np.ndarray:\n    \"\"\"Right\u2011biased exponential kernel (more weight on recent samples).\"\"\"\n    idx = np.arange(window_size)\n    e = np.exp(-alpha * (window_size - 1 - idx))\n    return e / e.sum()\n\n\n@lru_cache(maxsize=None)\ndef _combined_kernel(window_size: int) -> np.ndarray:\n    \"\"\"Product of Gaussian and exponential kernels, re\u2011normalised.\"\"\"\n    g = _gaussian_kernel(window_size)\n    e = _exponential_kernel(window_size)\n    c = g * e\n    return c / c.sum()\n\n\ndef _validate_signal(x, window_size: int) -> np.ndarray:\n    \"\"\"Convert to 1\u2011D float array and check feasibility.\"\"\"\n    arr = np.asarray(x, dtype=float)\n    if window_size <= 0:\n        raise ValueError(f\"window_size must be positive, got {window_size}\")\n    if arr.ndim != 1:\n        raise ValueError(\"input signal must be one\u2011dimensional\")\n    if arr.size < window_size:\n        raise ValueError(f\"Input length ({arr.size}) < window_size ({window_size})\")\n    return arr\n\n\ndef adaptive_filter(x, window_size: int = 20) -> np.ndarray:\n    \"\"\"Uniform moving\u2011average filter.\"\"\"\n    arr = _validate_signal(x, window_size)\n    if window_size == 1:\n        return arr.copy()\n    kernel = np.ones(window_size) / window_size\n    return np.convolve(arr, kernel, mode=\"valid\")\n\n\ndef gaussian_filter(x, window_size: int = 20) -> np.ndarray:\n    \"\"\"Gaussian\u2011weighted moving average.\"\"\"\n    arr = _validate_signal(x, window_size)\n    if window_size == 1:\n        return arr.copy()\n    return np.convolve(arr, _gaussian_kernel(window_size), mode=\"valid\")\n\n\ndef exponential_filter(x, window_size: int = 20) -> np.ndarray:\n    \"\"\"Exponential\u2011weighted moving average (recent samples emphasized).\"\"\"\n    arr = _validate_signal(x, window_size)\n    if window_size == 1:\n        return arr.copy()\n    return np.convolve(arr, _exponential_kernel(window_size), mode=\"valid\")\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size: int = 20) -> np.ndarray:\n    \"\"\"Combined Gaussian\u2011exponential kernel to preserve short\u2011term trends.\"\"\"\n    arr = _validate_signal(x, window_size)\n    if window_size == 1:\n        return arr.copy()\n    return np.convolve(arr, _combined_kernel(window_size), mode=\"valid\")\n\n\ndef median_filter(x, window_size: int = 20) -> np.ndarray:\n    \"\"\"Median filter using a sliding\u2011window view (valid output).\"\"\"\n    arr = _validate_signal(x, window_size)\n    if window_size == 1:\n        return arr.copy()\n    shape = (arr.size - window_size + 1, window_size)\n    strides = (arr.strides[0], arr.strides[0])\n    windows = np.lib.stride_tricks.as_strided(arr, shape=shape, strides=strides)\n    return np.median(windows, axis=1)\n\n\ndef process_signal(input_signal, window_size: int = 20, algorithm_type: str = \"enhanced\") -> np.ndarray:\n    \"\"\"Dispatch to the requested filtering algorithm.\"\"\"\n    algo = algorithm_type.lower()\n    if algo == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    if algo == \"adaptive\":\n        return adaptive_filter(input_signal, window_size)\n    if algo == \"gaussian\":\n        return gaussian_filter(input_signal, window_size)\n    if algo == \"exponential\":\n        return exponential_filter(input_signal, window_size)\n    if algo == \"median\":\n        return median_filter(input_signal, window_size)\n    raise ValueError(f\"Unsupported algorithm_type: {algorithm_type}\")\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (91.000)\n\n### Inspiration 2 (Score: 13.7278, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nReal-Time Adaptive Signal Processing Algorithm for Non-Stationary Time Series\n\nThis algorithm implements a sliding window approach to filter volatile, non-stationary\ntime series data while minimizing noise and preserving signal dynamics.\n\"\"\"\nimport numpy as np\nfrom scipy import signal\nfrom collections import deque\n\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"\n    Adaptive signal processing algorithm using sliding window approach.\n\n    Args:\n        x: Input signal (1D array of real-valued samples)\n        window_size: Size of the sliding window (W samples)\n\n    Returns:\n        y: Filtered output signal with length = len(x) - window_size + 1\n    \"\"\"\n    if len(x) < window_size:\n        raise ValueError(f\"Input signal length ({len(x)}) must be >= window_size ({window_size})\")\n\n    # Initialize output array\n    output_length = len(x) - window_size + 1\n    y = np.zeros(output_length)\n\n    # Simple moving average as baseline\n    for i in range(output_length):\n        window = x[i : i + window_size]\n\n        # Basic moving average filter\n        y[i] = np.mean(window)\n\n    return y\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"\n    Enhanced version with trend preservation using weighted moving average.\n\n    Args:\n        x: Input signal (1D array of real-valued samples)\n        window_size: Size of the sliding window\n\n    Returns:\n        y: Filtered output signal\n    \"\"\"\n    if len(x) < window_size:\n        raise ValueError(f\"Input signal length ({len(x)}) must be >= window_size ({window_size})\")\n\n    output_length = len(x) - window_size + 1\n    y = np.zeros(output_length)\n\n    # Create weights that emphasize recent samples\n    weights = np.exp(np.linspace(-2, 0, window_size))\n    weights = weights / np.sum(weights)\n\n    for i in range(output_length):\n        window = x[i : i + window_size]\n\n        # Weighted moving average with exponential weights\n        y[i] = np.sum(window * weights)\n\n    return y\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Main signal processing function that applies the selected algorithm.\n\n    Args:\n        input_signal: Input time series data\n        window_size: Window size for processing\n        algorithm_type: Type of algorithm to use (\"basic\" or \"enhanced\")\n\n    Returns:\n        Filtered signal\n    \"\"\"\n    if algorithm_type == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    else:\n        return adaptive_filter(input_signal, window_size)\n\n\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Excellent runs_successfully (1.000), Excellent output_length (91.000), Excellent slope_changes (66.000)\n\n### Inspiration 3 (Score: 13.7277, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _prepare_signal(x, window_size, *, require_odd=False):\n    \"\"\"Validate and convert input to a 1\u2011D float array.\"\"\"\n    arr = np.asarray(x, dtype=float)\n    if arr.ndim != 1:\n        raise ValueError(\"input signal must be one\u2011dimensional\")\n    if window_size <= 0:\n        raise ValueError(\"window_size must be positive\")\n    if require_odd and window_size % 2 == 0:\n        raise ValueError(\"window_size must be odd for this filter\")\n    if arr.size < window_size:\n        raise ValueError(f\"input length ({arr.size}) < window_size ({window_size})\")\n    return arr\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Simple moving\u2011average filter.\"\"\"\n    arr = _prepare_signal(x, window_size)\n    return np.convolve(arr, np.ones(window_size) / window_size, mode=\"valid\")\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"Exponential\u2011weighted moving average (recent samples weighted more).\"\"\"\n    arr = _prepare_signal(x, window_size)\n    w = np.exp(np.linspace(-2, 0, window_size))\n    w /= w.sum()\n    return np.convolve(arr, w[::-1], mode=\"valid\")  # reverse for right\u2011bias\n\ndef median_filter(x, window_size=21):\n    \"\"\"Median filter; window_size must be odd.\"\"\"\n    arr = _prepare_signal(x, window_size, require_odd=True)\n    shape = (arr.size - window_size + 1, window_size)\n    strides = (arr.strides[0], arr.strides[0])\n    windows = np.lib.stride_tricks.as_strided(arr, shape=shape, strides=strides)\n    return np.median(windows, axis=1)\n\ndef _hybrid_filter(x, window_size):\n    \"\"\"Apply adaptive filter then enhanced filter on the result.\"\"\"\n    interim = adaptive_filter(x, window_size)\n    return enhanced_filter_with_trend_preservation(interim, window_size)\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"Dispatch to the selected filtering algorithm.\"\"\"\n    algo = algorithm_type.lower()\n    dispatch = {\n        \"enhanced\": enhanced_filter_with_trend_preservation,\n        \"adaptive\": adaptive_filter,\n        \"median\": median_filter,\n        \"hybrid\": _hybrid_filter,\n    }\n    if algo not in dispatch:\n        raise ValueError(f\"Unsupported algorithm_type: {algorithm_type}\")\n    return dispatch[algo](input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (91.000)\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _as_array(x, w):\n    a = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window_size must be positive\")\n    if a.ndim != 1:\n        raise ValueError(\"input must be 1\u2011D\")\n    if a.size < w:\n        raise ValueError(f\"input length ({a.size}) < window_size ({w})\")\n    return a\n\ndef adaptive(x, w=20):\n    a = _as_array(x, w)\n    if w == 1:\n        return a.copy()\n    return np.convolve(a, np.ones(w) / w, mode=\"valid\")\n\ndef enhanced(x, w=20):\n    a = _as_array(x, w)\n    if w == 1:\n        return a.copy()\n    idx = np.arange(w)\n    exp = np.exp(-0.6 * (w - 1 - idx))\n    mid = (w - 1) / 2.0\n    sigma = max(w / 6.0, 1e-8)\n    gauss = np.exp(-0.5 * ((idx - mid) / sigma) ** 2)\n    k = exp * gauss\n    k /= k.sum()\n    return np.convolve(a, k[::-1], mode=\"valid\")\n\ndef process_signal(sig, w=20, alg=\"enhanced\"):\n    a = alg.lower()\n    if a == \"adaptive\":\n        return adaptive(sig, w)\n    return enhanced(sig, w)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\n\n# Task\nImprove the code to maximize FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\n\n## CRITICAL INSTRUCTIONS\nIf the code contains `# EVOLVE-BLOCK-START` and `# EVOLVE-BLOCK-END` markers:\n- Output ONLY the code that goes BETWEEN these markers\n- Do NOT include the markers themselves\n- Do NOT include code outside the markers (like `run_packing()`)\n- The system will automatically merge your output with the preserved sections\n\nIf there are NO EVOLVE-BLOCK markers:\n- Output the complete rewritten program\n\n```python\n# Your improved code here (ONLY the evolve block content if markers exist)\n```", "responses": ["import numpy as np\n\n_kcache = {}\n\ndef _as_arr(x, w):\n    a = np.asarray(x, float)\n    if w <= 0:\n        raise ValueError(\"window_size must be positive\")\n    if a.ndim != 1:\n        raise ValueError(\"input must be 1\u2011D\")\n    if a.size < w:\n        raise ValueError(f\"input length ({a.size}) < window_size ({w})\")\n    return a\n\ndef _kernel(w):\n    k = _kcache.get(w)\n    if k is None:\n        idx = np.arange(w)\n        exp = np.exp(-0.6 * (w - 1 - idx))\n        sigma = max(w / 6.0, 1e-8)\n        mid = (w - 1) / 2.0\n        gauss = np.exp(-0.5 * ((idx - mid) / sigma) ** 2)\n        k = exp * gauss\n        k /= k.sum()\n        _kcache[w] = k\n    return k\n\ndef process_signal(sig, w=20, alg=\"enhanced\"):\n    a = _as_arr(sig, w)\n    if w == 1:\n        return a.copy()\n    if alg.lower() == \"adaptive\":\n        return np.convolve(a, np.ones(w) / w, mode=\"valid\")\n    return np.convolve(a, _kernel(w)[::-1], mode=\"valid\")"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}