{"id": "3eb5c709-7186-4f04-b410-42fdaa905c30", "code": "# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\ndef _prepare_input(x, window_size):\n    \"\"\"Validate *window_size* and convert *x* to a 1\u2011D float array.\n\n    Returns a tuple ``(arr, ws)`` where ``ws`` is the validated window size.\n    If the input is shorter than ``ws`` an empty array is returned so callers\n    can handle the situation gracefully.\n    \"\"\"\n    ws = int(window_size)\n    if ws <= 0:\n        raise ValueError(\"window_size must be a positive integer\")\n    arr = np.asarray(x, dtype=float).ravel()\n    if arr.size < ws:\n        return np.empty(0, dtype=float), ws\n    return arr, ws\n\n\n@lru_cache(maxsize=32)\ndef _exp_weights(ws):\n    \"\"\"Pre\u2011compute exponential weights for EWMA.\"\"\"\n    w = np.exp(np.linspace(-2, 0, ws))\n    return w / w.sum()\n\n\ndef _apply_savgol(signal, window_len, polyorder=3):\n    \"\"\"Safely apply Savitzky\u2011Golay filter; fall back to simple MA.\"\"\"\n    if signal.size == 0:\n        return signal\n    try:\n        from scipy.signal import savgol_filter\n    except Exception:\n        # fallback: simple moving average\n        if window_len <= 0:\n            return signal\n        return np.convolve(signal, np.ones(window_len) / window_len, mode=\"valid\")\n\n    w = int(window_len)\n    if w % 2 == 0:\n        w += 1\n    min_len = polyorder + 2\n    if w < min_len:\n        w = min_len + (min_len % 2 == 0)\n    return savgol_filter(signal, window_length=w, polyorder=polyorder, mode='interp')\n\n\ndef _lowpass_filter(signal, cutoff=0.1, order=2):\n    \"\"\"Zero\u2011phase Butterworth low\u2011pass filter; identity fallback if SciPy unavailable.\"\"\"\n    if signal.size == 0:\n        return signal\n    try:\n        from scipy.signal import butter, filtfilt\n    except Exception:\n        return signal\n\n    # Normalized cutoff (Nyquist = 0.5 for unit sampling rate)\n    nyq = 0.5\n    norm_cutoff = min(1.0, max(0.0, cutoff / nyq))\n    b, a = butter(order, norm_cutoff, btype='low', analog=False)\n    return filtfilt(b, a, signal)\n\n\ndef _short_moving_average(signal, length=5):\n    \"\"\"Final short MA to smooth residual high\u2011frequency noise.\"\"\"\n    if signal.size < length or length <= 0:\n        return signal\n    return np.convolve(signal, np.ones(length) / length, mode=\"valid\")\n\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Simple moving\u2011average filter using cumulative sum (valid mode).\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    csum = np.cumsum(np.insert(arr, 0, 0.0))\n    return (csum[ws:] - csum[:-ws]) / ws\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"Multi\u2011stage filter: EWMA \u2192 adaptive Savitzky\u2011Golay \u2192 low\u2011pass \u2192 short MA.\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n\n    # Stage 1: EWMA (valid convolution)\n    ewma = np.convolve(arr, _exp_weights(ws), mode=\"valid\")\n\n    # Stage 2: Adaptive Savitzky\u2011Golay if enough points\n    if ewma.size >= max(5, ws):\n        cv = np.std(ewma) / (np.mean(np.abs(ewma)) + 1e-9)\n        adaptive_win = int(ws * (1.0 - 0.5 * min(max(cv, 0.0), 1.0)))\n        adaptive_win = max(5, adaptive_win)\n        sg = _apply_savgol(ewma, adaptive_win, polyorder=2)\n    else:\n        sg = ewma\n\n    # Stage 3: Low\u2011pass Butterworth (cutoff adapts to window size)\n    cutoff = max(0.02, 0.1 * (ws / 20.0))\n    lowpassed = _lowpass_filter(sg, cutoff=cutoff, order=2)\n\n    # Stage 4: Short moving average to clean residues\n    return _short_moving_average(lowpassed, length=5)\n\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; output aligns with other filters.\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    alpha = 2.0 / (ws + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[ws - 1 :]\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"Dispatch to the selected filtering algorithm (case\u2011insensitive).\"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n    if alg == \"savgol\":\n        arr, ws = _prepare_input(input_signal, window_size)\n        return _apply_savgol(arr, ws, polyorder=3) if arr.size else arr\n    if alg == \"hybrid\":\n        # EWMA followed by exponential smoothing\n        ewma = enhanced_filter_with_trend_preservation(input_signal, window_size)\n        return exponential_smoothing(ewma, window_size)\n    # default / \"enhanced\"\n    return enhanced_filter_with_trend_preservation(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n", "language": "python", "parent_id": "31c36692-fc2d-4265-9abd-834b3061579f", "generation": 6, "timestamp": 1764937704.271847, "iteration_found": 155, "metrics": {"runs_successfully": 1.0, "composite_score": 0.4985495778653399, "output_length": 87.0, "overall_score": 0.42791208051305285, "slope_changes": 38.2, "lag_error": 0.9018035365611491, "avg_error": 1.3223232235214735, "false_reversals": 31.0, "correlation": 0.2988186351507358, "noise_reduction": 0.0, "smoothness_score": 0.3436426116838488, "responsiveness_score": 0.5258166686387623, "accuracy_score": 0.2988186351507358, "efficiency_score": 1.0, "execution_time": 0.0006689548492431641, "success_rate": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Evolve block rewrite (preserved external code)", "parent_metrics": {"runs_successfully": 0.0, "error": "Stage 1 failed: '(' was never closed (tmpvaejwukf.py, line 56)"}, "island": 1}, "prompts": {"full_rewrite_user": {"system": "## CRITICAL FORMAT REQUIREMENTS (DO NOT VIOLATE)\n## OUTPUT FORMAT (CRITICAL)\n- Output ONLY the code that goes BETWEEN the `# EVOLVE-BLOCK-START` and `# EVOLVE-BLOCK-END` markers\n- Do NOT include the markers themselves in your output\n- Do NOT include any code outside the markers (imports, run_packing, etc.)\n- The system will automatically merge your output with the preserved code sections\n\n## FOCUS\n- Improve ONLY the `construct_packing()` function and helper functions within the evolve block\n- Functions like `run_packing()` are preserved automatically - do not include them\n\nViolating these requirements will cause the program to fail evaluation.\n\n---\n\nYou are a code\u2011evolution assistant tasked with improving the `construct_packing()` function and any helper functions that reside inside the **EVOLVE** block. Follow these strict guidelines:\n\n**Output Requirements**\n- **ONLY** output the Python code that belongs **between** the markers `# EVOLVE-BLOCK-START` and `# EVOLVE-BLOCK-END`.\n- Do **NOT** include the markers themselves, any import statements, or any surrounding code (e.g., `run_packing()`). The surrounding scaffolding will be merged automatically.\n\n**Scope**\n- Focus exclusively on `construct_packing()` and any helper functions defined within the EVOLVE block.\n- Do not modify or add code outside this block.\n\n**What NOT to do (avoid past failures)**\n- Do not produce code that does not compile or violates the function signatures.\n- Do not introduce syntax errors, missing parentheses, or undefined variables.\n- Do not leave placeholder `pass` statements or `TODO` comments that leave the logic incomplete.\n- Do not ignore edge\u2011case handling (e.g., empty input, duplicate items, size overflow).\n- Do not write overly aggressive \u201cbrute\u2011force\u201d loops that will exceed time limits.\n\n**Suggested Strategies**\n1. **Greedy Packing**: Sort items by size (or value/size ratio) and place them into the smallest box that can accommodate them. Update box capacities incrementally.\n2. **Best\u2011Fit Decreasing**: After sorting descending, try to fit each item into the box with the least remaining space that still fits the item. This often yields near\u2011optimal results with low complexity.\n3. **Fallback Backtracking**: If greedy placement fails for an item, attempt a limited depth\u2011first backtrack (e.g., try moving the last\u2011placed item to a different box) to resolve dead\u2011ends without exploding combinatorial space.\n4. **Validation Helper**: Implement a small helper `can_place(item, box)` that checks size constraints and returns a boolean. Use it consistently to avoid accidental over\u2011packing.\n5. **State Management**: Keep mutable structures (e.g., `box_remaining = [capacity] * num_boxes`) and update them in\u2011place; copy only when exploring backtrack branches.\n6. **Clear Return**: Ensure `construct_packing()` returns a list of lists, where each inner list contains the indices (or identifiers) of items assigned to that box. Return an empty list or raise a descriptive `ValueError` if packing is impossible.\n\n**Formatting**\n- Write clean, PEP\u20118 compliant code.\n- Include brief inline comments explaining non\u2011obvious steps.\n- Preserve existing function signatures and docstrings.\n\nRemember: **Only the code inside the EVOLVE block should be output, nothing else.**", "user": "# Current Program Information\n- Fitness: 0.0000\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness declined: 13.4402 \u2192 0.0000. Consider revising recent changes.\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4147, output_length: 91.0000, overall_score: 0.3667, slope_changes: 64.2000, lag_error: 1.0255, avg_error: 1.3708, false_reversals: 52.4000, correlation: 0.2667, noise_reduction: 0.0000, smoothness_score: 0.2375, responsiveness_score: 0.4937, accuracy_score: 0.2667, efficiency_score: 1.0000, execution_time: 0.0006, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Evolve block rewrite (preserved external code)\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4147, output_length: 91.0000, overall_score: 0.3667, slope_changes: 64.2000, lag_error: 1.0255, avg_error: 1.3708, false_reversals: 52.4000, correlation: 0.2667, noise_reduction: 0.0000, smoothness_score: 0.2375, responsiveness_score: 0.4937, accuracy_score: 0.2667, efficiency_score: 1.0000, execution_time: 0.0009, success_rate: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Unknown changes\n- Metrics: runs_successfully: 1.0000, composite_score: 0.4200, output_length: 91.0000, overall_score: 0.3899, slope_changes: 66.0000, lag_error: 0.8697, avg_error: 1.2418, false_reversals: 55.2000, correlation: 0.3768, noise_reduction: 0.0000, smoothness_score: 0.2326, responsiveness_score: 0.5349, accuracy_score: 0.3768, efficiency_score: 1.0000, execution_time: 0.0018, success_rate: 1.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 13.7278)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nReal-Time Adaptive Signal Processing Algorithm for Non-Stationary Time Series\n\nThis algorithm implements a sliding window approach to filter volatile, non-stationary\ntime series data while minimizing noise and preserving signal dynamics.\n\"\"\"\nimport numpy as np\nfrom scipy import signal\nfrom collections import deque\n\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"\n    Adaptive signal processing algorithm using sliding window approach.\n\n    Args:\n        x: Input signal (1D array of real-valued samples)\n        window_size: Size of the sliding window (W samples)\n\n    Returns:\n        y: Filtered output signal with length = len(x) - window_size + 1\n    \"\"\"\n    if len(x) < window_size:\n        raise ValueError(f\"Input signal length ({len(x)}) must be >= window_size ({window_size})\")\n\n    # Initialize output array\n    output_length = len(x) - window_size + 1\n    y = np.zeros(output_length)\n\n    # Simple moving average as baseline\n    for i in range(output_length):\n        window = x[i : i + window_size]\n\n        # Basic moving average filter\n        y[i] = np.mean(window)\n\n    return y\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"\n    Enhanced version with trend preservation using weighted moving average.\n\n    Args:\n        x: Input signal (1D array of real-valued samples)\n        window_size: Size of the sliding window\n\n    Returns:\n        y: Filtered output signal\n    \"\"\"\n    if len(x) < window_size:\n        raise ValueError(f\"Input signal length ({len(x)}) must be >= window_size ({window_size})\")\n\n    output_length = len(x) - window_size + 1\n    y = np.zeros(output_length)\n\n    # Create weights that emphasize recent samples\n    weights = np.exp(np.linspace(-2, 0, window_size))\n    weights = weights / np.sum(weights)\n\n    for i in range(output_length):\n        window = x[i : i + window_size]\n\n        # Weighted moving average with exponential weights\n        y[i] = np.sum(window * weights)\n\n    return y\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Main signal processing function that applies the selected algorithm.\n\n    Args:\n        input_signal: Input time series data\n        window_size: Window size for processing\n        algorithm_type: Type of algorithm to use (\"basic\" or \"enhanced\")\n\n    Returns:\n        Filtered signal\n    \"\"\"\n    if algorithm_type == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    else:\n        return adaptive_filter(input_signal, window_size)\n\n\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4200), Performs well on output_length (91.0000), Performs well on overall_score (0.3899), Performs well on slope_changes (66.0000), Performs well on lag_error (0.8697), Performs well on avg_error (1.2418), Performs well on false_reversals (55.2000), Performs well on correlation (0.3768), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.2326), Performs well on responsiveness_score (0.5349), Performs well on accuracy_score (0.3768), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0018), Performs well on success_rate (1.0000)\n\n### Program 2 (Score: 13.4402)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nReal-Time Adaptive Signal Processing Algorithm for Non\u2011Stationary Time Series\n\nProvides several filtering strategies (basic moving\u2011average, weighted EWMA,\nexponential smoothing and optional Savitzky\u2011Golay) with safe fall\u2011backs.\n\"\"\"\nimport numpy as np\nfrom scipy import signal\n\ndef _to_array(x, window):\n    \"\"\"Convert input to 1\u2011D float array and validate length.\"\"\"\n    arr = np.asarray(x, dtype=float)\n    if arr.ndim != 1:\n        raise ValueError(\"Input signal must be 1\u2011D\")\n    if window <= 0:\n        raise ValueError(\"window_size must be positive\")\n    if arr.size < window:\n        # Return empty array \u2013 caller can handle gracefully\n        return np.array([], dtype=float)\n    return arr\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Fast simple moving average using cumulative sum.\"\"\"\n    arr = _to_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    csum = np.cumsum(np.insert(arr, 0, 0.0))\n    return (csum[window_size:] - csum[:-window_size]) / window_size\n\ndef weighted_filter(x, window_size=20):\n    \"\"\"Exponentially weighted moving average (EWMA).\"\"\"\n    arr = _to_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    w = np.exp(np.linspace(-2, 0, window_size))\n    w /= w.sum()\n    return np.convolve(arr, w, mode='valid')\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; output length matches other filters.\"\"\"\n    arr = _to_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    alpha = 2.0 / (window_size + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[window_size - 1 :]\n\ndef _savgol_filter(x, window_size=20, polyorder=3):\n    \"\"\"Savitzky\u2011Golay filter with safe parameter handling.\"\"\"\n    arr = _to_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    # SciPy's savgol_filter may be unavailable; fall back to basic MA\n    if not hasattr(signal, \"savgol_filter\"):\n        return adaptive_filter(arr, window_size)\n    w = int(window_size)\n    if w % 2 == 0:\n        w += 1\n    w = max(w, polyorder + 2)\n    if w % 2 == 0:\n        w += 1\n    return signal.savgol_filter(arr, window_length=w, polyorder=polyorder, mode='interp')\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Dispatch to the selected filtering algorithm.\n\n    algorithm_type options:\n        \"basic\"   \u2013 simple moving average\n        \"enhanced\"\u2013 EWMA (default)\n        \"exp\"     \u2013 exponential smoothing\n        \"savgol\"  \u2013 Savitzky\u2011Golay (fallback to basic)\n        \"hybrid\"  \u2013 EWMA followed by exponential smoothing\n    \"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"enhanced\":\n        return weighted_filter(input_signal, window_size)\n    if alg == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n    if alg == \"savgol\":\n        return _savgol_filter(input_signal, window_size)\n    if alg == \"hybrid\":\n        tmp = weighted_filter(input_signal, window_size)\n        return exponential_smoothing(tmp, window_size)\n    # Default to enhanced for unknown types\n    return weighted_filter(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4147), Performs well on output_length (91.0000), Performs well on overall_score (0.3667), Performs well on slope_changes (64.2000), Performs well on lag_error (1.0255), Performs well on avg_error (1.3708), Performs well on false_reversals (52.4000), Performs well on correlation (0.2667), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.2375), Performs well on responsiveness_score (0.4937), Performs well on accuracy_score (0.2667), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0009), Performs well on success_rate (1.0000)\n\n### Program 3 (Score: 13.4402)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom typing import Any\n\ndef _prepare_input(x: Any, window_size: int):\n    \"\"\"Validate window size and convert input to a 1\u2011D float array.\n\n    Returns a tuple (arr, ws). If the input length is less than the window,\n    ``arr`` will be an empty array, allowing callers to handle it gracefully.\n    \"\"\"\n    if not isinstance(window_size, int) or window_size <= 0:\n        raise ValueError(f\"window_size must be a positive integer, got {window_size}\")\n    ws = int(window_size)\n    arr = np.asarray(x, dtype=float).ravel()\n    if arr.size < ws:\n        return np.empty(0, dtype=float), ws\n    return arr, ws\n\ndef _moving_average(arr: np.ndarray, ws: int) -> np.ndarray:\n    \"\"\"Fast moving\u2011average using cumulative sum.\"\"\"\n    csum = np.cumsum(np.insert(arr, 0, 0.0))\n    return (csum[ws:] - csum[:-ws]) / ws\n\ndef adaptive_filter(x: Any, window_size: int = 20) -> np.ndarray:\n    \"\"\"Simple moving\u2011average filter.\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    return _moving_average(arr, ws)\n\ndef enhanced_filter_with_trend_preservation(x: Any, window_size: int = 20) -> np.ndarray:\n    \"\"\"Exponential\u2011weighted moving\u2011average filter.\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    w = np.exp(np.linspace(-2, 0, ws))\n    w /= w.sum()\n    return np.convolve(arr, w, mode=\"valid\")\n\ndef exponential_smoothing(x: Any, window_size: int = 20) -> np.ndarray:\n    \"\"\"Recursive exponential smoothing; output aligned with other filters.\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    alpha = 2.0 / (ws + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[ws - 1 :]\n\n# Optional Savitzky\u2011Golay filter if SciPy is available\ntry:\n    from scipy.signal import savgol_filter\n    _HAS_SAVGOL = True\nexcept Exception:\n    _HAS_SAVGOL = False\n\ndef _savgol_filter(x: Any, window_size: int = 20, polyorder: int = 3) -> np.ndarray:\n    \"\"\"Savitzky\u2011Golay filter with safe parameter handling.\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    if not _HAS_SAVGOL:\n        return adaptive_filter(arr, ws)\n    w = int(ws)\n    if w % 2 == 0:\n        w += 1\n    if w < polyorder + 2:\n        w = polyorder + 2\n        if w % 2 == 0:\n            w += 1\n    return savgol_filter(arr, window_length=w, polyorder=polyorder, mode=\"interp\")\n\ndef process_signal(\n    input_signal: Any, window_size: int = 20, algorithm_type: str = \"enhanced\"\n) -> np.ndarray:\n    \"\"\"\n    Dispatch to the selected filtering algorithm.\n\n    Supported ``algorithm_type`` values:\n        \"basic\"    \u2013 simple moving average\n        \"enhanced\" \u2013 exponential\u2011weighted moving average\n        \"exp\"      \u2013 exponential smoothing\n        \"savgol\"   \u2013 Savitzky\u2011Golay (fallback to basic)\n        \"hybrid\"   \u2013 weighted filter followed by exponential smoothing\n    \"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    if alg == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n    if alg == \"savgol\":\n        return _savgol_filter(input_signal, window_size)\n    if alg == \"hybrid\":\n        weighted = enhanced_filter_with_trend_preservation(input_signal, window_size)\n        return exponential_smoothing(weighted, window_size)\n    # Fallback to enhanced for unknown types\n    return enhanced_filter_with_trend_preservation(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on composite_score (0.4147), Performs well on output_length (91.0000), Performs well on overall_score (0.3667), Performs well on slope_changes (64.2000), Performs well on lag_error (1.0255), Performs well on avg_error (1.3708), Performs well on false_reversals (52.4000), Performs well on correlation (0.2667), Performs well on noise_reduction (0.0000), Performs well on smoothness_score (0.2375), Performs well on responsiveness_score (0.4937), Performs well on accuracy_score (0.2667), Performs well on efficiency_score (1.0000), Performs well on execution_time (0.0006), Performs well on success_rate (1.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 13.4402)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\ndef _validate_window(window_size: int) -> int:\n    \"\"\"Validate and normalize the window size.\"\"\"\n    if not isinstance(window_size, (int, np.integer)):\n        raise TypeError(f\"window_size must be an integer, got {type(window_size).__name__}\")\n    ws = int(window_size)\n    if ws <= 0:\n        raise ValueError(f\"window_size must be positive, got {ws}\")\n    return ws\n\ndef _to_array(x, window_size):\n    \"\"\"\n    Convert input to a 1\u2011D float array and ensure it meets the window requirement.\n\n    Returns an empty array when the signal is shorter than the window so callers\n    can handle the situation gracefully.\n    \"\"\"\n    ws = _validate_window(window_size)\n    arr = np.asarray(x, dtype=float).ravel()\n    if arr.size < ws:\n        return np.empty(0, dtype=float), ws\n    return arr, ws\n\n@lru_cache(maxsize=32)\ndef _exp_weights(ws: int):\n    \"\"\"Pre\u2011compute exponential weights for a given window size.\"\"\"\n    w = np.exp(np.linspace(-2, 0, ws))\n    return w / w.sum()\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Simple moving\u2011average filter (valid convolution).\"\"\"\n    arr, ws = _to_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    kernel = np.ones(ws, dtype=float) / ws\n    return np.convolve(arr, kernel, mode='valid')\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"Exponentially weighted moving\u2011average filter (valid convolution).\"\"\"\n    arr, ws = _to_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    kernel = _exp_weights(ws)\n    return np.convolve(arr, kernel, mode='valid')\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; output aligned with other filters.\"\"\"\n    arr, ws = _to_array(x, window_size)\n    if arr.size == 0:\n        return arr\n    alpha = 2.0 / (ws + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[ws - 1 :]\n\ndef hybrid_filter(x, window_size=20):\n    \"\"\"\n    Hybrid filter: first apply EWMA, then exponential smoothing.\n    Returns an empty array if the intermediate result is empty.\n    \"\"\"\n    ewma = enhanced_filter_with_trend_preservation(x, window_size)\n    if ewma.size == 0:\n        return ewma\n    return exponential_smoothing(ewma, window_size)\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Dispatch to the selected filtering algorithm.\n\n    Parameters\n    ----------\n    input_signal : array\u2011like\n        Raw time\u2011series data.\n    window_size : int, optional\n        Size of the sliding window (default 20).\n    algorithm_type : str, optional\n        One of ``\"basic\"``, ``\"enhanced\"``, ``\"exp\"``, ``\"hybrid\"`` (case\u2011insensitive).\n\n    Returns\n    -------\n    numpy.ndarray\n        Filtered signal. May be empty if input is shorter than the window.\n    \"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    if alg == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n    if alg == \"hybrid\":\n        return hybrid_filter(input_signal, window_size)\n\n    raise ValueError(\n        f\"Unsupported algorithm_type '{algorithm_type}'. \"\n        \"Supported types are: 'basic', 'enhanced', 'exp', 'hybrid'.\"\n    )\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to composite_score\n\n### Program D2 (Score: 13.4402)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\ndef _prepare_input(x, window):\n    \"\"\"Validate *window* and convert *x* to a 1\u2011D float array.\n\n    Returns an empty array when the signal is shorter than *window* so callers can\n    handle the situation gracefully.\n    \"\"\"\n    ws = int(window)\n    if ws <= 0:\n        raise ValueError(\"window size must be positive\")\n    arr = np.asarray(x, dtype=float).ravel()\n    if arr.size < ws:\n        return np.empty(0, dtype=float), ws\n    return arr, ws\n\n@lru_cache(maxsize=32)\ndef _exp_weights(ws):\n    \"\"\"Pre\u2011compute exponential weights for EWMA.\"\"\"\n    w = np.exp(np.linspace(-2, 0, ws))\n    return w / w.sum()\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Fast simple moving\u2011average using cumulative sum.\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    csum = np.cumsum(np.insert(arr, 0, 0.0))\n    return (csum[ws:] - csum[:-ws]) / ws\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"Exponentially weighted moving\u2011average (valid convolution).\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    kernel = _exp_weights(ws)\n    return np.convolve(arr, kernel, mode='valid')\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; output aligns with other filters.\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    alpha = 2.0 / (ws + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[ws - 1 :]\n\ndef _savgol_filter(x, window_size=20, polyorder=3):\n    \"\"\"Savitzky\u2011Golay filter with safe fallback to basic MA.\"\"\"\n    try:\n        from scipy.signal import savgol_filter\n    except Exception:\n        return adaptive_filter(x, window_size)\n\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n\n    w = int(ws)\n    if w % 2 == 0:\n        w += 1\n    w = max(w, polyorder + 2)\n    if w % 2 == 0:\n        w += 1\n    return savgol_filter(arr, window_length=w, polyorder=polyorder, mode='interp')\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Dispatch to the selected filtering algorithm.\n\n    Supported ``algorithm_type`` values (case\u2011insensitive):\n        \"basic\"   \u2013 simple moving average\n        \"enhanced\"\u2013 EWMA (default)\n        \"exp\"     \u2013 exponential smoothing\n        \"savgol\"  \u2013 Savitzky\u2011Golay (fallback to basic)\n        \"hybrid\"  \u2013 EWMA followed by exponential smoothing\n    \"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    if alg == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n    if alg == \"savgol\":\n        return _savgol_filter(input_signal, window_size)\n    if alg == \"hybrid\":\n        tmp = enhanced_filter_with_trend_preservation(input_signal, window_size)\n        return exponential_smoothing(tmp, window_size)\n\n    # Fallback to enhanced for unknown types\n    return enhanced_filter_with_trend_preservation(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to composite_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 13.4402, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom functools import lru_cache\n\ndef _prepare_input(x, window):\n    \"\"\"Validate input and convert to 1\u2011D float array.\n\n    Returns a tuple ``(arr, ws)`` where ``ws`` is the validated window size.\n    If the input is shorter than ``ws`` an empty array is returned (graceful handling).\"\"\"\n    ws = int(window)\n    if ws <= 0:\n        raise ValueError(\"window size must be a positive integer\")\n    arr = np.asarray(x, dtype=float).ravel()\n    if arr.size < ws:\n        return np.empty(0, dtype=float), ws\n    return arr, ws\n\n@lru_cache(maxsize=32)\ndef _exp_weights(ws):\n    \"\"\"Pre\u2011compute exponential weights for a given window size.\"\"\"\n    w = np.exp(np.linspace(-2, 0, ws))\n    return w / w.sum()\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Fast simple moving\u2011average filter (valid convolution).\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    # Cumulative\u2011sum implementation for O(N) performance\n    csum = np.cumsum(np.insert(arr, 0, 0.0))\n    return (csum[ws:] - csum[:-ws]) / ws\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"Exponentially weighted moving\u2011average filter (valid convolution).\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    return np.convolve(arr, _exp_weights(ws), mode='valid')\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; output length aligns with other filters.\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    alpha = 2.0 / (ws + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[ws - 1 :]\n\ndef _savgol_filter(x, window_size=20, polyorder=3):\n    \"\"\"Savitzky\u2011Golay filter with safe fall\u2011back to adaptive filter.\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    try:\n        from scipy import signal\n        wlen = ws\n        if wlen % 2 == 0:\n            wlen += 1\n        wlen = max(wlen, polyorder + 2)\n        if wlen % 2 == 0:\n            wlen += 1\n        return signal.savgol_filter(arr, window_length=wlen, polyorder=polyorder, mode='interp')\n    except Exception:\n        return adaptive_filter(arr, ws)\n\ndef hybrid_filter(x, window_size=20):\n    \"\"\"Apply the enhanced filter followed by exponential smoothing.\"\"\"\n    tmp = enhanced_filter_with_trend_preservation(x, window_size)\n    return exponential_smoothing(tmp, window_size)\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"Dispatch to the selected filtering algorithm (case\u2011insensitive).\n\n    Supported ``algorithm_type`` values:\n        - \"basic\"   : simple moving average\n        - \"enhanced\": exponential weighted moving average (default)\n        - \"exp\"     : exponential smoothing\n        - \"savgol\"  : Savitzky\u2011Golay (fallback to basic)\n        - \"hybrid\"  : enhanced followed by smoothing\n    \"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n    if alg == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n    if alg == \"savgol\":\n        return _savgol_filter(input_signal, window_size)\n    if alg == \"hybrid\":\n        return hybrid_filter(input_signal, window_size)\n    # Default to enhanced for unknown types\n    return enhanced_filter_with_trend_preservation(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (91.000)\n\n### Inspiration 2 (Score: 0.0000, Type: Exploratory)\n```python\n# EVOLVE-BLOCK-START\ndef _moving_average(arr, w):\n    \"\"\"Efficient moving average using cumulative sum (valid convolution).\"\"\"\n    if w <= 1:\n        return arr.copy()\n    csum = np.cumsum(np.insert(arr, 0, 0.0))\n    return (csum[w:] - csum[:-w]) / w\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"\n    Exponentially weighted moving\u2011average (EWMA) followed by a short\n    smoothing pass to suppress residual high\u2011frequency noise.\n\n    The additional smoothing uses a small fixed window (up to 5 samples)\n    and is applied only when enough data points are available.\n    \"\"\"\n    arr, ws = _to_array(x, window_size)\n    if arr.size == 0:\n        return arr\n\n    # EWMA \u2013 valid convolution\n    ewma = np.convolve(arr, _exp_weights(ws), mode='valid')\n    if ewma.size == 0:\n        return ewma\n\n    # Final light smoothing (window up to 5, but not larger than the signal)\n    final_ws = min(5, ewma.size)\n    if final_ws <= 1:\n        return ewma\n    return _moving_average(ewma, final_ws)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Alternative runs_successfully approach, NumPy-based implementation\n\n### Inspiration 3 (Score: 10.2386, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\ntry:\n    from scipy.signal import savgol_filter, butter, filtfilt\n    _HAS_SCI = True\nexcept Exception:\n    _HAS_SCI = False\n\n\ndef _validate_input(x, window_size):\n    \"\"\"Convert input to a NumPy array and ensure it meets the minimum length.\n\n    Returns an empty array if the input is empty or shorter than ``window_size``.\n    Raises ``ValueError`` for non\u2011positive ``window_size``.\n    \"\"\"\n    if not isinstance(window_size, int) or window_size <= 0:\n        raise ValueError(f\"window_size must be a positive integer, got {window_size}\")\n\n    arr = np.asarray(x, dtype=float)\n    if arr.size == 0:\n        return np.empty(0, dtype=float)\n\n    if arr.size < window_size:\n        # Not enough data for the requested window \u2013 return empty result\n        return np.empty(0, dtype=float)\n\n    return arr\n\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Simple moving\u2011average filter using ``np.convolve`` (valid mode).\"\"\"\n    x = _validate_input(x, window_size)\n    if x.size == 0:\n        return np.array([], dtype=float)\n    return np.convolve(x, np.ones(window_size) / window_size, mode='valid')\n\n\ndef _apply_savgol(x, window_size, polyorder=3):\n    \"\"\"Safely apply Savitzky\u2011Golay filtering with sensible parameter handling.\"\"\"\n    x = _validate_input(x, window_size)\n    if x.size == 0:\n        return np.array([], dtype=float)\n\n    if not _HAS_SCI:\n        # Fallback to a simple moving average when SciPy is unavailable\n        return adaptive_filter(x, window_size)\n\n    w = int(window_size)\n    if w % 2 == 0:\n        w += 1\n    min_len = polyorder + 2\n    if w < min_len:\n        w = min_len + (min_len % 2 == 0)\n    return savgol_filter(x, window_length=w, polyorder=polyorder, mode='interp')\n\n\ndef _adaptive_window(base_window, signal):\n    \"\"\"Adjust Savitzky\u2011Golay window based on signal variability (coefficient of variation).\"\"\"\n    signal = np.asarray(signal, dtype=float)\n    if signal.size == 0:\n        return max(5, base_window | 1)  # ensure odd and at least 5\n    cv = np.std(signal) / (np.mean(np.abs(signal)) + 1e-9)\n    cv = max(0.0, min(1.0, cv))\n    adaptive = int(base_window * (1.0 - 0.5 * cv))\n    adaptive = max(5, adaptive)\n    if adaptive % 2 == 0:\n        adaptive += 1\n    return adaptive\n\n\ndef _lowpass_filter(signal, cutoff, order=2):\n    \"\"\"Zero\u2011phase Butterworth low\u2011pass filter (identity fallback if SciPy unavailable).\"\"\"\n    signal = np.asarray(signal, dtype=float)\n    if signal.size == 0:\n        return signal\n    if not _HAS_SCI:\n        return signal\n\n    # Assume unit sampling rate (fs=1). Normalized cutoff = cutoff / (0.5*fs) = 2*cutoff\n    nyq = 0.5\n    norm_cutoff = min(1.0, max(0.0, cutoff / nyq))\n    b, a = butter(order, norm_cutoff, btype='low', analog=False)\n    return filtfilt(b, a, signal)\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"\n    Multi\u2011stage filter:\n        1\ufe0f\u20e3 Exponential weighted moving average (EWMA).\n        2\ufe0f\u20e3 Adaptive Savitzky\u2011Golay smoothing.\n        3\ufe0f\u20e3 Low\u2011pass Butterworth filter (adaptive cutoff).\n        4\ufe0f\u20e3 Short moving average (5\u2011point) for residual smoothing.\n    \"\"\"\n    x = _validate_input(x, window_size)\n    if x.size == 0:\n        return np.array([], dtype=float)\n\n    # Stage 1: EWMA\n    weights = np.exp(np.linspace(-2, 0, window_size))\n    weights /= weights.sum()\n    ewma = np.convolve(x, weights, mode='valid')\n\n    # Stage 2: Adaptive Savitzky\u2011Golay\n    adaptive_win = _adaptive_window(window_size, ewma)\n    sg = _apply_savgol(ewma, adaptive_win, polyorder=2)\n\n    # Stage 3: Low\u2011pass filter\n    base_cutoff = 0.1  # baseline cutoff frequency (relative to Nyquist)\n    cutoff = max(0.02, base_cutoff * (window_size / 20.0))\n    lowpassed = _lowpass_filter(sg, cutoff=cutoff, order=2)\n\n    # Stage 4: Final short moving average (5\u2011point)\n    if lowpassed.size < 5:\n        return lowpassed\n    final = np.convolve(lowpassed, np.ones(5) / 5, mode='valid')\n    return final\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"\n    Dispatch to the selected filtering algorithm.\n\n    Parameters\n    ----------\n    input_signal : array\u2011like\n        Raw signal to be filtered.\n    window_size : int, optional\n        Base window length for filters (default is 20).\n    algorithm_type : {\"basic\", \"savgol\", \"enhanced\"}, optional\n        Choose the filtering strategy (case\u2011insensitive). Unrecognised values raise ``ValueError``.\n    \"\"\"\n    alg = str(algorithm_type).lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"savgol\":\n        return _apply_savgol(input_signal, window_size, polyorder=3)\n    if alg == \"enhanced\":\n        return enhanced_filter_with_trend_preservation(input_signal, window_size)\n\n    raise ValueError(f\"Unsupported algorithm_type: {algorithm_type}\")\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\nUnique approach: Modification: Evolve block rewrite (preserved external code), Excellent runs_successfully (1.000), Excellent output_length (87.000)\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef _as_array(x, window_size):\n    \"\"\"Convert input to 1\u2011D float array and validate window size.\"\"\"\n    arr = np.asarray(x, dtype=float)\n    ws = int(window_size)\n    if ws <= 0:\n        raise ValueError(\"window_size must be a positive integer\")\n    if arr.size < ws:\n        raise ValueError(f\"Input length ({arr.size}) < window_size ({ws})\")\n    return arr, ws\n\ndef _apply_savgol(signal, window_len, polyorder=3):\n    \"\"\"Safely apply Savitzky\u2011Golay filter; fallback to simple moving average.\"\"\"\n    try:\n        from scipy.signal import savgol_filter\n    except Exception:\n        # fallback: simple moving average\n        if window_len <= 0:\n            return signal\n        return np.convolve(signal, np.ones(window_len) / window_len, mode=\"valid\")\n    # ensure odd window length and minimum size for polyorder\n    w = int(window_len)\n    if w % 2 == 0:\n        w += 1\n    min_len = polyorder + 2\n    if w < min_len:\n        w = min_len + (min_len % 2 == 0)\n    return savgol_filter(signal, window_length=w, polyorder=polyorder, mode='interp')\n\ndef _short_moving_average(signal, length=5):\n    \"\"\"Final short moving average to smooth residual high\u2011frequency noise.\"\"\"\n    if signal.size < length or length <= 0:\n        return signal\n    return np.convolve(signal, np.ones(length) / length, mode=\"valid\")\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Simple moving\u2011average filter.\"\"\"\n    arr, ws = _as_array(x, window_size)\n    return np.convolve(arr, np.ones(ws) / ws, mode=\"valid\")\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"Multi\u2011stage filter: EWMA \u2192 optional Savitzky\u2011Golay \u2192 short MA.\"\"\"\n    arr, ws = _as_array(x, window_size)\n\n    # Stage 1: Exponential weighted moving average (EWMA)\n    weights = np.exp(np.linspace(-2, 0, ws))\n    weights /= weights.sum()\n    ewma = np.convolve(arr, weights, mode=\"valid\")\n\n    # Stage 2: Savitzky\u2011Golay if enough points, else keep EWMA\n    if ewma.size >= max(5, ws):\n        # adapt window size based on signal variability (simple heuristic)\n        cv = np.std(ewma) / (np.mean(np.abs(ewma)) + 1e-9)\n        adaptive_win = int(ws * (1.0 - 0.5 * min(max(cv, 0.0), 1.0))\n        adaptive_win = max(5, adaptive_win)\n        sg = _apply_savgol(ewma, adaptive_win, polyorder=2)\n    else:\n        sg = ewma\n\n    # Stage 3: Short moving average to clean residues\n    final = _short_moving_average(sg, length=5)\n    return final\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; output length matches other filters.\"\"\"\n    arr, ws = _as_array(x, window_size)\n    alpha = 2.0 / (ws + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[ws - 1 :]\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"Dispatch to the selected filtering algorithm (case\u2011insensitive).\"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n    # default to enhanced for unknown or \"enhanced\"\n    return enhanced_filter_with_trend_preservation(input_signal, window_size)\n# EVOLVE-BLOCK-END\n\n\ndef generate_test_signal(length=1000, noise_level=0.3, seed=42):\n    \"\"\"\n    Generate synthetic test signal with known characteristics.\n\n    Args:\n        length: Length of the signal\n        noise_level: Standard deviation of noise to add\n        seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (noisy_signal, clean_signal)\n    \"\"\"\n    np.random.seed(seed)\n    t = np.linspace(0, 10, length)\n\n    # Create a complex signal with multiple components\n    clean_signal = (\n        2 * np.sin(2 * np.pi * 0.5 * t)  # Low frequency component\n        + 1.5 * np.sin(2 * np.pi * 2 * t)  # Medium frequency component\n        + 0.5 * np.sin(2 * np.pi * 5 * t)  # Higher frequency component\n        + 0.8 * np.exp(-t / 5) * np.sin(2 * np.pi * 1.5 * t)  # Decaying oscillation\n    )\n\n    # Add non-stationary behavior\n    trend = 0.1 * t * np.sin(0.2 * t)  # Slowly varying trend\n    clean_signal += trend\n\n    # Add random walk component for non-stationarity\n    random_walk = np.cumsum(np.random.randn(length) * 0.05)\n    clean_signal += random_walk\n\n    # Add noise\n    noise = np.random.normal(0, noise_level, length)\n    noisy_signal = clean_signal + noise\n\n    return noisy_signal, clean_signal\n\n\ndef run_signal_processing(signal_length=1000, noise_level=0.3, window_size=20):\n    \"\"\"\n    Run the signal processing algorithm on a test signal.\n\n    Returns:\n        Dictionary containing results and metrics\n    \"\"\"\n    # Generate test signal\n    noisy_signal, clean_signal = generate_test_signal(signal_length, noise_level)\n\n    # Process the signal\n    filtered_signal = process_signal(noisy_signal, window_size, \"enhanced\")\n\n    # Calculate basic metrics\n    if len(filtered_signal) > 0:\n        # Align signals for comparison (account for processing delay)\n        delay = window_size - 1\n        aligned_clean = clean_signal[delay:]\n        aligned_noisy = noisy_signal[delay:]\n\n        # Ensure same length\n        min_length = min(len(filtered_signal), len(aligned_clean))\n        filtered_signal = filtered_signal[:min_length]\n        aligned_clean = aligned_clean[:min_length]\n        aligned_noisy = aligned_noisy[:min_length]\n\n        # Calculate correlation with clean signal\n        correlation = np.corrcoef(filtered_signal, aligned_clean)[0, 1] if min_length > 1 else 0\n\n        # Calculate noise reduction\n        noise_before = np.var(aligned_noisy - aligned_clean)\n        noise_after = np.var(filtered_signal - aligned_clean)\n        noise_reduction = (noise_before - noise_after) / noise_before if noise_before > 0 else 0\n\n        return {\n            \"filtered_signal\": filtered_signal,\n            \"clean_signal\": aligned_clean,\n            \"noisy_signal\": aligned_noisy,\n            \"correlation\": correlation,\n            \"noise_reduction\": noise_reduction,\n            \"signal_length\": min_length,\n        }\n    else:\n        return {\n            \"filtered_signal\": [],\n            \"clean_signal\": [],\n            \"noisy_signal\": [],\n            \"correlation\": 0,\n            \"noise_reduction\": 0,\n            \"signal_length\": 0,\n        }\n\n\nif __name__ == \"__main__\":\n    # Test the algorithm\n    results = run_signal_processing()\n    print(f\"Signal processing completed!\")\n    print(f\"Correlation with clean signal: {results['correlation']:.3f}\")\n    print(f\"Noise reduction: {results['noise_reduction']:.3f}\")\n    print(f\"Processed signal length: {results['signal_length']}\")\n\n```\n\n# Task\nImprove the code to maximize FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\n\n## CRITICAL INSTRUCTIONS\nIf the code contains `# EVOLVE-BLOCK-START` and `# EVOLVE-BLOCK-END` markers:\n- Output ONLY the code that goes BETWEEN these markers\n- Do NOT include the markers themselves\n- Do NOT include code outside the markers (like `run_packing()`)\n- The system will automatically merge your output with the preserved sections\n\nIf there are NO EVOLVE-BLOCK markers:\n- Output the complete rewritten program\n\n```python\n# Your improved code here (ONLY the evolve block content if markers exist)\n```", "responses": ["import numpy as np\nfrom functools import lru_cache\n\ndef _prepare_input(x, window_size):\n    \"\"\"Validate *window_size* and convert *x* to a 1\u2011D float array.\n\n    Returns a tuple ``(arr, ws)`` where ``ws`` is the validated window size.\n    If the input is shorter than ``ws`` an empty array is returned so callers\n    can handle the situation gracefully.\n    \"\"\"\n    ws = int(window_size)\n    if ws <= 0:\n        raise ValueError(\"window_size must be a positive integer\")\n    arr = np.asarray(x, dtype=float).ravel()\n    if arr.size < ws:\n        return np.empty(0, dtype=float), ws\n    return arr, ws\n\n\n@lru_cache(maxsize=32)\ndef _exp_weights(ws):\n    \"\"\"Pre\u2011compute exponential weights for EWMA.\"\"\"\n    w = np.exp(np.linspace(-2, 0, ws))\n    return w / w.sum()\n\n\ndef _apply_savgol(signal, window_len, polyorder=3):\n    \"\"\"Safely apply Savitzky\u2011Golay filter; fall back to simple MA.\"\"\"\n    if signal.size == 0:\n        return signal\n    try:\n        from scipy.signal import savgol_filter\n    except Exception:\n        # fallback: simple moving average\n        if window_len <= 0:\n            return signal\n        return np.convolve(signal, np.ones(window_len) / window_len, mode=\"valid\")\n\n    w = int(window_len)\n    if w % 2 == 0:\n        w += 1\n    min_len = polyorder + 2\n    if w < min_len:\n        w = min_len + (min_len % 2 == 0)\n    return savgol_filter(signal, window_length=w, polyorder=polyorder, mode='interp')\n\n\ndef _lowpass_filter(signal, cutoff=0.1, order=2):\n    \"\"\"Zero\u2011phase Butterworth low\u2011pass filter; identity fallback if SciPy unavailable.\"\"\"\n    if signal.size == 0:\n        return signal\n    try:\n        from scipy.signal import butter, filtfilt\n    except Exception:\n        return signal\n\n    # Normalized cutoff (Nyquist = 0.5 for unit sampling rate)\n    nyq = 0.5\n    norm_cutoff = min(1.0, max(0.0, cutoff / nyq))\n    b, a = butter(order, norm_cutoff, btype='low', analog=False)\n    return filtfilt(b, a, signal)\n\n\ndef _short_moving_average(signal, length=5):\n    \"\"\"Final short MA to smooth residual high\u2011frequency noise.\"\"\"\n    if signal.size < length or length <= 0:\n        return signal\n    return np.convolve(signal, np.ones(length) / length, mode=\"valid\")\n\n\ndef adaptive_filter(x, window_size=20):\n    \"\"\"Simple moving\u2011average filter using cumulative sum (valid mode).\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    csum = np.cumsum(np.insert(arr, 0, 0.0))\n    return (csum[ws:] - csum[:-ws]) / ws\n\n\ndef enhanced_filter_with_trend_preservation(x, window_size=20):\n    \"\"\"Multi\u2011stage filter: EWMA \u2192 adaptive Savitzky\u2011Golay \u2192 low\u2011pass \u2192 short MA.\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n\n    # Stage 1: EWMA (valid convolution)\n    ewma = np.convolve(arr, _exp_weights(ws), mode=\"valid\")\n\n    # Stage 2: Adaptive Savitzky\u2011Golay if enough points\n    if ewma.size >= max(5, ws):\n        cv = np.std(ewma) / (np.mean(np.abs(ewma)) + 1e-9)\n        adaptive_win = int(ws * (1.0 - 0.5 * min(max(cv, 0.0), 1.0)))\n        adaptive_win = max(5, adaptive_win)\n        sg = _apply_savgol(ewma, adaptive_win, polyorder=2)\n    else:\n        sg = ewma\n\n    # Stage 3: Low\u2011pass Butterworth (cutoff adapts to window size)\n    cutoff = max(0.02, 0.1 * (ws / 20.0))\n    lowpassed = _lowpass_filter(sg, cutoff=cutoff, order=2)\n\n    # Stage 4: Short moving average to clean residues\n    return _short_moving_average(lowpassed, length=5)\n\n\ndef exponential_smoothing(x, window_size=20):\n    \"\"\"Recursive exponential smoothing; output aligns with other filters.\"\"\"\n    arr, ws = _prepare_input(x, window_size)\n    if arr.size == 0:\n        return arr\n    alpha = 2.0 / (ws + 1.0)\n    y = np.empty_like(arr)\n    y[0] = arr[0]\n    for i in range(1, arr.size):\n        y[i] = alpha * arr[i] + (1.0 - alpha) * y[i - 1]\n    return y[ws - 1 :]\n\n\ndef process_signal(input_signal, window_size=20, algorithm_type=\"enhanced\"):\n    \"\"\"Dispatch to the selected filtering algorithm (case\u2011insensitive).\"\"\"\n    alg = algorithm_type.lower()\n    if alg == \"basic\":\n        return adaptive_filter(input_signal, window_size)\n    if alg == \"exp\":\n        return exponential_smoothing(input_signal, window_size)\n    if alg == \"savgol\":\n        arr, ws = _prepare_input(input_signal, window_size)\n        return _apply_savgol(arr, ws, polyorder=3) if arr.size else arr\n    if alg == \"hybrid\":\n        # EWMA followed by exponential smoothing\n        ewma = enhanced_filter_with_trend_preservation(input_signal, window_size)\n        return exponential_smoothing(ewma, window_size)\n    # default / \"enhanced\"\n    return enhanced_filter_with_trend_preservation(input_signal, window_size)"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}